{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d75117f",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/rickiepark/llm-from-scratch/blob/main/ch06/01_main-chapter-code/ch06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c024bfa4-1a7a-4751-b5a1-827225a3478b",
   "metadata": {
    "id": "c024bfa4-1a7a-4751-b5a1-827225a3478b"
   },
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<font size=\"2\">\n",
    "세바스찬 라시카(Sebastian Raschka)가 쓴 <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a>의 번역서 <br><<b><a href=\"<a href=\"http://tensorflow.blog/llm-from-scratch\">밑바닥부터 만들면서 배우는 LLM</a></b>>의 예제 코드입니다.<br>\n",
    "<br>코드 저장소: <a href=\"https://github.com/rickiepark/llm-from-scratch\">https://github.com/rickiepark/llm-from-scratch</a>\n",
    "</font>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<a href=\"http://tensorflow.blog/llm-from-scratch\"><img src=\"https://tensorflowkorea.wordpress.com/wp-content/uploads/2025/09/ebb091ebb094eb8ba5llm_ebb3b8ecb185_ec959eeba9b4.jpg\" width=\"100px\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfabadb8-5935-45ff-b39c-db7a29012129",
   "metadata": {
    "id": "bfabadb8-5935-45ff-b39c-db7a29012129"
   },
   "source": [
    "# 챕터 6: 텍스트 분류를 위한 미세 튜닝\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
    "outputId": "92210e7a-246a-40c5-d0fa-edbee611fc44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib 버전: 3.10.8\n",
      "numpy 버전: 2.4.0\n",
      "tiktoken 버전: 0.12.0\n",
      "torch 버전: 2.9.1+cu126\n",
      "pandas 버전: 2.3.3\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\",  # 그래프 라이브러리\n",
    "        \"numpy\",       # 파이토치와 텐서플로의 종속성\n",
    "        \"tiktoken\",    # 토크나이저\n",
    "        \"torch\",       # 딥러닝 라이브러리\n",
    "        # \"tensorflow\",  # OpenAI의 사전 훈련된 가중치를 위해서\n",
    "        \"pandas\"       # 데이터셋 로딩을 위해\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} 버전: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a445828a-ff10-4efa-9f60-a2e2aed4c87d",
   "metadata": {
    "id": "a445828a-ff10-4efa-9f60-a2e2aed4c87d"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch06_compressed/01.webp\" width=800px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a84cf35-b37f-4c15-8972-dfafc9fadc1c",
   "metadata": {
    "id": "3a84cf35-b37f-4c15-8972-dfafc9fadc1c"
   },
   "source": [
    "## 6.1 여러 가지 미세 튜닝 방법\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac45579d-d485-47dc-829e-43be7f4db57b",
   "metadata": {
    "id": "ac45579d-d485-47dc-829e-43be7f4db57b"
   },
   "source": [
    "- 가장 일반적인 언어 모델 미세 튜닝 방법은 지시 미세 조정 및 분류 미세 튜닝입니다.\n",
    "- 아래에 나타난 지시 미세 튜닝은 다음 장의 주제입니다.\n",
    "- pretrained model에서 finetuning하는 것이 효과적\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c29ef42-46d9-43d4-8bb4-94974e1665e4",
   "metadata": {
    "id": "6c29ef42-46d9-43d4-8bb4-94974e1665e4"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch06_compressed/02.webp\" width=700px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f60321-95b8-46a9-97bf-1d07fda2c3dd",
   "metadata": {
    "id": "a7f60321-95b8-46a9-97bf-1d07fda2c3dd"
   },
   "source": [
    "- 이 장의 주제인 분류 미세 튜닝(Classification finetuning)은 머신 러닝에 대한 배경 지식이 있다면 이미 익숙할 수 있는 절차입니다. 예를 들어, 손글씨 숫자를 분류하기 위해 합성곱 신경망을 훈련하는 것과 유사합니다.\n",
    "- 분류 미세 튜닝에서는 모델이 출력할 수 있는 특정 개수의 클래스 레이블(예: \"스팸\" 및 \"스팸아님\")이 있습니다.\n",
    "- 분류 미세 튜닝된 모델은 훈련 중에 본 클래스(예: \"스팸\" 또는 \"스팸아님\")만 예측할 수 있는 반면, 지시 미세 튜닝된 모델은 일반적으로 많은 작업을 수행할 수 있습니다.\n",
    "- 분류 미세 튜닝된 모델을 매우 특수화된 모델로 생각할 수 있습니다. 실제로는 다양한 작업에서 잘 수행되는 일반 모델보다 특수 모델을 만드는 것이 훨씬 쉽습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b37a0c4-0bb1-4061-b1fe-eaa4416d52c3",
   "metadata": {
    "id": "0b37a0c4-0bb1-4061-b1fe-eaa4416d52c3"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch06_compressed/03.webp\" width=600px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf",
   "metadata": {
    "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf"
   },
   "source": [
    "## 6.2 데이터셋 준비\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f628975-d2e8-4f7f-ab38-92bb868b7067",
   "metadata": {
    "id": "5f628975-d2e8-4f7f-ab38-92bb868b7067"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch06_compressed/04.webp\" width=700px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbd459f-63fa-4d8c-8499-e23103156c7d",
   "metadata": {
    "id": "9fbd459f-63fa-4d8c-8499-e23103156c7d"
   },
   "source": [
    "- 이 섹션에서는 분류 미세 튜닝에 사용할 데이터셋을 준비합니다.\n",
    "- 스팸 및 스팸아님 텍스트 메시지로 구성된 데이터셋을 분류하기 위해 LLM을 미세 튜닝합니다.\n",
    "- 먼저 데이터셋을 다운로드하고 압축을 풉니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
    "outputId": "8102ff6b-68a4-4d70-90ce-9a835722d953"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datas\\sms_spam_collection\\SMSSpamCollection.tsv가 이미 있어 다운로드 및 압축 해제를 건너뜁니다.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"datas/sms_spam_collection.zip\"\n",
    "extracted_path = \"datas/sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path}가 이미 있어 다운로드 및 압축 해제를 건너뜁니다.\")\n",
    "        return\n",
    "\n",
    "    # 파일을 다운로드 합니다.\n",
    "    response = requests.get(url, stream=True, timeout=60)\n",
    "    response.raise_for_status()\n",
    "    with open(zip_path, \"wb\") as out_file:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            if chunk:\n",
    "                out_file.write(chunk)\n",
    "\n",
    "    # 파일 압축을 풉니다.\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    # .tsv 파일 확장자를 추가합니다.\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"파일이 다운로드되어 {data_file_path}에 저장되었습니다.\")\n",
    "\n",
    "try:\n",
    "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
    "except (requests.exceptions.RequestException, TimeoutError) as e:\n",
    "    print(f\"기본 URL 실패: {e}. 백업 URL을 시도합니다...\")\n",
    "    url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/sms%2Bspam%2Bcollection.zip\"\n",
    "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aac2d19-06d0-4005-916b-0bd4b1ee50d1",
   "metadata": {
    "id": "6aac2d19-06d0-4005-916b-0bd4b1ee50d1"
   },
   "source": [
    "- 데이터셋은 탭으로 구분된 텍스트 파일로 저장되며, Pandas DataFrame으로 로드할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da0ed4da-ac31-4e4d-8bdd-2153be4656a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 440
    },
    "id": "da0ed4da-ac31-4e4d-8bdd-2153be4656a4",
    "outputId": "83060795-1163-4d18-89a7-76a5ced320c3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b6e631-4f0b-4aab-82b9-8898e6663109",
   "metadata": {
    "id": "e7b6e631-4f0b-4aab-82b9-8898e6663109"
   },
   "source": [
    "- 클래스 분포를 확인해 보면, 데이터에 \"스팸\"보다 \"햄\"(즉, \"스팸아님\")이 훨씬 더 많이 포함되어 있음을 알 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "495a5280-9d7c-41d4-9719-64ab99056d4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "495a5280-9d7c-41d4-9719-64ab99056d4c",
    "outputId": "1e1c04f1-6999-4eac-9fda-3d95409a02a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f773f054-0bdc-4aad-bbf6-397621bf63db",
   "metadata": {
    "id": "f773f054-0bdc-4aad-bbf6-397621bf63db"
   },
   "source": [
    "- 간단하게 하기 위해, 그리고 교육 목적으로 작은 데이터셋을 선호하기 때문에 (LLM을 더 빠르게 미세 튜닝할 수 있음), 각 클래스마다 747개의 샘플이 포함되도록 데이터 세트를 서브샘플링(언더샘플링)합니다.\n",
    "- (언더샘플링 외에도 클래스 불균형을 처리하는 여러 가지 다른 방법이 있지만 LLM에 관한 책의 범위를 벗어납니다. [`imbalanced-learn` 사용자 가이드](https://imbalanced-learn.org/stable/user_guide.html)에서 예제와 자세한 정보를 찾을 수 있습니다.)\n",
    "- 데이터가 편향되어 있으면\n",
    "  - 다수 클래스로 편향이 됨\n",
    "  - 정확도가 높지만 스팸을탐ㅌ지하지 못할 가능성이 있음\n",
    "  - 스팸을 노이지로 취급해 무시해 버릴 가능성이 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7be4a0a2-9704-4a96-b38f-240339818688",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7be4a0a2-9704-4a96-b38f-240339818688",
    "outputId": "32448d26-f31d-4158-9f99-58d044a1e90e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_balanced_dataset(df):\n",
    "\n",
    "    # \"스팸\" 샘플 개수 세기\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "\n",
    "    # \"스팸\" 샘플 개수와 일치하도록 \"햄\" 샘플을 무작위로 샘플링\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
    "\n",
    "    # \"햄\"과 \"스팸\"을 합침\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
    "\n",
    "    return balanced_df\n",
    "\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fd2f5a-06d8-4d30-a2e3-230b86c559d6",
   "metadata": {
    "id": "d3fd2f5a-06d8-4d30-a2e3-230b86c559d6"
   },
   "source": [
    "- 다음으로, 문자열 클래스 레이블 \"ham\"과 \"spam\"을 정수 클래스 레이블 0과 1로 변경합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1b10c3d-5d57-42d0-8de8-cf80a06f5ffd",
   "metadata": {
    "id": "c1b10c3d-5d57-42d0-8de8-cf80a06f5ffd"
   },
   "outputs": [],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6f7f062-ef4e-4020-8275-71990cab4414",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 440
    },
    "id": "e6f7f062-ef4e-4020-8275-71990cab4414",
    "outputId": "c8d42c61-bae9-40f6-8e6e-7effa919a67f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>0</td>\n",
       "      <td>Awww dat is sweet! We can think of something t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>0</td>\n",
       "      <td>Just got to  &amp;lt;#&amp;gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4831</th>\n",
       "      <td>0</td>\n",
       "      <td>The word \"Checkmate\" in chess comes from the P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>0</td>\n",
       "      <td>This is wishing you a great day. Moji told me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5440</th>\n",
       "      <td>0</td>\n",
       "      <td>Thank you. do you generally date the brothas?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5537</th>\n",
       "      <td>1</td>\n",
       "      <td>Want explicit SEX in 30 secs? Ring 02073162414...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5540</th>\n",
       "      <td>1</td>\n",
       "      <td>ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>1</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>1</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label                                               Text\n",
       "4307      0  Awww dat is sweet! We can think of something t...\n",
       "4138      0                             Just got to  &lt;#&gt;\n",
       "4831      0  The word \"Checkmate\" in chess comes from the P...\n",
       "4461      0  This is wishing you a great day. Moji told me ...\n",
       "5440      0      Thank you. do you generally date the brothas?\n",
       "...     ...                                                ...\n",
       "5537      1  Want explicit SEX in 30 secs? Ring 02073162414...\n",
       "5540      1  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
       "5547      1  Had your contract mobile 11 Mnths? Latest Moto...\n",
       "5566      1  REMINDER FROM O2: To get 2.50 pounds free call...\n",
       "5567      1  This is the 2nd time we have tried 2 contact u...\n",
       "\n",
       "[1494 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5715e685-35b4-4b45-a86c-8a8694de9d6f",
   "metadata": {
    "id": "5715e685-35b4-4b45-a86c-8a8694de9d6f"
   },
   "source": [
    "- 데이터셋을 훈련 세트, 검증 세트, 테스트 세트로 무작위 분할하는 함수를 정의해 보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uQl0Psdmx15D",
   "metadata": {
    "id": "uQl0Psdmx15D"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def random_split(df, train_frac, validation_frac):\n",
    "    \"\"\"\n",
    "    데이터프레임을 학습, 검증, 테스트 세트로 무작위 분할하는 함수\n",
    "    \n",
    "    Args:\n",
    "        df: 분할할 전체 데이터프레임\n",
    "        train_frac: 학습 데이터 비율 (예: 0.7)\n",
    "        validation_frac: 검증 데이터 비율 (예: 0.1)\n",
    "        # 테스트 데이터 비율은 남은 비율로 자동 결정됩니다.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. 데이터프레임 전체 섞기 (Shuffle)\n",
    "    # - frac=1: 전체 데이터의 100%를 샘플링 (모든 데이터를 가져오되 순서만 섞음)\n",
    "    # - random_state=123: 매번 실행할 때마다 똑같은 순서로 섞이도록 고정 (재현성 확보)\n",
    "    # - reset_index(drop=True): 섞인 후 뒤죽박죽된 인덱스를 버리고, 0부터 다시 차례대로 부여\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "    # 2. 분할할 지점(인덱스 위치) 계산\n",
    "    # 전체 개수(len)에 비율을 곱해 어디서 자를지 정수형(int)으로 계산\n",
    "    train_end = int(len(df) * train_frac)                          # 학습 데이터가 끝나는 지점\n",
    "    validation_end = train_end + int(len(df) * validation_frac)    # 검증 데이터가 끝나는 지점\n",
    "\n",
    "    # 3. 데이터프레임 슬라이싱 (Slicing)으로 분할\n",
    "    train_df = df[:train_end]                     # 처음부터 ~ 학습 끝 지점까지\n",
    "    validation_df = df[train_end:validation_end]  # 학습 끝 지점부터 ~ 검증 끝 지점까지\n",
    "    test_df = df[validation_end:]                 # 검증 끝 지점부터 ~ 마지막 끝까지 (나머지 전부)\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "# 함수 실행 예시\n",
    "# balanced_df라는 데이터를 7:1:2 비율로 나눕니다.\n",
    "# (Train: 70%, Validation: 10%, Test: 나머지 20%)\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "\n",
    "# 4. 결과 저장 (CSV 파일 생성)\n",
    "# index=None: 저장할 때 불필요한 인덱스 번호(0, 1, 2...)는 파일에 포함하지 않음\n",
    "train_df.to_csv(\"datas/train.csv\", index=None)\n",
    "validation_df.to_csv(\"datas/validation.csv\", index=None)\n",
    "test_df.to_csv(\"datas/test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d7a0c5-1d5f-458a-b685-3f49520b0094",
   "metadata": {
    "id": "a8d7a0c5-1d5f-458a-b685-3f49520b0094"
   },
   "source": [
    "## 6.3 데이터 로더 만들기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7126108a-75e7-4862-b0fb-cbf59a18bb6c",
   "metadata": {
    "id": "7126108a-75e7-4862-b0fb-cbf59a18bb6c"
   },
   "source": [
    "- 텍스트 메시지의 길이가 다르다는 점에 유의하세요. 배치에 여러 훈련 샘플을 결합하려면 다음 중 하나를 수행해야 합니다.\n",
    "  1. 데이터셋 또는 배치에서 가장 짧은 메시지 길이로 모든 메시지를 자릅니다.\n",
    "  2. 데이터셋 또는 배치에서 가장 긴 메시지 길이로 모든 메시지에 패딩을 추가합니다.\n",
    "\n",
    "- 옵션 2를 선택하고 데이터셋에서 가장 긴 메시지에 맞춰 모든 메시지에 패딩을 추가합니다.\n",
    "- 이를 위해 2장에서 설명한 대로 `<|endoftext|>`를 패딩 토큰으로 사용합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0829f33f-1428-4f22-9886-7fee633b3666",
   "metadata": {
    "id": "0829f33f-1428-4f22-9886-7fee633b3666"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch06_compressed/06.webp\" width=800px>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
    "outputId": "8991d92a-7bbe-4b9d-aca5-cd8f51331654"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f582ff-68bf-450e-bd87-5fb61afe431c",
   "metadata": {
    "id": "04f582ff-68bf-450e-bd87-5fb61afe431c"
   },
   "source": [
    "- `SpamDataset` 클래스는 학습 데이터셋에서 가장 긴 시퀀스를 식별하고 다른 시퀀스에 패딩 토큰을 추가하여 해당 길이에 맞춥니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7791b52-af18-4ac4-afa9-b921068e383e",
   "metadata": {
    "id": "d7791b52-af18-4ac4-afa9-b921068e383e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd  # 데이터프레임 사용을 위해 pandas 임포트 필요\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    \"\"\"\n",
    "    CSV 파일의 텍스트 데이터를 읽어 토큰화, 자르기, 패딩을 수행하여\n",
    "    PyTorch 모델에 입력 가능한 형태로 변환하는 데이터셋 클래스\n",
    "    \"\"\"\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        # 1. 데이터 로드: pandas를 사용하여 CSV 파일을 읽어옵니다.\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        # 2. 토큰화 (Tokenization):\n",
    "        # 데이터프레임의 \"Text\" 컬럼에 있는 모든 문장을 하나씩 꺼내서\n",
    "        # tokenizer.encode()를 통해 정수 리스트(숫자)로 변환합니다.\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "\n",
    "        # 3. 최대 길이(max_length) 결정 로직:\n",
    "        if max_length is None:\n",
    "            # 사용자가 길이를 지정하지 않았다면, 데이터 중 가장 긴 문장의 길이를 사용\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            # 사용자가 길이를 지정했다면 그 값을 사용하고,\n",
    "            self.max_length = max_length\n",
    "            # 지정된 길이보다 긴 문장은 뒷부분을 잘라냅니다 (Truncation).\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        # 4. 패딩 (Padding):\n",
    "        # 모든 문장의 길이를 self.max_length로 통일합니다.\n",
    "        # 문장 길이가 max_length보다 짧다면, 부족한 만큼 pad_token_id로 채웁니다.\n",
    "        # 예: 문장 [10, 20], max=4, pad=0 -> [10, 20, 0, 0]\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        데이터셋에서 특정 인덱스(index)의 샘플을 가져오는 함수\n",
    "        데이터 로더(DataLoader)가 배치를 만들 때 이 함수를 반복 호출합니다.\n",
    "        \"\"\"\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "\n",
    "        # 파이토치 모델은 '텐서(Tensor)' 형태만 입력받을 수 있으므로 변환합니다.\n",
    "        # dtype=torch.long은 정수형(인덱스, 라벨 등)을 의미합니다.\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        # 데이터셋의 전체 샘플 개수를 반환 (학습 시 에포크 계산 등에 사용됨)\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        # 데이터셋 내의 모든 문장 중 가장 긴 문장의 길이를 찾는 헬퍼 함수\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length\n",
    "        \n",
    "        # (참고) 파이썬의 max() 함수를 쓰면 위 6줄을 한 줄로 줄일 수 있습니다:\n",
    "        # return max(len(encoded_text) for encoded_text in self.encoded_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "uzj85f8ou82h",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uzj85f8ou82h",
    "outputId": "f34653cf-2371-4d5c-dc85-249b327ab8bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"datas/train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bdd932-97eb-4b88-9cf9-d766ea4c3a60",
   "metadata": {
    "id": "15bdd932-97eb-4b88-9cf9-d766ea4c3a60"
   },
   "source": [
    "- 또한 검증 세트와 테스트 세트를 가장 긴 훈련 시퀀스에 맞춰 패딩합니다.\n",
    "- 검증 세트와 테스트 세트 샘플 중 가장 긴 훈련 세트 샘플보다 긴 샘플은 `SpamDataset` 코드에서 `encoded_text[:self.max_length]`를 통해 잘린다는 점에 유의하세요.\n",
    "- 이 동작은 완전히 선택 사항이며, 검증 세트와 테스트 세트의 경우 모두 `max_length=None`으로 설정해도 잘 작동합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb0c502d-a75e-4248-8ea0-196e2b00c61e",
   "metadata": {
    "id": "bb0c502d-a75e-4248-8ea0-196e2b00c61e"
   },
   "outputs": [],
   "source": [
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"datas/validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"datas/test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20170d89-85a0-4844-9887-832f5d23432a",
   "metadata": {
    "id": "20170d89-85a0-4844-9887-832f5d23432a"
   },
   "source": [
    "- 다음으로, 데이터셋을 사용하여 데이터 로더를 만듭니다. 이는 이전 장에서 데이터 로더를 생성하는 것과 유사합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bcc349-205f-48f8-9655-95ff21f5e72f",
   "metadata": {
    "id": "64bcc349-205f-48f8-9655-95ff21f5e72f"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch06_compressed/07.webp\" width=700px>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542",
   "metadata": {
    "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True, #학습할 때는 shuffle가 중요\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True, #미지막을 버릴지 말지\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7335db-e0bb-4e27-80c5-eea11e593a57",
   "metadata": {
    "id": "ab7335db-e0bb-4e27-80c5-eea11e593a57"
   },
   "source": [
    "- 검증 단계로서, 데이터 로더를 반복하고 각 배치에 120개의 토큰으로 구성된 8개의 훈련 샘플이 포함되어 있는지 확인합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
    "outputId": "4714979b-cbc7-4575-9868-8e9e11363d58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 로더:\n",
      "입력 배치 차원: torch.Size([8, 120])\n",
      "레이블 배치 차원 torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(\"훈련 세트 로더:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(\"입력 배치 차원:\", input_batch.shape)\n",
    "print(\"레이블 배치 차원\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdd7947-7039-49bf-8a5e-c0a2f4281ca1",
   "metadata": {
    "id": "5cdd7947-7039-49bf-8a5e-c0a2f4281ca1"
   },
   "source": [
    "- 마지막으로, 각 데이터셋의 총 배치 수를 출력해 보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "IZfw-TYD2zTj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZfw-TYD2zTj",
    "outputId": "d56f2c36-8e27-4653-bb9d-6a7aa312ddbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130개 훈련 배치\n",
      "19개 검증 배치\n",
      "38개 테스트 배치\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)}개 훈련 배치\")\n",
    "print(f\"{len(val_loader)}개 검증 배치\")\n",
    "print(f\"{len(test_loader)}개 테스트 배치\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c4f61a-5f5d-4b3b-97cf-151b617d1d6c",
   "metadata": {
    "id": "d1c4f61a-5f5d-4b3b-97cf-151b617d1d6c"
   },
   "source": [
    "## 6.4 사전 훈련된 가중치로 모델 초기화하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e1af8b-8bd1-4b44-8b8b-dc031496e208",
   "metadata": {
    "id": "97e1af8b-8bd1-4b44-8b8b-dc031496e208"
   },
   "source": [
    "- 이 섹션에서는 이전 챕터에서 작업했던 사전 훈련된 모델을 초기화합니다.\n",
    "\n",
    "<img src=\"images/llm_from_scratch/ch06_compressed/08.webp\" width=700px>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2992d779-f9fb-4812-a117-553eb790a5a9",
   "metadata": {
    "id": "2992d779-f9fb-4812-a117-553eb790a5a9"
   },
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # 어휘사전 크기\n",
    "    \"context_length\": 1024,  # 문맥 길이\n",
    "    \"drop_rate\": 0.0,        # 드롭아웃 비율\n",
    "    \"qkv_bias\": True         # 쿼리-키-값 편향\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12}, #트랜스포머 블록(Transformer Block)을 몇 층으로 쌓아 올렸는지\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
    "    f\"데이터셋 길이 {train_dataset.max_length}가 모델의 문맥 \"\n",
    "    f\"길이 {BASE_CONFIG['context_length']}를 초과합니다. `max_length={BASE_CONFIG['context_length']}`로 \"\n",
    "    f\"데이터 셋을 다시 초기화하십시오.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "022a649a-44f5-466c-8a8e-326c063384f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "022a649a-44f5-466c-8a8e-326c063384f5",
    "outputId": "57d50f99-37f3-4cea-9720-95939486fa9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미 파일이 존재합니다: models/gpt2\\gpt2-small-124M.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from previous_chapters import GPTModel, load_gpt2_model\n",
    "\n",
    "model_name = \"gpt2-small-124M.pth\"\n",
    "model = load_gpt2_model(model_name, BASE_CONFIG)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8e056c-abe0-415f-b34d-df686204259e",
   "metadata": {
    "id": "ab8e056c-abe0-415f-b34d-df686204259e"
   },
   "source": [
    "- 모델이 제대로 로드되었는지 확인하기 위해 일관된 텍스트를 생성하는지 다시 한번 확인해 보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8ac25ff-74b1-4149-8dc5-4c429d464330",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d8ac25ff-74b1-4149-8dc5-4c429d464330",
    "outputId": "db55f7cb-837b-42cf-f138-b40b9906cd40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import (\n",
    "    generate_text_simple,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "\n",
    "text_1 = \"Every effort moves you\"\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69162550-6a02-4ece-8db1-06c71d61946f",
   "metadata": {
    "id": "69162550-6a02-4ece-8db1-06c71d61946f"
   },
   "source": [
    "- 모델을 분류기로 미세 튜닝하기 전에 프롬프트를 통해 스팸 메시지를 분류할 수 있는지 확인해 보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94224aa9-c95a-4f8a-a420-76d01e3a800c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "94224aa9-c95a-4f8a-a420-76d01e3a800c",
    "outputId": "751c01da-c3a6-4496-9bc9-bd7b2b1a145d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce39ed0-2c77-410d-8392-dd15d4b22016",
   "metadata": {
    "id": "1ce39ed0-2c77-410d-8392-dd15d4b22016"
   },
   "source": [
    "- 보시다시피, 이 모델은 지시 사항을 잘 따르지 못합니다.\n",
    "- 이는 모델이 사전 학습만 되었고 지시 미세 튜닝되지 않았기 때문에 예상되는 결과입니다 (지시 미세 튜닝은 다음 장에서 다룹니다).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9ae440-32f9-412f-96cf-fd52cc3e2522",
   "metadata": {
    "id": "4c9ae440-32f9-412f-96cf-fd52cc3e2522"
   },
   "source": [
    "## 6.5 분류 헤드 추가하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e9d66f-76b2-40fc-9ec5-3f972a8db9c0",
   "metadata": {
    "id": "d6e9d66f-76b2-40fc-9ec5-3f972a8db9c0"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch06_compressed/09.webp\" width=700px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217bac05-78df-4412-bd80-612f8061c01d",
   "metadata": {
    "id": "217bac05-78df-4412-bd80-612f8061c01d"
   },
   "source": [
    "- 이 절에서는 사전 훈련된 LLM을 분류 미세 튜닝에 사용할 수 있도록 수정합니다.\n",
    "- 먼저 모델 구조를 살펴보겠습니다.(위의 그림과 연관지어서 구조 파악)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f640a76-dd00-4769-9bc8-1aed0cec330d",
   "metadata": {
    "id": "3f640a76-dd00-4769-9bc8-1aed0cec330d"
   },
   "source": [
    "- 위에서 4장에서 구현한 구조가 깔끔하게 정리되어 있는 것을 볼 수 있습니다.\n",
    "- 목표는 출력 층 교체하고 미세 튜닝하는 것입니다.\n",
    "- 이를 위해 먼저 모델을 동결합니다. 즉, 모든 층을 훈련 불가능하게 만듭니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fkMWFl-0etea",
   "metadata": {
    "id": "fkMWFl-0etea"
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72155f83-87d9-476a-a978-a15aa2d44147",
   "metadata": {
    "id": "72155f83-87d9-476a-a978-a15aa2d44147"
   },
   "source": [
    "- 그런 다음 출력 층(`model.out_head`)을 교체합니다. 이 층은 입력을 50,257차원(어휘사전 크기)으로 매핑합니다.\n",
    "- 이진 분류(\"스팸\" 및 \"스팸아님\"의 두 클래스 예측)를 위해 모델을 미세 튜닝하기 때문에 아래와 같이 출력 층를 교체할 수 있으며 기본적으로 학습 가능합니다.\n",
    "- 아래 코드를 더 일반적으로 유지하기 위해 `BASE_CONFIG[\"emb_dim\"]`(\"gpt2-small (124M)\" 모델에서 768과 같음)을 사용하는 것에 유의하세요.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e759fa0-0f69-41be-b576-17e5f20e04cb",
   "metadata": {
    "id": "7e759fa0-0f69-41be-b576-17e5f20e04cb"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30be5475-ae77-4f97-8f3e-dec462b1339f",
   "metadata": {
    "id": "30be5475-ae77-4f97-8f3e-dec462b1339f"
   },
   "source": [
    "- 기술적으로 출력 층만 훈련하는 것으로 충분합니다.\n",
    "- 하지만, [대규모 언어 모델 미세 튜닝](https://magazine.sebastianraschka.com/p/finetuning-large-language-models)에서 확인했듯이, 실험 결과 추가 층을 미세 튜닝하면 성능이 눈에 띄게 향상되는 것으로 나타났습니다.\n",
    "- 따라서 마지막 트랜스포머 블록과 마지막 트랜스포머 블록을 출력 층에 연결하는 최종 `LayerNorm` 모듈도 훈련 가능하도록 설정합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b5e496",
   "metadata": {},
   "source": [
    "- 데이터가 적으면 layer를 늘린다고 정확도가 증가하지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1418b0bd",
   "metadata": {},
   "source": [
    "<img src=\"images/relation_with_layers_and_finetuninig.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be7c1eb-c46c-4065-8525-eea1b8c66d10",
   "metadata": {
    "id": "0be7c1eb-c46c-4065-8525-eea1b8c66d10"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch06_compressed/10.webp\" width=700px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f6f637",
   "metadata": {},
   "source": [
    "- 최종 layer을 학습가능하도록 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aedc120-5ee3-48f6-92f2-ad9304ebcdc7",
   "metadata": {
    "id": "2aedc120-5ee3-48f6-92f2-ad9304ebcdc7"
   },
   "outputs": [],
   "source": [
    "# 1. 마지막 트랜스포머 블록의 파라미터 잠금 해제\n",
    "# model.trf_blocks[-1]: 트랜스포머 블록 리스트 중 '가장 마지막(-1)' 블록을 선택\n",
    "for param in model.trf_blocks[-1].parameters():\n",
    "    # requires_grad = True:\n",
    "    # 이 파라미터(가중치)에 대해 기울기(Gradient)를 계산하도록 설정합니다.\n",
    "    # 즉, 역전파(Backpropagation) 때 이 가중치를 '업데이트(학습)' 하겠다는 뜻입니다.\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 2. 마지막 정규화(Normalization) 층의 파라미터 잠금 해제\n",
    "# 모델의 최종 출력 직전에 있는 LayerNorm 층도 학습 대상에 포함시킵니다.\n",
    "for param in model.final_norm.parameters():\n",
    "    # 마찬가지로 이 층의 가중치도 학습되도록 설정합니다.\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f012b899-8284-4d3a-97c0-8a48eb33ba2e",
   "metadata": {
    "id": "f012b899-8284-4d3a-97c0-8a48eb33ba2e"
   },
   "source": [
    "- 이전 장에서처럼 이 모델을 비슷하게 사용할 수 있습니다.\n",
    "- 예를 들어, 텍스트 입력을 제공해 보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f645c06a-7df6-451c-ad3f-eafb18224ebc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f645c06a-7df6-451c-ad3f-eafb18224ebc",
    "outputId": "f34b4ba9-8f2f-4210-8d62-8bd541f58eef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력: tensor([[5211,  345,  423,  640]])\n",
      "입력 차원: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"입력:\", inputs)\n",
    "print(\"입력 차원:\", inputs.shape) # shape: (배치 크기, 토큰 수)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbf8481-772d-467b-851c-a62b86d0cb1b",
   "metadata": {
    "id": "fbbf8481-772d-467b-851c-a62b86d0cb1b"
   },
   "source": [
    "- 이전 장과 다른 점은 출력 차원이 50,257개가 아니라 2개라는 것입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48dc84f1-85cc-4609-9cee-94ff539f00f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48dc84f1-85cc-4609-9cee-94ff539f00f4",
    "outputId": "eb844ee1-84ed-4082-c03a-cc1b78c21cb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출력:\n",
      " tensor([[[-1.5854,  0.9904],\n",
      "         [-3.7235,  7.4548],\n",
      "         [-2.2661,  6.6049],\n",
      "         [-3.5983,  3.9902]]])\n",
      "출력 차원: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "\n",
    "print(\"출력:\\n\", outputs)\n",
    "print(\"출력 차원:\", outputs.shape) # shape: (배치 크기, 토큰 수, 클래스 수)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75430a01-ef9c-426a-aca0-664689c4f461",
   "metadata": {
    "id": "75430a01-ef9c-426a-aca0-664689c4f461"
   },
   "source": [
    "- 이전 장에서 논의했듯이 각 입력 토큰에 대해 하나의 출력 벡터가 있습니다.\n",
    "- 모델에 4개의 입력 토큰이 있는 텍스트 샘플을 제공했으므로 출력은 2차원 출력 벡터 4개로 구성됩니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df9144f-6817-4be4-8d4b-5d4dadfe4a9b",
   "metadata": {
    "id": "7df9144f-6817-4be4-8d4b-5d4dadfe4a9b"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch06_compressed/11.webp\" width=800px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bb8616-c791-4f5c-bac0-5302f663e46a",
   "metadata": {
    "id": "e3bb8616-c791-4f5c-bac0-5302f663e46a"
   },
   "source": [
    "- 3장에서는 각 입력 토큰을 다른 모든 입력 토큰에 연결하는 어텐션 메커니즘에 대해 논의했습니다.\n",
    "- 3장에서는 GPT와 같은 모델에 사용되는 코잘 어텐션 마스크도 소개했습니다. 코잘 마스크는 현재 토큰이 현재 및 이전 토큰 위치만 참조하도록 만듭니다.\n",
    "- 코잘 어텐션 메커니즘을 기반으로, 4번째 (마지막) 토큰이 다른 모든 토큰에 대한 정보를 포함하는 유일한 토큰이기 때문에 모든 토큰 중에서 가장 많은 정보를 담고 있습니다.\n",
    "- 따라서 우리는 이 마지막 토큰에 특히 관심이 있으며, 스팸 분류 작업을 위해 미세 튜닝할 것입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49383a8c-41d5-4dab-98f1-238bca0c2ed7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49383a8c-41d5-4dab-98f1-238bca0c2ed7",
    "outputId": "aac4b65b-6b1b-4ac4-aa4f-404664d418df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "마지막 출력 토큰: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "print(\"마지막 출력 토큰:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df08ae0-e664-4670-b7c5-8a2280d9b41b",
   "metadata": {
    "id": "8df08ae0-e664-4670-b7c5-8a2280d9b41b"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch06_compressed/12.webp\" width=400px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aa4aef-e1e9-491b-9adf-5aa973e59b8c",
   "metadata": {
    "id": "32aa4aef-e1e9-491b-9adf-5aa973e59b8c"
   },
   "source": [
    "## 6.6 분류 손실과 정확도 계산하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669e1fd1-ace8-44b4-b438-185ed0ba8b33",
   "metadata": {
    "id": "669e1fd1-ace8-44b4-b438-185ed0ba8b33"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch06_compressed/13.webp\" width=700px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7df4ee-0a34-4a4d-896d-affbbf81e0b3",
   "metadata": {
    "id": "7a7df4ee-0a34-4a4d-896d-affbbf81e0b3"
   },
   "source": [
    "- 손실 계산을 설명하기 전에 모델 출력이 어떻게 클래스 레이블로 변환되는지 간략하게 살펴보겠습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557996dd-4c6b-49c4-ab83-f60ef7e1d69e",
   "metadata": {
    "id": "557996dd-4c6b-49c4-ab83-f60ef7e1d69e"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch06_compressed/14.webp\" width=800px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edd71fa-628a-4d00-b81d-6d8bcb2c341d",
   "metadata": {
    "id": "7edd71fa-628a-4d00-b81d-6d8bcb2c341d"
   },
   "source": [
    "- 5장과 유사하게, `softmax` 함수를 통해 출력(로짓)을 확률 점수로 변환한 다음 `argmax` 함수를 통해 가장 큰 확률 값의 인덱스를 얻습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b81efa92-9be1-4b9e-8790-ce1fc7b17f01",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b81efa92-9be1-4b9e-8790-ce1fc7b17f01",
    "outputId": "67e77996-146a-4a11-c049-9fd02a1c0e77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스 레이블: 1\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
    "label = torch.argmax(probas)\n",
    "print(\"클래스 레이블:\", label.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414a6f02-307e-4147-a416-14d115bf8179",
   "metadata": {
    "id": "414a6f02-307e-4147-a416-14d115bf8179"
   },
   "source": [
    "- 5장에서 설명했듯이 소프트맥스 함수는 여기서는 선택 사항입니다. 가장 큰 출력이 가장 큰 확률 점수에 해당하기 때문입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9f9ad66-4969-4501-8239-3ccdb37e71a2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f9f9ad66-4969-4501-8239-3ccdb37e71a2",
    "outputId": "2a62cad9-c4b6-4f3c-c6ab-cd77f7d844fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스 레이블: 1\n"
     ]
    }
   ],
   "source": [
    "logits = outputs[:, -1, :]\n",
    "label = torch.argmax(logits)\n",
    "print(\"클래스 레이블:\", label.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb20d3a-cbba-4ab1-8584-d94e16589505",
   "metadata": {
    "id": "dcb20d3a-cbba-4ab1-8584-d94e16589505"
   },
   "source": [
    "- 이 개념을 적용하여 소위 분류 정확도를 계산할 수 있습니다. 분류 정확도는 주어진 데이터셋에서 정확하게 예측한 백분율입니다.\n",
    "- 분류 정확도를 계산하기 위해 앞서 설명한 `argmax` 기반 예측 코드를 데이터셋에 있는 모든 샘플에 적용하고 다음과 같이 정확한 예측의 비율을 계산할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecf9572-aed0-4a21-9c3b-7f9f2aec5f23",
   "metadata": {
    "id": "3ecf9572-aed0-4a21-9c3b-7f9f2aec5f23"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    \"\"\"\n",
    "    데이터 로더를 순회하며 모델의 정확도를 계산하는 함수\n",
    "    \"\"\"\n",
    "    # 1. 평가 모드 전환 (매우 중요)\n",
    "    # Dropout이나 Batch Normalization 같이 학습 때만 동작해야 하는 기능들을 비활성화합니다.\n",
    "    model.eval()\n",
    "    \n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    # 2. 평가할 배치 개수 설정\n",
    "    # num_batches가 없으면 전체 데이터를, 있으면 지정된 개수만큼만 확인합니다 (빠른 테스트용).\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "        \n",
    "    # 3. 데이터 로더 순회 (enumerate로 인덱스 i와 데이터를 같이 받음)\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        # 지정된 배치 개수까지만 반복\n",
    "        if i < num_batches:\n",
    "            # 데이터를 GPU(또는 지정된 device)로 이동\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "            # 4. 기울기(Gradient) 계산 비활성화 context\n",
    "            # 평가만 할 것이므로 역전파를 위한 기록을 하지 않아 메모리를 아끼고 속도를 높입니다.\n",
    "            with torch.no_grad():\n",
    "                # 모델 예측 수행\n",
    "                # 결과 shape 가정: (Batch_Size, Sequence_Length, Num_Classes)\n",
    "                # [:, -1, :] -> 모든 배치의(:), 가장 마지막 토큰(-1)의, 모든 클래스 확률(:)을 가져옴\n",
    "                logits = model(input_batch)[:, -1, :] \n",
    "            \n",
    "            # 5. 예측값 결정\n",
    "            # dim=-1: 가장 마지막 차원(클래스 확률)에서 가장 큰 값의 인덱스(클래스 번호)를 찾음\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            # 6. 정확도 누적 계산\n",
    "            # 현재 배치의 데이터 개수 더하기\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            # 예측값과 정답이 같은지 비교(==)하여 True(1)의 개수(.sum)를 더함\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    # 전체 맞은 개수 / 전체 데이터 개수 = 정확도\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669faeec-1968-4401-9786-d0849f61d32b",
   "metadata": {},
   "source": [
    "- 현재 모델 파라미터는 CPU에 로딩되어 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4124c6e2-9d0e-4ab9-9762-8698cf8a314e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{device(type='cpu')}\n"
     ]
    }
   ],
   "source": [
    "devices = {param.device for param in model.parameters()}\n",
    "print(devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7165fe46-a284-410b-957f-7524877d1a1a",
   "metadata": {
    "id": "7165fe46-a284-410b-957f-7524877d1a1a"
   },
   "source": [
    "- 여러 데이터셋에 대한 분류 정확도를 계산하기 위해 함수를 적용해 보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "390e5255-8427-488c-adef-e1c10ab4fb26",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "390e5255-8427-488c-adef-e1c10ab4fb26",
    "outputId": "76689837-ea1a-4e32-fc27-503c98f5d9d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실행 장치: cuda\n",
      "훈련 정확도: 46.25%\n",
      "검증 정확도: 45.00%\n",
      "테스트 정확도: 48.75%\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"실행 장치: {device}\")\n",
    "\n",
    "model.to(device) # nn.Module 클래스의 경우 model = model.to(device) 할당문이 필요하지 않습니다.\n",
    "\n",
    "torch.manual_seed(123) # 데이터 로더에서 셔플링하기 때문에 재현성을 위해\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"훈련 정확도: {train_accuracy*100:.2f}%\")\n",
    "print(f\"검증 정확도: {val_accuracy*100:.2f}%\")\n",
    "print(f\"테스트 정확도: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30345e2a-afed-4d22-9486-f4010f90a871",
   "metadata": {
    "id": "30345e2a-afed-4d22-9486-f4010f90a871"
   },
   "source": [
    "- 예상대로 모델을 미세 튜닝하지 않았기 때문에 예측 정확도가 그리 좋지 않습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4a9d15-8fc7-48a2-8734-d92a2f265328",
   "metadata": {
    "id": "4f4a9d15-8fc7-48a2-8734-d92a2f265328"
   },
   "source": [
    "- 미세 튜닝(훈련)을 시작하기 전에 먼저 훈련 중에 최적화하려는 손실 함수를 정의해야 합니다.\n",
    "- 목표는 모델의 스팸 분류 정확도를 최대화하는 것이지만 분류 정확도는 미분 가능한 함수가 아닙니다.\n",
    "- 따라서 분류 정확도를 최대화하는 대신, 크로스 엔트로피 손실을 최소화합니다 (무료 강의 [Introduction to Deep Learning](https://sebastianraschka.com/blog/2021/dl-course.html#l08-multinomial-logistic-regression--softmax-regression) 8강에서 이 주제에 대해 자세히 알아볼 수 있습니다)\n",
    "\n",
    "- `calc_loss_batch` 함수는 5장과 동일하지만 모든 토큰 `model(input_batch)` 대신 마지막 토큰 `model(input_batch)[:, -1, :]`을 최적화하는 데에만 관심이 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1e9547-806c-41a9-8aba-3b2822baabe4",
   "metadata": {
    "id": "2f1e9547-806c-41a9-8aba-3b2822baabe4"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    \"\"\"\n",
    "    배치 단위로 모델의 손실(Loss)을 계산하는 함수\n",
    "    \"\"\"\n",
    "    # 1. 데이터를 연산 장치(GPU 또는 CPU)로 이동\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "    # 2. 모델 예측 (Forward Pass)\n",
    "    # logits shape: [배치 크기, 문장 길이, 단어 집합 크기(Vocab Size)]\n",
    "    logits = model(input_batch)\n",
    "\n",
    "    # 3. 손실 계산 방식 분기 (중요!)\n",
    "    # target_batch의 차원 수(dim)를 확인하여 작업 종류를 구분합니다.\n",
    "    \n",
    "    # CASE A: 단순 분류 (Sequence Classification)\n",
    "    # 정답(target)이 [0, 1, 0] 처럼 1차원인 경우 (각 문장마다 정답이 하나)\n",
    "    if target_batch.dim() == 1:\n",
    "        # 문장의 '가장 마지막 토큰'의 예측값(logits[:, -1, :])만 사용하여\n",
    "        # 정답과 비교해 손실을 계산합니다.\n",
    "        loss = torch.nn.functional.cross_entropy(logits[:, -1, :], target_batch)\n",
    "        \n",
    "    # CASE B: 언어 모델링 (Language Modeling / Next Token Prediction)\n",
    "    # 정답이 [[10, 20], [30, 40]] 처럼 2차원인 경우 (모든 단어 위치마다 정답이 존재)\n",
    "    else:\n",
    "        # 모델 출력과 정답을 일렬로 쭉 폅니다(Flatten).\n",
    "        # logits: [배치*길이, 단어집합크기], target: [배치*길이]\n",
    "        # 이렇게 모양을 맞춰줘야 CrossEntropy가 모든 단어에 대해 오차를 평균 낼 수 있습니다.\n",
    "        loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a013aab9-f854-4866-ad55-5b8350adb50a",
   "metadata": {
    "id": "a013aab9-f854-4866-ad55-5b8350adb50a"
   },
   "source": [
    "`calc_loss_loader`는 5장과 완전히 동일합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7b83e10-5720-45e7-ac5e-369417ca846b",
   "metadata": {
    "id": "b7b83e10-5720-45e7-ac5e-369417ca846b"
   },
   "outputs": [],
   "source": [
    "# 5장과 동일\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # num_batches가 데이터 로더의 배치 수를 초과하는 경우\n",
    "        # 데이터 로더의 총 배치 수와 일치하도록 배치 수를 줄입니다.\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56826ecd-6e74-40e6-b772-d3541e585067",
   "metadata": {
    "id": "56826ecd-6e74-40e6-b772-d3541e585067"
   },
   "source": [
    "- `calc_closs_loader`를 사용하여 훈련을 시작하기 전 초기 훈련, 검증 및 테스트 세트 손실을 계산합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f6f00e53-5beb-4e64-b147-f26fd481c6ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6f00e53-5beb-4e64-b147-f26fd481c6ff",
    "outputId": "e08fb71b-c0ad-422d-ce01-955b40430558"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 손실: 2.453\n",
      "검증 손실: 2.583\n",
      "테스트 손실: 2.322\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # 효율성을 위해 그레이디언트 추적을 비활성화합니다. 아직 훈련하지 않기 때문입니다.\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "\n",
    "print(f\"훈련 손실: {train_loss:.3f}\")\n",
    "print(f\"검증 손실: {val_loss:.3f}\")\n",
    "print(f\"테스트 손실: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04b980b-e583-4f62-84a0-4edafaf99d5d",
   "metadata": {
    "id": "e04b980b-e583-4f62-84a0-4edafaf99d5d"
   },
   "source": [
    "- 다음 섹션에서는 손실 값과 결과적으로 분류 정확도를 개선하기 위해 모델을 훈련합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456ae0fd-6261-42b4-ab6a-d24289953083",
   "metadata": {
    "id": "456ae0fd-6261-42b4-ab6a-d24289953083"
   },
   "source": [
    "## 6.7 지도 학습 데이터로 모델 미세 튜닝하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9b099b-0829-4f72-8a2b-4363e3497026",
   "metadata": {
    "id": "6a9b099b-0829-4f72-8a2b-4363e3497026"
   },
   "source": [
    "- 이 절에서는 모델의 분류 정확도를 향상시키기 위한 훈련 함수를 정의하고 사용합니다.\n",
    "- 아래 `train_classifier_simple` 함수는 5장에서 모델 사전 훈련에 사용했던 `train_model_simple` 함수와 거의 동일합니다.\n",
    "- 단 두 가지 차이점은 다음과 같습니다.\n",
    "  1. 토큰 수 대신 학습된 샘플 수(`examples_seen`)를 추적합니다.\n",
    "  2. 각 에포크 다음에 샘플 텍스트를 출력하는 대신 정확도를 계산합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979b6222-1dc2-4530-9d01-b6b04fe3de12",
   "metadata": {
    "id": "979b6222-1dc2-4530-9d01-b6b04fe3de12"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch06_compressed/15.webp\" width=600px>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Csbr60to50FL",
   "metadata": {
    "id": "Csbr60to50FL"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 5장의 `train_model_simple`과 구조가 거의 같지만, 분류(Classification)를 위해 일부 수정된 함수\n",
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                            eval_freq, eval_iter):\n",
    "    \"\"\"\n",
    "    모델을 학습시키고, 주기적으로 검증 데이터로 성능을 평가하는 함수\n",
    "    \n",
    "    Args:\n",
    "        model: 학습할 파이토치 모델\n",
    "        train_loader: 학습 데이터 공급자 (DataLoader)\n",
    "        val_loader: 검증 데이터 공급자 (DataLoader)\n",
    "        optimizer: 가중치를 업데이트하는 최적화 도구 (예: AdamW)\n",
    "        device: 학습을 진행할 장치 (CPU or GPU)\n",
    "        num_epochs: 전체 데이터를 몇 번 반복해서 학습할지\n",
    "        eval_freq: 몇 번의 스텝(배치)마다 손실을 출력할지 설정\n",
    "        eval_iter: 평가 시 몇 개의 배치만 사용할지 (속도를 위해 일부만 사용 가능)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. 기록용 리스트 초기화 (나중에 그래프를 그리기 위해 저장)\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    # 2. 메인 학습 루프 (에포크 단위 반복)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # 중요: 모델을 '학습 모드'로 전환 (Dropout 등이 켜짐)\n",
    "\n",
    "        # 3. 배치 단위 반복 (데이터 로더에서 배치를 하나씩 꺼냄)\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # (a) 기울기 초기화: 이전 배치의 계산 찌꺼기 제거\n",
    "            \n",
    "            # (b) 손실(Loss) 계산: 모델이 예측하고, 정답과 비교하여 오차 계산\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            \n",
    "            # (c) 역전파(Backpropagation): 오차를 줄이는 방향(기울기) 계산\n",
    "            loss.backward() \n",
    "            \n",
    "            # (d) 가중치 업데이트: 계산된 방향으로 모델 파라미터 수정\n",
    "            optimizer.step() \n",
    "\n",
    "            # 진행 상황 추적\n",
    "            examples_seen += input_batch.shape[0] # 몇 개의 데이터를 봤는지 누적\n",
    "            global_step += 1\n",
    "\n",
    "            # 4. 중간 평가 단계 (eval_freq 스텝마다 실행)\n",
    "            # 학습 중간중간에 손실(Loss)이 잘 줄어들고 있는지 확인\n",
    "            if global_step % eval_freq == 0:\n",
    "                # evaluate_model 함수를 호출하여 현재 상태의 손실 계산\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                \n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                \n",
    "                print(f\"에포크 {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"훈련 손실 {train_loss:.3f}, 검증 손실 {val_loss:.3f}\")\n",
    "\n",
    "        # 5. 에포크 종료 후 정확도(Accuracy) 계산\n",
    "        # 손실(Loss)만으로는 직관적이지 않으므로, '몇 퍼센트 맞췄는지' 확인\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        \n",
    "        print(f\"훈련 정확도: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"검증 정확도: {val_accuracy*100:.2f}%\")\n",
    "        \n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9624cb30-3e3a-45be-b006-c00475b58ae8",
   "metadata": {
    "id": "9624cb30-3e3a-45be-b006-c00475b58ae8"
   },
   "source": [
    "- `evaluate_model` 함수는 `train_classifier_simple` 에서 사용되며 5장에서 사용한 것과 동일합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc7bc04-6aa6-4516-a147-460e2f466eab",
   "metadata": {
    "id": "bcc7bc04-6aa6-4516-a147-460e2f466eab"
   },
   "outputs": [],
   "source": [
    "# 5장과 동일\n",
    "# 모델의 손실을 평가하는 헬퍼 함수\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()  # 중요: 모델을 '평가 모드'로 전환 (Dropout 등이 꺼짐)\n",
    "    \n",
    "    # 평가 시에는 기울기 계산을 하지 않음 (메모리 절약, 속도 향상)\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    \n",
    "    model.train() # 평가가 끝나면 다시 '학습 모드'로 복구\n",
    "    \n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e807bfe9-364d-46b2-9e25-3b000c3ef6f9",
   "metadata": {
    "id": "e807bfe9-364d-46b2-9e25-3b000c3ef6f9"
   },
   "source": [
    "- M3 맥북 에어 노트북 컴퓨터에서는 훈련 시간이 약 5분 정도 소요되며 V100 또는 A100 GPU에서는 30초 미만이 소요됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "X7kU3aAj7vTJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X7kU3aAj7vTJ",
    "outputId": "2785a778-4dd8-442f-df56-fc2640b6a8a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크 1 (Step 000000): 훈련 손실 2.153, 검증 손실 2.392\n",
      "에포크 1 (Step 000050): 훈련 손실 0.617, 검증 손실 0.637\n",
      "에포크 1 (Step 000100): 훈련 손실 0.523, 검증 손실 0.557\n",
      "훈련 정확도: 70.00% | 검증 정확도: 72.50%\n",
      "에포크 2 (Step 000150): 훈련 손실 0.561, 검증 손실 0.489\n",
      "에포크 2 (Step 000200): 훈련 손실 0.419, 검증 손실 0.397\n",
      "에포크 2 (Step 000250): 훈련 손실 0.409, 검증 손실 0.353\n",
      "훈련 정확도: 82.50% | 검증 정확도: 85.00%\n",
      "에포크 3 (Step 000300): 훈련 손실 0.333, 검증 손실 0.320\n",
      "에포크 3 (Step 000350): 훈련 손실 0.340, 검증 손실 0.306\n",
      "훈련 정확도: 90.00% | 검증 정확도: 90.00%\n",
      "에포크 4 (Step 000400): 훈련 손실 0.136, 검증 손실 0.200\n",
      "에포크 4 (Step 000450): 훈련 손실 0.153, 검증 손실 0.132\n",
      "에포크 4 (Step 000500): 훈련 손실 0.222, 검증 손실 0.137\n",
      "훈련 정확도: 100.00% | 검증 정확도: 97.50%\n",
      "에포크 5 (Step 000550): 훈련 손실 0.207, 검증 손실 0.143\n",
      "에포크 5 (Step 000600): 훈련 손실 0.083, 검증 손실 0.074\n",
      "훈련 정확도: 100.00% | 검증 정확도: 97.50%\n",
      "훈련 소요 시간: 0.49분\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"훈련 소요 시간: {execution_time_minutes:.2f}분\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1261bf90-3ce7-4591-895a-044a05538f30",
   "metadata": {
    "id": "1261bf90-3ce7-4591-895a-044a05538f30"
   },
   "source": [
    "- 5장과 유사하게, 맷플롯립을 사용하여 훈련 및 검증 세트에 대한 손실 함수를 그립니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cURgnDqdCeka",
   "metadata": {
    "id": "cURgnDqdCeka"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # 훈련 및 검증 손실을 에포크에 따라 그립니다.\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    # 처리한 샘플 수를 위해 두 번째 x축을 만듭니다.\n",
    "    ax2 = ax1.twiny()  # 동일한 y축을 공유하는 두 번째 x축을 만듭니다.\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)  # 눈금 정렬을 위한 보이지 않는 그래프\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()  # 공간을 확보하기 위해 레이아웃을 조정합니다.\n",
    "    plt.savefig(f\"outputs/{label}-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "OIqRt466DiGk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "OIqRt466DiGk",
    "outputId": "1e8172fe-1ab5-4fe5-a230-2d366edd9f08"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd28174-1836-44ba-b6c0-7e0be774fadc",
   "metadata": {
    "id": "dbd28174-1836-44ba-b6c0-7e0be774fadc"
   },
   "source": [
    "- 기울기가 아래쪽으로 향하고 있으므로 모델이 잘 학습하고 있음을 알 수 있습니다.\n",
    "- 또한, 훈련 손실과 검증 손실이 매우 가깝다는 사실은 모델이 훈련 데이터에 과대적합되는 경향이 없음을 나타냅니다.\n",
    "- 마찬가지로, 아래에서 정확도를 그래프로 표시할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "yz8BIsaF0TUo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "yz8BIsaF0TUo",
    "outputId": "c7c1f0ea-13e3-4e3b-f59a-637d0cc89bc9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aba699-21bc-42de-a69c-99f370bb0363",
   "metadata": {
    "id": "90aba699-21bc-42de-a69c-99f370bb0363"
   },
   "source": [
    "- 위의 정확도 그래프를 기반으로 에포크 4와 5 이후 모델이 비교적 높은 훈련 및 검증 정확도를 달성했음을 알 수 있습니다.\n",
    "- 하지만 이전에 훈련 함수에서 `eval_iter=5`를 지정했던 것을 기억해야 합니다. 이는 훈련 및 검증 세트의 일부만 사용해 성능을 추정했음을 의미합니다.\n",
    "- 아래와 같이 전체 데이터셋에 대한 훈련, 검증 및 테스트 세트 성능을 계산할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "UHWaJFrjY0zW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UHWaJFrjY0zW",
    "outputId": "c9022a93-8fe5-443a-8106-ab8fc727e008"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 정확도: 97.21%\n",
      "검증 정확도: 97.32%\n",
      "테스트 정확도: 95.67%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"훈련 정확도: {train_accuracy*100:.2f}%\")\n",
    "print(f\"검증 정확도: {val_accuracy*100:.2f}%\")\n",
    "print(f\"테스트 정확도: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6882649f-dc7b-401f-84d2-024ff79c74a1",
   "metadata": {
    "id": "6882649f-dc7b-401f-84d2-024ff79c74a1"
   },
   "source": [
    "- 훈련 세트와 검증 세트의 성능이 거의 동일한 것을 확인할 수 있습니다.\n",
    "- 그러나 테스트 세트 성능이 약간 낮은 것을 보면 모델이 훈련 데이터에 대해 아주 작은 정도로 과적합되었음을 알 수 있으며, 학습률과 같은 일부 하이퍼파라미터를 조정하는 데 사용된 검증 데이터에도 과적합되었음을 알 수 있습니다.\n",
    "- 하지만 이는 정상적인 현상이며, 모델의 드롭아웃 비율(`drop_rate`)이나 옵티마이저 설정의 `weight_decay`를 높여 이러한 차이를 줄일 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74d9ad7-3ec1-450e-8c9f-4fc46d3d5bb0",
   "metadata": {
    "id": "a74d9ad7-3ec1-450e-8c9f-4fc46d3d5bb0"
   },
   "source": [
    "## 6.8 LLM을 스팸 분류기로 사용하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ebcfa2-479e-408b-9cf0-7421f6144855",
   "metadata": {
    "id": "72ebcfa2-479e-408b-9cf0-7421f6144855"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch06_compressed/18.webp\" width=700px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5408e6-83e4-4e5a-8503-c2fba6073f31",
   "metadata": {
    "id": "fd5408e6-83e4-4e5a-8503-c2fba6073f31"
   },
   "source": [
    "- 마지막으로, 미세 튜닝된 GPT 모델을 실제로 사용해 보겠습니다.\n",
    "- 아래 `classify_review` 함수는 이전에 구현한 `SpamDataset`과 유사한 데이터 전처리 단계를 구현합니다.\n",
    "- 그런 다음, 이 함수는 모델에서 예측된 정수 클래스 레이블을 반환하고 해당 클래스 이름을 반환합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aHdn6xvL-IW5",
   "metadata": {
    "id": "aHdn6xvL-IW5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    \"\"\"\n",
    "    단일 텍스트(리뷰)를 입력받아 스팸 여부를 분류하는 함수\n",
    "    \"\"\"\n",
    "    # 1. 평가 모드 설정\n",
    "    # 학습이 아니므로 Dropout 등을 비활성화하여 일관된 결과를 얻습니다.\n",
    "    model.eval()\n",
    "\n",
    "    # 2. 텍스트 토큰화 (Encoding)\n",
    "    # 문자열(text)을 모델이 이해하는 정수 리스트(input_ids)로 변환합니다.\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    \n",
    "    # 모델이 물리적으로 처리할 수 있는 최대 길이 확인 (예: GPT-2는 보통 1024)\n",
    "    supported_context_length = model.pos_emb.weight.shape[0]\n",
    "\n",
    "    # 3. 시퀀스 자르기 (Truncation)\n",
    "    # 입력이 너무 길면 모델이 처리할 수 없으므로 잘라냅니다.\n",
    "    # 사용자가 설정한 max_length와 모델 한계치 중 더 작은 값으로 길이를 제한합니다.\n",
    "    # 주의: 아래 코드는 max_length가 None일 경우 에러가 날 수 있으므로, assert문으로 방어합니다.\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "    \n",
    "    # (안전장치) max_length가 올바르게 설정되었는지 확인\n",
    "    assert max_length is not None, (\n",
    "        \"max_length가 지정되지 않았습니다. 모델의 최대 문맥 길이를 사용하려면 \"\n",
    "        \"max_length=model.pos_emb.weight.shape[0]로 지정하세요.\"\n",
    "    )\n",
    "    assert max_length <= supported_context_length, (\n",
    "        f\"max_length({max_length})가 모델이 지원하는 문맥 길이({supported_context_length})를 초과했습니다.\"\n",
    "    )\n",
    "    \n",
    "    # 4. 패딩 (Padding)\n",
    "    # 설정한 max_length보다 문장이 짧을 경우, 남은 뒷부분을 pad_token_id로 채웁니다.\n",
    "    # 모델은 고정된 길이의 입력을 선호하기 때문입니다.\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    \n",
    "    # 5. 텐서 변환 및 배치 차원 추가 (매우 중요!)\n",
    "    # 현재 input_ids는 [길이] 형태의 1차원 리스트입니다.\n",
    "    # 하지만 모델은 [배치 크기, 길이] 형태의 2차원 입력을 기대합니다.\n",
    "    # unsqueeze(0)을 통해 [1, 길이] 형태로 차원을 하나 늘려줍니다. (가짜 배치 생성)\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) \n",
    "\n",
    "    # 6. 모델 추론 (Inference)\n",
    "    with torch.no_grad(): # 기울기 계산 끄기 (메모리 절약)\n",
    "        # 모델에 입력을 넣어 출력(Logits)을 얻습니다.\n",
    "        # [:, -1, :] : (모든 배치, 마지막 토큰, 모든 클래스) -> 분류를 위해 마지막 토큰만 사용\n",
    "        logits = model(input_tensor)[:, -1, :]\n",
    "    \n",
    "    # 7. 결과 해석\n",
    "    # argmax: 확률값 중 가장 큰 값의 인덱스(0 또는 1)를 뽑습니다.\n",
    "    # item(): 텐서 값을 파이썬 정수(int)로 변환합니다.\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # 8. 사람이 읽을 수 있는 결과 반환\n",
    "    # 1이면 \"스팸\", 0이면 \"스팸아님\" 리턴\n",
    "    return \"스팸\" if predicted_label == 1 else \"스팸아님\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29682d8-a899-4d9b-b973-f8d5ec68172c",
   "metadata": {
    "id": "f29682d8-a899-4d9b-b973-f8d5ec68172c"
   },
   "source": [
    "- 몇 개의 샘플로 시험해 보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "apU_pf51AWSV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "apU_pf51AWSV",
    "outputId": "0fee6062-1569-4873-9da9-5eea3f023f56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스팸\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1g5VTOo_Ajs5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1g5VTOo_Ajs5",
    "outputId": "1c341d60-1b9d-489b-cd00-7afe547e9389"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스팸아님\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf736e39-0d47-40c1-8d18-1f716cf7a81e",
   "metadata": {
    "id": "bf736e39-0d47-40c1-8d18-1f716cf7a81e"
   },
   "source": [
    "- 마지막으로, 나중에 다시 훈련하지 않고 모델을 재사용할 수 있도록 모델을 저장합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "mYnX-gI1CfQY",
   "metadata": {
    "id": "mYnX-gI1CfQY"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"outputs/review_classifier.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba78cf7c-6b80-4f71-a50e-3ccc73839af6",
   "metadata": {
    "id": "ba78cf7c-6b80-4f71-a50e-3ccc73839af6"
   },
   "source": [
    "- 그런 다음 새 세션에서 다음과 같이 모델을 로드할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cc4e68a5-d492-493b-87ef-45c475f353f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cc4e68a5-d492-493b-87ef-45c475f353f5",
    "outputId": "badf32ed-f908-4a02-c122-b86d3ac9953b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch.load(\"outputs/review_classifier.pth\", map_location=device, weights_only=True)\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b70ac71-234f-4eeb-b33d-c62726d50cd4",
   "metadata": {
    "id": "5b70ac71-234f-4eeb-b33d-c62726d50cd4"
   },
   "source": [
    "## 요약\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafdc910-d616-47ab-aa85-f90c6e7ed80e",
   "metadata": {
    "id": "dafdc910-d616-47ab-aa85-f90c6e7ed80e"
   },
   "source": [
    "- 연습 문제 풀이는 [./exercise-solutions.ipynb](./exercise-solutions.ipynb)에서 찾을 수 있습니다.\n",
    "- 또한 관심 있는 독자는 [부록 E](../../appendix-E)에서 LoRA를 사용한 파라미터 효율적인 훈련에 대한 소개를 찾을 수 있습니다.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "llm-hands-on",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
