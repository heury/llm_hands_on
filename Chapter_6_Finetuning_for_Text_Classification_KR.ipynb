{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d75117f",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/rickiepark/llm-from-scratch/blob/main/ch06/01_main-chapter-code/ch06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c024bfa4-1a7a-4751-b5a1-827225a3478b",
   "metadata": {
    "id": "c024bfa4-1a7a-4751-b5a1-827225a3478b"
   },
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<font size=\"2\">\n",
    "세바스찬 라시카(Sebastian Raschka)가 쓴 <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a>의 번역서 <br><<b><a href=\"<a href=\"http://tensorflow.blog/llm-from-scratch\">밑바닥부터 만들면서 배우는 LLM</a></b>>의 예제 코드입니다.<br>\n",
    "<br>코드 저장소: <a href=\"https://github.com/rickiepark/llm-from-scratch\">https://github.com/rickiepark/llm-from-scratch</a>\n",
    "</font>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<a href=\"http://tensorflow.blog/llm-from-scratch\"><img src=\"https://tensorflowkorea.wordpress.com/wp-content/uploads/2025/09/ebb091ebb094eb8ba5llm_ebb3b8ecb185_ec959eeba9b4.jpg\" width=\"100px\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfabadb8-5935-45ff-b39c-db7a29012129",
   "metadata": {
    "id": "bfabadb8-5935-45ff-b39c-db7a29012129"
   },
   "source": [
    "# 챕터 6: 텍스트 분류를 위한 미세 튜닝\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
    "outputId": "92210e7a-246a-40c5-d0fa-edbee611fc44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib 버전: 3.10.8\n",
      "numpy 버전: 2.3.5\n",
      "tiktoken 버전: 0.12.0\n",
      "torch 버전: 2.9.1+cu126\n",
      "pandas 버전: 2.3.3\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\",  # 그래프 라이브러리\n",
    "        \"numpy\",       # 파이토치와 텐서플로의 종속성\n",
    "        \"tiktoken\",    # 토크나이저\n",
    "        \"torch\",       # 딥러닝 라이브러리\n",
    "        # \"tensorflow\",  # OpenAI의 사전 훈련된 가중치를 위해서\n",
    "        \"pandas\"       # 데이터셋 로딩을 위해\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} 버전: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a445828a-ff10-4efa-9f60-a2e2aed4c87d",
   "metadata": {
    "id": "a445828a-ff10-4efa-9f60-a2e2aed4c87d"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch06_compressed/01.webp\" width=800px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a84cf35-b37f-4c15-8972-dfafc9fadc1c",
   "metadata": {
    "id": "3a84cf35-b37f-4c15-8972-dfafc9fadc1c"
   },
   "source": [
    "## 6.1 여러 가지 미세 튜닝 방법\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac45579d-d485-47dc-829e-43be7f4db57b",
   "metadata": {
    "id": "ac45579d-d485-47dc-829e-43be7f4db57b"
   },
   "source": [
    "- 가장 일반적인 언어 모델 미세 튜닝 방법은 지시 미세 조정 및 분류 미세 튜닝입니다.\n",
    "- 아래에 나타난 지시 미세 튜닝은 다음 장의 주제입니다.\n",
    "- pretrained model에서 finetuning하는 것이 효과적\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c29ef42-46d9-43d4-8bb4-94974e1665e4",
   "metadata": {
    "id": "6c29ef42-46d9-43d4-8bb4-94974e1665e4"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch06_compressed/02.webp\" width=700px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f60321-95b8-46a9-97bf-1d07fda2c3dd",
   "metadata": {
    "id": "a7f60321-95b8-46a9-97bf-1d07fda2c3dd"
   },
   "source": [
    "- 이 장의 주제인 분류 미세 튜닝(Classification finetuning)은 머신 러닝에 대한 배경 지식이 있다면 이미 익숙할 수 있는 절차입니다. 예를 들어, 손글씨 숫자를 분류하기 위해 합성곱 신경망을 훈련하는 것과 유사합니다.\n",
    "- 분류 미세 튜닝에서는 모델이 출력할 수 있는 특정 개수의 클래스 레이블(예: \"스팸\" 및 \"스팸아님\")이 있습니다.\n",
    "- 분류 미세 튜닝된 모델은 훈련 중에 본 클래스(예: \"스팸\" 또는 \"스팸아님\")만 예측할 수 있는 반면, 지시 미세 튜닝된 모델은 일반적으로 많은 작업을 수행할 수 있습니다.\n",
    "- 분류 미세 튜닝된 모델을 매우 특수화된 모델로 생각할 수 있습니다. 실제로는 다양한 작업에서 잘 수행되는 일반 모델보다 특수 모델을 만드는 것이 훨씬 쉽습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b37a0c4-0bb1-4061-b1fe-eaa4416d52c3",
   "metadata": {
    "id": "0b37a0c4-0bb1-4061-b1fe-eaa4416d52c3"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch06_compressed/03.webp\" width=600px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf",
   "metadata": {
    "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf"
   },
   "source": [
    "## 6.2 데이터셋 준비\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f628975-d2e8-4f7f-ab38-92bb868b7067",
   "metadata": {
    "id": "5f628975-d2e8-4f7f-ab38-92bb868b7067"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch06_compressed/04.webp\" width=700px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbd459f-63fa-4d8c-8499-e23103156c7d",
   "metadata": {
    "id": "9fbd459f-63fa-4d8c-8499-e23103156c7d"
   },
   "source": [
    "- 이 섹션에서는 분류 미세 튜닝에 사용할 데이터셋을 준비합니다.\n",
    "- 스팸 및 스팸아님 텍스트 메시지로 구성된 데이터셋을 분류하기 위해 LLM을 미세 튜닝합니다.\n",
    "- 먼저 데이터셋을 다운로드하고 압축을 풉니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
    "outputId": "8102ff6b-68a4-4d70-90ce-9a835722d953"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datas\\sms_spam_collection\\SMSSpamCollection.tsv가 이미 있어 다운로드 및 압축 해제를 건너뜁니다.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"datas/sms_spam_collection.zip\"\n",
    "extracted_path = \"datas/sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path}가 이미 있어 다운로드 및 압축 해제를 건너뜁니다.\")\n",
    "        return\n",
    "\n",
    "    # 파일을 다운로드 합니다.\n",
    "    response = requests.get(url, stream=True, timeout=60)\n",
    "    response.raise_for_status()\n",
    "    with open(zip_path, \"wb\") as out_file:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            if chunk:\n",
    "                out_file.write(chunk)\n",
    "\n",
    "    # 파일 압축을 풉니다.\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    # .tsv 파일 확장자를 추가합니다.\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"파일이 다운로드되어 {data_file_path}에 저장되었습니다.\")\n",
    "\n",
    "try:\n",
    "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
    "except (requests.exceptions.RequestException, TimeoutError) as e:\n",
    "    print(f\"기본 URL 실패: {e}. 백업 URL을 시도합니다...\")\n",
    "    url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/sms%2Bspam%2Bcollection.zip\"\n",
    "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aac2d19-06d0-4005-916b-0bd4b1ee50d1",
   "metadata": {
    "id": "6aac2d19-06d0-4005-916b-0bd4b1ee50d1"
   },
   "source": [
    "- 데이터셋은 탭으로 구분된 텍스트 파일로 저장되며, Pandas DataFrame으로 로드할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da0ed4da-ac31-4e4d-8bdd-2153be4656a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 440
    },
    "id": "da0ed4da-ac31-4e4d-8bdd-2153be4656a4",
    "outputId": "83060795-1163-4d18-89a7-76a5ced320c3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b6e631-4f0b-4aab-82b9-8898e6663109",
   "metadata": {
    "id": "e7b6e631-4f0b-4aab-82b9-8898e6663109"
   },
   "source": [
    "- 클래스 분포를 확인해 보면, 데이터에 \"스팸\"보다 \"햄\"(즉, \"스팸아님\")이 훨씬 더 많이 포함되어 있음을 알 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "495a5280-9d7c-41d4-9719-64ab99056d4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "495a5280-9d7c-41d4-9719-64ab99056d4c",
    "outputId": "1e1c04f1-6999-4eac-9fda-3d95409a02a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f773f054-0bdc-4aad-bbf6-397621bf63db",
   "metadata": {
    "id": "f773f054-0bdc-4aad-bbf6-397621bf63db"
   },
   "source": [
    "- 간단하게 하기 위해, 그리고 교육 목적으로 작은 데이터셋을 선호하기 때문에 (LLM을 더 빠르게 미세 튜닝할 수 있음), 각 클래스마다 747개의 샘플이 포함되도록 데이터 세트를 서브샘플링(언더샘플링)합니다.\n",
    "- (언더샘플링 외에도 클래스 불균형을 처리하는 여러 가지 다른 방법이 있지만 LLM에 관한 책의 범위를 벗어납니다. [`imbalanced-learn` 사용자 가이드](https://imbalanced-learn.org/stable/user_guide.html)에서 예제와 자세한 정보를 찾을 수 있습니다.)\n",
    "- 데이터가 편향되어 있으면\n",
    "  - 다수 클래스로 편향이 됨\n",
    "  - 정확도가 높지만 스팸을탐ㅌ지하지 못할 가능성이 있음\n",
    "  - 스팸을 노이지로 취급해 무시해 버릴 가능성이 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7be4a0a2-9704-4a96-b38f-240339818688",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7be4a0a2-9704-4a96-b38f-240339818688",
    "outputId": "32448d26-f31d-4158-9f99-58d044a1e90e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_balanced_dataset(df):\n",
    "\n",
    "    # \"스팸\" 샘플 개수 세기\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "\n",
    "    # \"스팸\" 샘플 개수와 일치하도록 \"햄\" 샘플을 무작위로 샘플링\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
    "\n",
    "    # \"햄\"과 \"스팸\"을 합침\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
    "\n",
    "    return balanced_df\n",
    "\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fd2f5a-06d8-4d30-a2e3-230b86c559d6",
   "metadata": {
    "id": "d3fd2f5a-06d8-4d30-a2e3-230b86c559d6"
   },
   "source": [
    "- 다음으로, 문자열 클래스 레이블 \"ham\"과 \"spam\"을 정수 클래스 레이블 0과 1로 변경합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1b10c3d-5d57-42d0-8de8-cf80a06f5ffd",
   "metadata": {
    "id": "c1b10c3d-5d57-42d0-8de8-cf80a06f5ffd"
   },
   "outputs": [],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6f7f062-ef4e-4020-8275-71990cab4414",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 440
    },
    "id": "e6f7f062-ef4e-4020-8275-71990cab4414",
    "outputId": "c8d42c61-bae9-40f6-8e6e-7effa919a67f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>0</td>\n",
       "      <td>Awww dat is sweet! We can think of something t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>0</td>\n",
       "      <td>Just got to  &amp;lt;#&amp;gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4831</th>\n",
       "      <td>0</td>\n",
       "      <td>The word \"Checkmate\" in chess comes from the P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>0</td>\n",
       "      <td>This is wishing you a great day. Moji told me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5440</th>\n",
       "      <td>0</td>\n",
       "      <td>Thank you. do you generally date the brothas?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5537</th>\n",
       "      <td>1</td>\n",
       "      <td>Want explicit SEX in 30 secs? Ring 02073162414...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5540</th>\n",
       "      <td>1</td>\n",
       "      <td>ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>1</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>1</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label                                               Text\n",
       "4307      0  Awww dat is sweet! We can think of something t...\n",
       "4138      0                             Just got to  &lt;#&gt;\n",
       "4831      0  The word \"Checkmate\" in chess comes from the P...\n",
       "4461      0  This is wishing you a great day. Moji told me ...\n",
       "5440      0      Thank you. do you generally date the brothas?\n",
       "...     ...                                                ...\n",
       "5537      1  Want explicit SEX in 30 secs? Ring 02073162414...\n",
       "5540      1  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
       "5547      1  Had your contract mobile 11 Mnths? Latest Moto...\n",
       "5566      1  REMINDER FROM O2: To get 2.50 pounds free call...\n",
       "5567      1  This is the 2nd time we have tried 2 contact u...\n",
       "\n",
       "[1494 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5715e685-35b4-4b45-a86c-8a8694de9d6f",
   "metadata": {
    "id": "5715e685-35b4-4b45-a86c-8a8694de9d6f"
   },
   "source": [
    "- 데이터셋을 훈련 세트, 검증 세트, 테스트 세트로 무작위 분할하는 함수를 정의해 보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "uQl0Psdmx15D",
   "metadata": {
    "id": "uQl0Psdmx15D"
   },
   "outputs": [],
   "source": [
    "def random_split(df, train_frac, validation_frac):\n",
    "    # 데이터프레임 전체 섞기, frac=1이 전체를 의미\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "    # 분할 인덱스 계산\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    # 데이터프레임 분할\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "# 테스트 크기는 나머지에 해당하는 0.2입니다.\n",
    "\n",
    "train_df.to_csv(\"datas/train.csv\", index=None)\n",
    "validation_df.to_csv(\"datas/validation.csv\", index=None)\n",
    "test_df.to_csv(\"datas/test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d7a0c5-1d5f-458a-b685-3f49520b0094",
   "metadata": {
    "id": "a8d7a0c5-1d5f-458a-b685-3f49520b0094"
   },
   "source": [
    "## 6.3 데이터 로더 만들기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7126108a-75e7-4862-b0fb-cbf59a18bb6c",
   "metadata": {
    "id": "7126108a-75e7-4862-b0fb-cbf59a18bb6c"
   },
   "source": [
    "- 텍스트 메시지의 길이가 다르다는 점에 유의하세요. 배치에 여러 훈련 샘플을 결합하려면 다음 중 하나를 수행해야 합니다.\n",
    "  1. 데이터셋 또는 배치에서 가장 짧은 메시지 길이로 모든 메시지를 자릅니다.\n",
    "  2. 데이터셋 또는 배치에서 가장 긴 메시지 길이로 모든 메시지에 패딩을 추가합니다.\n",
    "\n",
    "- 옵션 2를 선택하고 데이터셋에서 가장 긴 메시지에 맞춰 모든 메시지에 패딩을 추가합니다.\n",
    "- 이를 위해 2장에서 설명한 대로 `<|endoftext|>`를 패딩 토큰으로 사용합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0829f33f-1428-4f22-9886-7fee633b3666",
   "metadata": {
    "id": "0829f33f-1428-4f22-9886-7fee633b3666"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch06_compressed/06.webp\" width=800px>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
    "outputId": "8991d92a-7bbe-4b9d-aca5-cd8f51331654"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f582ff-68bf-450e-bd87-5fb61afe431c",
   "metadata": {
    "id": "04f582ff-68bf-450e-bd87-5fb61afe431c"
   },
   "source": [
    "- `SpamDataset` 클래스는 학습 데이터셋에서 가장 긴 시퀀스를 식별하고 다른 시퀀스에 패딩 토큰을 추가하여 해당 길이에 맞춥니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7791b52-af18-4ac4-afa9-b921068e383e",
   "metadata": {
    "id": "d7791b52-af18-4ac4-afa9-b921068e383e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        # 텍스트 토큰화\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            # max_length보다 긴 시퀀스 자르기\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        # 가장 긴 시퀀스에 맞춰 패딩하기\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length\n",
    "        # 참고: 이 메서드를 구현하는 더 파이썬적인 버전은\n",
    "        # 다음과 같으며, 다음 장에서도 사용됩니다.\n",
    "        # return max(len(encoded_text) for encoded_text in self.encoded_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "uzj85f8ou82h",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uzj85f8ou82h",
    "outputId": "f34653cf-2371-4d5c-dc85-249b327ab8bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"datas/train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bdd932-97eb-4b88-9cf9-d766ea4c3a60",
   "metadata": {
    "id": "15bdd932-97eb-4b88-9cf9-d766ea4c3a60"
   },
   "source": [
    "- 또한 검증 세트와 테스트 세트를 가장 긴 훈련 시퀀스에 맞춰 패딩합니다.\n",
    "- 검증 세트와 테스트 세트 샘플 중 가장 긴 훈련 세트 샘플보다 긴 샘플은 `SpamDataset` 코드에서 `encoded_text[:self.max_length]`를 통해 잘린다는 점에 유의하세요.\n",
    "- 이 동작은 완전히 선택 사항이며, 검증 세트와 테스트 세트의 경우 모두 `max_length=None`으로 설정해도 잘 작동합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb0c502d-a75e-4248-8ea0-196e2b00c61e",
   "metadata": {
    "id": "bb0c502d-a75e-4248-8ea0-196e2b00c61e"
   },
   "outputs": [],
   "source": [
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"datas/validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"datas/test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20170d89-85a0-4844-9887-832f5d23432a",
   "metadata": {
    "id": "20170d89-85a0-4844-9887-832f5d23432a"
   },
   "source": [
    "- 다음으로, 데이터셋을 사용하여 데이터 로더를 만듭니다. 이는 이전 장에서 데이터 로더를 생성하는 것과 유사합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bcc349-205f-48f8-9655-95ff21f5e72f",
   "metadata": {
    "id": "64bcc349-205f-48f8-9655-95ff21f5e72f"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch06_compressed/07.webp\" width=700px>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542",
   "metadata": {
    "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True, #학습할 때는 shuffle가 중요\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True, #미지막을 버릴지 말지\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7335db-e0bb-4e27-80c5-eea11e593a57",
   "metadata": {
    "id": "ab7335db-e0bb-4e27-80c5-eea11e593a57"
   },
   "source": [
    "- 검증 단계로서, 데이터 로더를 반복하고 각 배치에 120개의 토큰으로 구성된 8개의 훈련 샘플이 포함되어 있는지 확인합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
    "outputId": "4714979b-cbc7-4575-9868-8e9e11363d58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 로더:\n",
      "입력 배치 차원: torch.Size([8, 120])\n",
      "레이블 배치 차원 torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(\"훈련 세트 로더:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(\"입력 배치 차원:\", input_batch.shape)\n",
    "print(\"레이블 배치 차원\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdd7947-7039-49bf-8a5e-c0a2f4281ca1",
   "metadata": {
    "id": "5cdd7947-7039-49bf-8a5e-c0a2f4281ca1"
   },
   "source": [
    "- 마지막으로, 각 데이터셋의 총 배치 수를 출력해 보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "IZfw-TYD2zTj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZfw-TYD2zTj",
    "outputId": "d56f2c36-8e27-4653-bb9d-6a7aa312ddbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130개 훈련 배치\n",
      "19개 검증 배치\n",
      "38개 테스트 배치\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)}개 훈련 배치\")\n",
    "print(f\"{len(val_loader)}개 검증 배치\")\n",
    "print(f\"{len(test_loader)}개 테스트 배치\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c4f61a-5f5d-4b3b-97cf-151b617d1d6c",
   "metadata": {
    "id": "d1c4f61a-5f5d-4b3b-97cf-151b617d1d6c"
   },
   "source": [
    "## 6.4 사전 훈련된 가중치로 모델 초기화하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e1af8b-8bd1-4b44-8b8b-dc031496e208",
   "metadata": {
    "id": "97e1af8b-8bd1-4b44-8b8b-dc031496e208"
   },
   "source": [
    "- 이 섹션에서는 이전 챕터에서 작업했던 사전 훈련된 모델을 초기화합니다.\n",
    "\n",
    "<img src=\"images/llm_from_scratch/ch06_compressed/08.webp\" width=700px>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2992d779-f9fb-4812-a117-553eb790a5a9",
   "metadata": {
    "id": "2992d779-f9fb-4812-a117-553eb790a5a9"
   },
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # 어휘사전 크기\n",
    "    \"context_length\": 1024,  # 문맥 길이\n",
    "    \"drop_rate\": 0.0,        # 드롭아웃 비율\n",
    "    \"qkv_bias\": True         # 쿼리-키-값 편향\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12}, #트랜스포머 블록(Transformer Block)을 몇 층으로 쌓아 올렸는지\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
    "    f\"데이터셋 길이 {train_dataset.max_length}가 모델의 문맥 \"\n",
    "    f\"길이 {BASE_CONFIG['context_length']}를 초과합니다. `max_length={BASE_CONFIG['context_length']}`로 \"\n",
    "    f\"데이터 셋을 다시 초기화하십시오.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "022a649a-44f5-466c-8a8e-326c063384f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "022a649a-44f5-466c-8a8e-326c063384f5",
    "outputId": "57d50f99-37f3-4cea-9720-95939486fa9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미 파일이 존재합니다: models/gpt2\\gpt2-small-124M.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from previous_chapters import GPTModel, load_gpt2_model\n",
    "\n",
    "model_name = \"gpt2-small-124M.pth\"\n",
    "model = load_gpt2_model(model_name, BASE_CONFIG)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8e056c-abe0-415f-b34d-df686204259e",
   "metadata": {
    "id": "ab8e056c-abe0-415f-b34d-df686204259e"
   },
   "source": [
    "- 모델이 제대로 로드되었는지 확인하기 위해 일관된 텍스트를 생성하는지 다시 한번 확인해 보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8ac25ff-74b1-4149-8dc5-4c429d464330",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d8ac25ff-74b1-4149-8dc5-4c429d464330",
    "outputId": "db55f7cb-837b-42cf-f138-b40b9906cd40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import (\n",
    "    generate_text_simple,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "\n",
    "text_1 = \"Every effort moves you\"\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69162550-6a02-4ece-8db1-06c71d61946f",
   "metadata": {
    "id": "69162550-6a02-4ece-8db1-06c71d61946f"
   },
   "source": [
    "- 모델을 분류기로 미세 튜닝하기 전에 프롬프트를 통해 스팸 메시지를 분류할 수 있는지 확인해 보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94224aa9-c95a-4f8a-a420-76d01e3a800c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "94224aa9-c95a-4f8a-a420-76d01e3a800c",
    "outputId": "751c01da-c3a6-4496-9bc9-bd7b2b1a145d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce39ed0-2c77-410d-8392-dd15d4b22016",
   "metadata": {
    "id": "1ce39ed0-2c77-410d-8392-dd15d4b22016"
   },
   "source": [
    "- 보시다시피, 이 모델은 지시 사항을 잘 따르지 못합니다.\n",
    "- 이는 모델이 사전 학습만 되었고 지시 미세 튜닝되지 않았기 때문에 예상되는 결과입니다 (지시 미세 튜닝은 다음 장에서 다룹니다).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9ae440-32f9-412f-96cf-fd52cc3e2522",
   "metadata": {
    "id": "4c9ae440-32f9-412f-96cf-fd52cc3e2522"
   },
   "source": [
    "## 6.5 분류 헤드 추가하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e9d66f-76b2-40fc-9ec5-3f972a8db9c0",
   "metadata": {
    "id": "d6e9d66f-76b2-40fc-9ec5-3f972a8db9c0"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch06_compressed/09.webp\" width=700px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217bac05-78df-4412-bd80-612f8061c01d",
   "metadata": {
    "id": "217bac05-78df-4412-bd80-612f8061c01d"
   },
   "source": [
    "- 이 절에서는 사전 훈련된 LLM을 분류 미세 튜닝에 사용할 수 있도록 수정합니다.\n",
    "- 먼저 모델 구조를 살펴보겠습니다.(위의 그림과 연관지어서 구조 파악)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f640a76-dd00-4769-9bc8-1aed0cec330d",
   "metadata": {
    "id": "3f640a76-dd00-4769-9bc8-1aed0cec330d"
   },
   "source": [
    "- 위에서 4장에서 구현한 구조가 깔끔하게 정리되어 있는 것을 볼 수 있습니다.\n",
    "- 목표는 출력 층 교체하고 미세 튜닝하는 것입니다.\n",
    "- 이를 위해 먼저 모델을 동결합니다. 즉, 모든 층을 훈련 불가능하게 만듭니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fkMWFl-0etea",
   "metadata": {
    "id": "fkMWFl-0etea"
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72155f83-87d9-476a-a978-a15aa2d44147",
   "metadata": {
    "id": "72155f83-87d9-476a-a978-a15aa2d44147"
   },
   "source": [
    "- 그런 다음 출력 층(`model.out_head`)을 교체합니다. 이 층은 입력을 50,257차원(어휘사전 크기)으로 매핑합니다.\n",
    "- 이진 분류(\"스팸\" 및 \"스팸아님\"의 두 클래스 예측)를 위해 모델을 미세 튜닝하기 때문에 아래와 같이 출력 층를 교체할 수 있으며 기본적으로 학습 가능합니다.\n",
    "- 아래 코드를 더 일반적으로 유지하기 위해 `BASE_CONFIG[\"emb_dim\"]`(\"gpt2-small (124M)\" 모델에서 768과 같음)을 사용하는 것에 유의하세요.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e759fa0-0f69-41be-b576-17e5f20e04cb",
   "metadata": {
    "id": "7e759fa0-0f69-41be-b576-17e5f20e04cb"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30be5475-ae77-4f97-8f3e-dec462b1339f",
   "metadata": {
    "id": "30be5475-ae77-4f97-8f3e-dec462b1339f"
   },
   "source": [
    "- 기술적으로 출력 층만 훈련하는 것으로 충분합니다.\n",
    "- 하지만, [대규모 언어 모델 미세 튜닝](https://magazine.sebastianraschka.com/p/finetuning-large-language-models)에서 확인했듯이, 실험 결과 추가 층을 미세 튜닝하면 성능이 눈에 띄게 향상되는 것으로 나타났습니다.\n",
    "- 따라서 마지막 트랜스포머 블록과 마지막 트랜스포머 블록을 출력 층에 연결하는 최종 `LayerNorm` 모듈도 훈련 가능하도록 설정합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b5e496",
   "metadata": {},
   "source": [
    "- 데이터가 적으면 layer를 늘린다고 정확도가 증가하지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1418b0bd",
   "metadata": {},
   "source": [
    "<img src=\"images/relation_with_layers_and_finetuninig.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be7c1eb-c46c-4065-8525-eea1b8c66d10",
   "metadata": {
    "id": "0be7c1eb-c46c-4065-8525-eea1b8c66d10"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch06_compressed/10.webp\" width=700px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f6f637",
   "metadata": {},
   "source": [
    "- 최종 layer을 학습가능하도록 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2aedc120-5ee3-48f6-92f2-ad9304ebcdc7",
   "metadata": {
    "id": "2aedc120-5ee3-48f6-92f2-ad9304ebcdc7"
   },
   "outputs": [],
   "source": [
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f012b899-8284-4d3a-97c0-8a48eb33ba2e",
   "metadata": {
    "id": "f012b899-8284-4d3a-97c0-8a48eb33ba2e"
   },
   "source": [
    "- 이전 장에서처럼 이 모델을 비슷하게 사용할 수 있습니다.\n",
    "- 예를 들어, 텍스트 입력을 제공해 보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f645c06a-7df6-451c-ad3f-eafb18224ebc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f645c06a-7df6-451c-ad3f-eafb18224ebc",
    "outputId": "f34b4ba9-8f2f-4210-8d62-8bd541f58eef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력: tensor([[5211,  345,  423,  640]])\n",
      "입력 차원: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"입력:\", inputs)\n",
    "print(\"입력 차원:\", inputs.shape) # shape: (배치 크기, 토큰 수)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbf8481-772d-467b-851c-a62b86d0cb1b",
   "metadata": {
    "id": "fbbf8481-772d-467b-851c-a62b86d0cb1b"
   },
   "source": [
    "- 이전 장과 다른 점은 출력 차원이 50,257개가 아니라 2개라는 것입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48dc84f1-85cc-4609-9cee-94ff539f00f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48dc84f1-85cc-4609-9cee-94ff539f00f4",
    "outputId": "eb844ee1-84ed-4082-c03a-cc1b78c21cb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출력:\n",
      " tensor([[[-1.5854,  0.9904],\n",
      "         [-3.7235,  7.4548],\n",
      "         [-2.2661,  6.6049],\n",
      "         [-3.5983,  3.9902]]])\n",
      "출력 차원: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "\n",
    "print(\"출력:\\n\", outputs)\n",
    "print(\"출력 차원:\", outputs.shape) # shape: (배치 크기, 토큰 수, 클래스 수)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75430a01-ef9c-426a-aca0-664689c4f461",
   "metadata": {
    "id": "75430a01-ef9c-426a-aca0-664689c4f461"
   },
   "source": [
    "- 이전 장에서 논의했듯이 각 입력 토큰에 대해 하나의 출력 벡터가 있습니다.\n",
    "- 모델에 4개의 입력 토큰이 있는 텍스트 샘플을 제공했으므로 출력은 2차원 출력 벡터 4개로 구성됩니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df9144f-6817-4be4-8d4b-5d4dadfe4a9b",
   "metadata": {
    "id": "7df9144f-6817-4be4-8d4b-5d4dadfe4a9b"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch06_compressed/11.webp\" width=800px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bb8616-c791-4f5c-bac0-5302f663e46a",
   "metadata": {
    "id": "e3bb8616-c791-4f5c-bac0-5302f663e46a"
   },
   "source": [
    "- 3장에서는 각 입력 토큰을 다른 모든 입력 토큰에 연결하는 어텐션 메커니즘에 대해 논의했습니다.\n",
    "- 3장에서는 GPT와 같은 모델에 사용되는 코잘 어텐션 마스크도 소개했습니다. 코잘 마스크는 현재 토큰이 현재 및 이전 토큰 위치만 참조하도록 만듭니다.\n",
    "- 코잘 어텐션 메커니즘을 기반으로, 4번째 (마지막) 토큰이 다른 모든 토큰에 대한 정보를 포함하는 유일한 토큰이기 때문에 모든 토큰 중에서 가장 많은 정보를 담고 있습니다.\n",
    "- 따라서 우리는 이 마지막 토큰에 특히 관심이 있으며, 스팸 분류 작업을 위해 미세 튜닝할 것입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49383a8c-41d5-4dab-98f1-238bca0c2ed7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49383a8c-41d5-4dab-98f1-238bca0c2ed7",
    "outputId": "aac4b65b-6b1b-4ac4-aa4f-404664d418df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "마지막 출력 토큰: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "print(\"마지막 출력 토큰:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df08ae0-e664-4670-b7c5-8a2280d9b41b",
   "metadata": {
    "id": "8df08ae0-e664-4670-b7c5-8a2280d9b41b"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch06_compressed/12.webp\" width=400px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aa4aef-e1e9-491b-9adf-5aa973e59b8c",
   "metadata": {
    "id": "32aa4aef-e1e9-491b-9adf-5aa973e59b8c"
   },
   "source": [
    "## 6.6 분류 손실과 정확도 계산하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669e1fd1-ace8-44b4-b438-185ed0ba8b33",
   "metadata": {
    "id": "669e1fd1-ace8-44b4-b438-185ed0ba8b33"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch06_compressed/13.webp\" width=700px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7df4ee-0a34-4a4d-896d-affbbf81e0b3",
   "metadata": {
    "id": "7a7df4ee-0a34-4a4d-896d-affbbf81e0b3"
   },
   "source": [
    "- 손실 계산을 설명하기 전에 모델 출력이 어떻게 클래스 레이블로 변환되는지 간략하게 살펴보겠습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557996dd-4c6b-49c4-ab83-f60ef7e1d69e",
   "metadata": {
    "id": "557996dd-4c6b-49c4-ab83-f60ef7e1d69e"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch06_compressed/14.webp\" width=800px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edd71fa-628a-4d00-b81d-6d8bcb2c341d",
   "metadata": {
    "id": "7edd71fa-628a-4d00-b81d-6d8bcb2c341d"
   },
   "source": [
    "- 5장과 유사하게, `softmax` 함수를 통해 출력(로짓)을 확률 점수로 변환한 다음 `argmax` 함수를 통해 가장 큰 확률 값의 인덱스를 얻습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b81efa92-9be1-4b9e-8790-ce1fc7b17f01",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b81efa92-9be1-4b9e-8790-ce1fc7b17f01",
    "outputId": "67e77996-146a-4a11-c049-9fd02a1c0e77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스 레이블: 1\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
    "label = torch.argmax(probas)\n",
    "print(\"클래스 레이블:\", label.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414a6f02-307e-4147-a416-14d115bf8179",
   "metadata": {
    "id": "414a6f02-307e-4147-a416-14d115bf8179"
   },
   "source": [
    "- 5장에서 설명했듯이 소프트맥스 함수는 여기서는 선택 사항입니다. 가장 큰 출력이 가장 큰 확률 점수에 해당하기 때문입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9f9ad66-4969-4501-8239-3ccdb37e71a2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f9f9ad66-4969-4501-8239-3ccdb37e71a2",
    "outputId": "2a62cad9-c4b6-4f3c-c6ab-cd77f7d844fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스 레이블: 1\n"
     ]
    }
   ],
   "source": [
    "logits = outputs[:, -1, :]\n",
    "label = torch.argmax(logits)\n",
    "print(\"클래스 레이블:\", label.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb20d3a-cbba-4ab1-8584-d94e16589505",
   "metadata": {
    "id": "dcb20d3a-cbba-4ab1-8584-d94e16589505"
   },
   "source": [
    "- 이 개념을 적용하여 소위 분류 정확도를 계산할 수 있습니다. 분류 정확도는 주어진 데이터셋에서 정확하게 예측한 백분율입니다.\n",
    "- 분류 정확도를 계산하기 위해 앞서 설명한 `argmax` 기반 예측 코드를 데이터셋에 있는 모든 샘플에 적용하고 다음과 같이 정확한 예측의 비율을 계산할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ecf9572-aed0-4a21-9c3b-7f9f2aec5f23",
   "metadata": {
    "id": "3ecf9572-aed0-4a21-9c3b-7f9f2aec5f23"
   },
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]  # 마지막 출력 토큰의 로짓\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669faeec-1968-4401-9786-d0849f61d32b",
   "metadata": {},
   "source": [
    "- 현재 모델 파라미터는 CPU에 로딩되어 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4124c6e2-9d0e-4ab9-9762-8698cf8a314e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{device(type='cpu')}\n"
     ]
    }
   ],
   "source": [
    "devices = {param.device for param in model.parameters()}\n",
    "print(devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7165fe46-a284-410b-957f-7524877d1a1a",
   "metadata": {
    "id": "7165fe46-a284-410b-957f-7524877d1a1a"
   },
   "source": [
    "- 여러 데이터셋에 대한 분류 정확도를 계산하기 위해 함수를 적용해 보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "390e5255-8427-488c-adef-e1c10ab4fb26",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "390e5255-8427-488c-adef-e1c10ab4fb26",
    "outputId": "76689837-ea1a-4e32-fc27-503c98f5d9d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실행 장치: cuda\n",
      "훈련 정확도: 46.25%\n",
      "검증 정확도: 45.00%\n",
      "테스트 정확도: 48.75%\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"실행 장치: {device}\")\n",
    "\n",
    "model.to(device) # nn.Module 클래스의 경우 model = model.to(device) 할당문이 필요하지 않습니다.\n",
    "\n",
    "torch.manual_seed(123) # 데이터 로더에서 셔플링하기 때문에 재현성을 위해\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"훈련 정확도: {train_accuracy*100:.2f}%\")\n",
    "print(f\"검증 정확도: {val_accuracy*100:.2f}%\")\n",
    "print(f\"테스트 정확도: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30345e2a-afed-4d22-9486-f4010f90a871",
   "metadata": {
    "id": "30345e2a-afed-4d22-9486-f4010f90a871"
   },
   "source": [
    "- 예상대로 모델을 미세 튜닝하지 않았기 때문에 예측 정확도가 그리 좋지 않습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4a9d15-8fc7-48a2-8734-d92a2f265328",
   "metadata": {
    "id": "4f4a9d15-8fc7-48a2-8734-d92a2f265328"
   },
   "source": [
    "- 미세 튜닝(훈련)을 시작하기 전에 먼저 훈련 중에 최적화하려는 손실 함수를 정의해야 합니다.\n",
    "- 목표는 모델의 스팸 분류 정확도를 최대화하는 것이지만 분류 정확도는 미분 가능한 함수가 아닙니다.\n",
    "- 따라서 분류 정확도를 최대화하는 대신, 크로스 엔트로피 손실을 최소화합니다 (무료 강의 [Introduction to Deep Learning](https://sebastianraschka.com/blog/2021/dl-course.html#l08-multinomial-logistic-regression--softmax-regression) 8강에서 이 주제에 대해 자세히 알아볼 수 있습니다)\n",
    "\n",
    "- `calc_loss_batch` 함수는 5장과 동일하지만 모든 토큰 `model(input_batch)` 대신 마지막 토큰 `model(input_batch)[:, -1, :]`을 최적화하는 데에만 관심이 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1e9547-806c-41a9-8aba-3b2822baabe4",
   "metadata": {
    "id": "2f1e9547-806c-41a9-8aba-3b2822baabe4"
   },
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    # target이 1차원이면(마지막 토큰만) 첫 번째 방식, 2차원이면(전체 문장) 두 번째 방식\n",
    "    if target_batch.dim() == 1:\n",
    "        loss = torch.nn.functional.cross_entropy(logits[:, -1, :], target_batch)\n",
    "    else:\n",
    "        loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a013aab9-f854-4866-ad55-5b8350adb50a",
   "metadata": {
    "id": "a013aab9-f854-4866-ad55-5b8350adb50a"
   },
   "source": [
    "`calc_loss_loader`는 5장과 완전히 동일합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7b83e10-5720-45e7-ac5e-369417ca846b",
   "metadata": {
    "id": "b7b83e10-5720-45e7-ac5e-369417ca846b"
   },
   "outputs": [],
   "source": [
    "# 5장과 동일\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # num_batches가 데이터 로더의 배치 수를 초과하는 경우\n",
    "        # 데이터 로더의 총 배치 수와 일치하도록 배치 수를 줄입니다.\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56826ecd-6e74-40e6-b772-d3541e585067",
   "metadata": {
    "id": "56826ecd-6e74-40e6-b772-d3541e585067"
   },
   "source": [
    "- `calc_closs_loader`를 사용하여 훈련을 시작하기 전 초기 훈련, 검증 및 테스트 세트 손실을 계산합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f6f00e53-5beb-4e64-b147-f26fd481c6ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6f00e53-5beb-4e64-b147-f26fd481c6ff",
    "outputId": "e08fb71b-c0ad-422d-ce01-955b40430558"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 손실: 2.453\n",
      "검증 손실: 2.583\n",
      "테스트 손실: 2.322\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # 효율성을 위해 그레이디언트 추적을 비활성화합니다. 아직 훈련하지 않기 때문입니다.\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "\n",
    "print(f\"훈련 손실: {train_loss:.3f}\")\n",
    "print(f\"검증 손실: {val_loss:.3f}\")\n",
    "print(f\"테스트 손실: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04b980b-e583-4f62-84a0-4edafaf99d5d",
   "metadata": {
    "id": "e04b980b-e583-4f62-84a0-4edafaf99d5d"
   },
   "source": [
    "- 다음 섹션에서는 손실 값과 결과적으로 분류 정확도를 개선하기 위해 모델을 훈련합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456ae0fd-6261-42b4-ab6a-d24289953083",
   "metadata": {
    "id": "456ae0fd-6261-42b4-ab6a-d24289953083"
   },
   "source": [
    "## 6.7 지도 학습 데이터로 모델 미세 튜닝하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9b099b-0829-4f72-8a2b-4363e3497026",
   "metadata": {
    "id": "6a9b099b-0829-4f72-8a2b-4363e3497026"
   },
   "source": [
    "- 이 절에서는 모델의 분류 정확도를 향상시키기 위한 훈련 함수를 정의하고 사용합니다.\n",
    "- 아래 `train_classifier_simple` 함수는 5장에서 모델 사전 훈련에 사용했던 `train_model_simple` 함수와 거의 동일합니다.\n",
    "- 단 두 가지 차이점은 다음과 같습니다.\n",
    "  1. 토큰 수 대신 학습된 샘플 수(`examples_seen`)를 추적합니다.\n",
    "  2. 각 에포크 다음에 샘플 텍스트를 출력하는 대신 정확도를 계산합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979b6222-1dc2-4530-9d01-b6b04fe3de12",
   "metadata": {
    "id": "979b6222-1dc2-4530-9d01-b6b04fe3de12"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch06_compressed/15.webp\" width=600px>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "Csbr60to50FL",
   "metadata": {
    "id": "Csbr60to50FL"
   },
   "outputs": [],
   "source": [
    "# 5장의 `train_model_simple`과 전체적으로 동일\n",
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                            eval_freq, eval_iter):\n",
    "    # 손실 및 처리한 샘플 수를 위한 리스트 초기화\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    # 메인 학습 루프\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # 모델을 훈련 모드로 설정\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # 이전 배치 반복에서 얻은 손실의 그레이디언트 재설정\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # 손실 그레이디언트 계산\n",
    "            optimizer.step() # 손실 그레이디언트를 사용하여 모델 가중치 업데이트\n",
    "            examples_seen += input_batch.shape[0] # 새로 추가: 토큰 대신 샘플 추적\n",
    "            global_step += 1\n",
    "\n",
    "            # 선택적 평가 단계\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"에포크 {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"훈련 손실 {train_loss:.3f}, 검증 손실 {val_loss:.3f}\")\n",
    "\n",
    "        # 각 에포크 후 정확도 계산\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        print(f\"훈련 정확도: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"검증 정확도: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9624cb30-3e3a-45be-b006-c00475b58ae8",
   "metadata": {
    "id": "9624cb30-3e3a-45be-b006-c00475b58ae8"
   },
   "source": [
    "- `evaluate_model` 함수는 `train_classifier_simple` 에서 사용되며 5장에서 사용한 것과 동일합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bcc7bc04-6aa6-4516-a147-460e2f466eab",
   "metadata": {
    "id": "bcc7bc04-6aa6-4516-a147-460e2f466eab"
   },
   "outputs": [],
   "source": [
    "# 5장과 동일\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e807bfe9-364d-46b2-9e25-3b000c3ef6f9",
   "metadata": {
    "id": "e807bfe9-364d-46b2-9e25-3b000c3ef6f9"
   },
   "source": [
    "- M3 맥북 에어 노트북 컴퓨터에서는 훈련 시간이 약 5분 정도 소요되며 V100 또는 A100 GPU에서는 30초 미만이 소요됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "X7kU3aAj7vTJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X7kU3aAj7vTJ",
    "outputId": "2785a778-4dd8-442f-df56-fc2640b6a8a1"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m optimizer = torch.optim.AdamW(model.parameters(), lr=\u001b[32m5e-5\u001b[39m, weight_decay=\u001b[32m0.1\u001b[39m)\n\u001b[32m      9\u001b[39m num_epochs = \u001b[32m5\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m train_losses, val_losses, train_accs, val_accs, examples_seen = \u001b[43mtrain_classifier_simple\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_freq\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m end_time = time.time()\n\u001b[32m     16\u001b[39m execution_time_minutes = (end_time - start_time) / \u001b[32m60\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mtrain_classifier_simple\u001b[39m\u001b[34m(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# 선택적 평가 단계\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_step % eval_freq == \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     train_loss, val_loss = \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m     train_losses.append(train_loss)\n\u001b[32m     25\u001b[39m     val_losses.append(val_loss)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mevaluate_model\u001b[39m\u001b[34m(model, train_loader, val_loader, device, eval_iter)\u001b[39m\n\u001b[32m      3\u001b[39m model.eval()\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     train_loss = \u001b[43mcalc_loss_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n\u001b[32m      7\u001b[39m model.train()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mcalc_loss_loader\u001b[39m\u001b[34m(data_loader, model, device, num_batches)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, (input_batch, target_batch) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_loader):\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i < num_batches:\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m         loss = \u001b[43mcalc_loss_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m         total_loss += loss.item()\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mcalc_loss_batch\u001b[39m\u001b[34m(input_batch, target_batch, model, device)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcalc_loss_batch\u001b[39m(input_batch, target_batch, model, device):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     input_batch, target_batch = \u001b[43minput_batch\u001b[49m.to(device), target_batch.to(device)\n\u001b[32m      3\u001b[39m     logits = model(input_batch)[:, -\u001b[32m1\u001b[39m, :]  \u001b[38;5;66;03m# 마지막 출력 토큰의 로짓\u001b[39;00m\n\u001b[32m      4\u001b[39m     loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<stringsource>:69\u001b[39m, in \u001b[36mcfunc.to_py.__Pyx_CFunc_b0409f__29_pydevd_sys_monitoring_cython_object__lParen__etc_to_py_4code_4line.wrap\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1481\u001b[39m, in \u001b[36m_pydevd_sys_monitoring_cython._line_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1523\u001b[39m, in \u001b[36m_pydevd_sys_monitoring_cython._internal_line_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1324\u001b[39m, in \u001b[36m_pydevd_sys_monitoring_cython._stop_on_breakpoint\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1961\u001b[39m, in \u001b[36m_pydevd_sys_monitoring_cython._do_wait_suspend\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\dev\\llm_lecture\\.venv\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2188\u001b[39m, in \u001b[36mPyDB.do_wait_suspend\u001b[39m\u001b[34m(self, thread, frame, event, arg, exception_type)\u001b[39m\n\u001b[32m   2185\u001b[39m             from_this_thread.append(frame_custom_thread_id)\n\u001b[32m   2187\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._threads_suspended_single_notification.notify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[32m-> \u001b[39m\u001b[32m2188\u001b[39m         keep_suspended = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_suspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2190\u001b[39m frames_list = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2192\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[32m   2193\u001b[39m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\dev\\llm_lecture\\.venv\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2257\u001b[39m, in \u001b[36mPyDB._do_wait_suspend\u001b[39m\u001b[34m(self, thread, frame, event, arg, trace_suspend_type, from_this_thread, frames_tracker)\u001b[39m\n\u001b[32m   2254\u001b[39m                 queue.put(internal_cmd)\n\u001b[32m   2255\u001b[39m                 wait_timeout = TIMEOUT_FAST\n\u001b[32m-> \u001b[39m\u001b[32m2257\u001b[39m         \u001b[43mnotify_event\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2258\u001b[39m         notify_event.clear()\n\u001b[32m   2260\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.12-windows-x86_64-none\\Lib\\threading.py:655\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    653\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    654\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m655\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.12-windows-x86_64-none\\Lib\\threading.py:359\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    361\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"훈련 소요 시간: {execution_time_minutes:.2f}분\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1261bf90-3ce7-4591-895a-044a05538f30",
   "metadata": {
    "id": "1261bf90-3ce7-4591-895a-044a05538f30"
   },
   "source": [
    "- 5장과 유사하게, 맷플롯립을 사용하여 훈련 및 검증 세트에 대한 손실 함수를 그립니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cURgnDqdCeka",
   "metadata": {
    "id": "cURgnDqdCeka"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # 훈련 및 검증 손실을 에포크에 따라 그립니다.\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    # 처리한 샘플 수를 위해 두 번째 x축을 만듭니다.\n",
    "    ax2 = ax1.twiny()  # 동일한 y축을 공유하는 두 번째 x축을 만듭니다.\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)  # 눈금 정렬을 위한 보이지 않는 그래프\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()  # 공간을 확보하기 위해 레이아웃을 조정합니다.\n",
    "    plt.savefig(f\"outputs/{label}-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "OIqRt466DiGk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "OIqRt466DiGk",
    "outputId": "1e8172fe-1ab5-4fe5-a230-2d366edd9f08"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd28174-1836-44ba-b6c0-7e0be774fadc",
   "metadata": {
    "id": "dbd28174-1836-44ba-b6c0-7e0be774fadc"
   },
   "source": [
    "- 기울기가 아래쪽으로 향하고 있으므로 모델이 잘 학습하고 있음을 알 수 있습니다.\n",
    "- 또한, 훈련 손실과 검증 손실이 매우 가깝다는 사실은 모델이 훈련 데이터에 과대적합되는 경향이 없음을 나타냅니다.\n",
    "- 마찬가지로, 아래에서 정확도를 그래프로 표시할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "yz8BIsaF0TUo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "yz8BIsaF0TUo",
    "outputId": "c7c1f0ea-13e3-4e3b-f59a-637d0cc89bc9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aba699-21bc-42de-a69c-99f370bb0363",
   "metadata": {
    "id": "90aba699-21bc-42de-a69c-99f370bb0363"
   },
   "source": [
    "- 위의 정확도 그래프를 기반으로 에포크 4와 5 이후 모델이 비교적 높은 훈련 및 검증 정확도를 달성했음을 알 수 있습니다.\n",
    "- 하지만 이전에 훈련 함수에서 `eval_iter=5`를 지정했던 것을 기억해야 합니다. 이는 훈련 및 검증 세트의 일부만 사용해 성능을 추정했음을 의미합니다.\n",
    "- 아래와 같이 전체 데이터셋에 대한 훈련, 검증 및 테스트 세트 성능을 계산할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "UHWaJFrjY0zW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UHWaJFrjY0zW",
    "outputId": "c9022a93-8fe5-443a-8106-ab8fc727e008"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 정확도: 97.21%\n",
      "검증 정확도: 97.32%\n",
      "테스트 정확도: 95.67%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"훈련 정확도: {train_accuracy*100:.2f}%\")\n",
    "print(f\"검증 정확도: {val_accuracy*100:.2f}%\")\n",
    "print(f\"테스트 정확도: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6882649f-dc7b-401f-84d2-024ff79c74a1",
   "metadata": {
    "id": "6882649f-dc7b-401f-84d2-024ff79c74a1"
   },
   "source": [
    "- 훈련 세트와 검증 세트의 성능이 거의 동일한 것을 확인할 수 있습니다.\n",
    "- 그러나 테스트 세트 성능이 약간 낮은 것을 보면 모델이 훈련 데이터에 대해 아주 작은 정도로 과적합되었음을 알 수 있으며, 학습률과 같은 일부 하이퍼파라미터를 조정하는 데 사용된 검증 데이터에도 과적합되었음을 알 수 있습니다.\n",
    "- 하지만 이는 정상적인 현상이며, 모델의 드롭아웃 비율(`drop_rate`)이나 옵티마이저 설정의 `weight_decay`를 높여 이러한 차이를 줄일 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74d9ad7-3ec1-450e-8c9f-4fc46d3d5bb0",
   "metadata": {
    "id": "a74d9ad7-3ec1-450e-8c9f-4fc46d3d5bb0"
   },
   "source": [
    "## 6.8 LLM을 스팸 분류기로 사용하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ebcfa2-479e-408b-9cf0-7421f6144855",
   "metadata": {
    "id": "72ebcfa2-479e-408b-9cf0-7421f6144855"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch06_compressed/18.webp\" width=700px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5408e6-83e4-4e5a-8503-c2fba6073f31",
   "metadata": {
    "id": "fd5408e6-83e4-4e5a-8503-c2fba6073f31"
   },
   "source": [
    "- 마지막으로, 미세 튜닝된 GPT 모델을 실제로 사용해 보겠습니다.\n",
    "- 아래 `classify_review` 함수는 이전에 구현한 `SpamDataset`과 유사한 데이터 전처리 단계를 구현합니다.\n",
    "- 그런 다음, 이 함수는 모델에서 예측된 정수 클래스 레이블을 반환하고 해당 클래스 이름을 반환합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aHdn6xvL-IW5",
   "metadata": {
    "id": "aHdn6xvL-IW5"
   },
   "outputs": [],
   "source": [
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    model.eval()\n",
    "\n",
    "    # 모델에 대한 입력 준비\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.weight.shape[0]\n",
    "\n",
    "    # 너무 긴 시퀀스 자르기\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "    assert max_length is not None, (\n",
    "        \"max_length가 지정되지 않았습니다. 모델의 최대 문맥 길이를 사용하려면\"\n",
    "        \"max_length=model.pos_emb.weight.shape[0]로 지정하세요.\"\n",
    "    )\n",
    "    assert max_length <= supported_context_length, (\n",
    "        f\"max_length({max_length})가 모델이 지원하는 문맥 길이({supported_context_length})를 초과했습니다.\"\n",
    "    )\n",
    "    # 또는 max_length=None인 경우를 안정적으로 처리하는 방법은 다음과 같습니다.\n",
    "    # max_len = min(max_length, supported_context_length) if max_length else supported_context_length\n",
    "    # input_ids = input_ids[:max_len]\n",
    "\n",
    "    # 가장 긴 시퀀스로 패딩하기\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # 배치 차원 추가\n",
    "\n",
    "    # 모델 추론\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :]  # 마지막 출력 토큰의 로짓\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # 분류 결과 반환\n",
    "    return \"스팸\" if predicted_label == 1 else \"스팸아님\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29682d8-a899-4d9b-b973-f8d5ec68172c",
   "metadata": {
    "id": "f29682d8-a899-4d9b-b973-f8d5ec68172c"
   },
   "source": [
    "- 몇 개의 샘플로 시험해 보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "apU_pf51AWSV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "apU_pf51AWSV",
    "outputId": "0fee6062-1569-4873-9da9-5eea3f023f56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스팸\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1g5VTOo_Ajs5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1g5VTOo_Ajs5",
    "outputId": "1c341d60-1b9d-489b-cd00-7afe547e9389"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스팸아님\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf736e39-0d47-40c1-8d18-1f716cf7a81e",
   "metadata": {
    "id": "bf736e39-0d47-40c1-8d18-1f716cf7a81e"
   },
   "source": [
    "- 마지막으로, 나중에 다시 훈련하지 않고 모델을 재사용할 수 있도록 모델을 저장합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "mYnX-gI1CfQY",
   "metadata": {
    "id": "mYnX-gI1CfQY"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"outputs/review_classifier.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba78cf7c-6b80-4f71-a50e-3ccc73839af6",
   "metadata": {
    "id": "ba78cf7c-6b80-4f71-a50e-3ccc73839af6"
   },
   "source": [
    "- 그런 다음 새 세션에서 다음과 같이 모델을 로드할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cc4e68a5-d492-493b-87ef-45c475f353f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cc4e68a5-d492-493b-87ef-45c475f353f5",
    "outputId": "badf32ed-f908-4a02-c122-b86d3ac9953b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch.load(\"outputs/review_classifier.pth\", map_location=device, weights_only=True)\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b70ac71-234f-4eeb-b33d-c62726d50cd4",
   "metadata": {
    "id": "5b70ac71-234f-4eeb-b33d-c62726d50cd4"
   },
   "source": [
    "## 요약\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafdc910-d616-47ab-aa85-f90c6e7ed80e",
   "metadata": {
    "id": "dafdc910-d616-47ab-aa85-f90c6e7ed80e"
   },
   "source": [
    "- 연습 문제 풀이는 [./exercise-solutions.ipynb](./exercise-solutions.ipynb)에서 찾을 수 있습니다.\n",
    "- 또한 관심 있는 독자는 [부록 E](../../appendix-E)에서 LoRA를 사용한 파라미터 효율적인 훈련에 대한 소개를 찾을 수 있습니다.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "llm_lecture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
