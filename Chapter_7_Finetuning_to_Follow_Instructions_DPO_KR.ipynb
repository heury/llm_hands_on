{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62129596-d10f-45b1-a1af-ee10f358f773",
   "metadata": {
    "id": "62129596-d10f-45b1-a1af-ee10f358f773"
   },
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<font size=\"2\">\n",
    "이 코드는 <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a>의 저서 <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a>를 위한 보충 코드입니다.<br>\n",
    "<br>코드 저장소: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
    "</font>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<a href=\"http://mng.bz/orYv\"><img src=\"images/llm_from_scratch/ch07_compressed/cover-small.webp\" width=\"100px\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bd2379-ed2f-4c77-8b71-f1f0242b9ff9",
   "metadata": {
    "id": "b0bd2379-ed2f-4c77-8b71-f1f0242b9ff9"
   },
   "source": [
    "# LLM 정렬을 위한 직접 선호도 최적화(DPO) 바닥부터 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04cb2b8-d87b-4c6b-a225-c630d758f68e",
   "metadata": {
    "id": "d04cb2b8-d87b-4c6b-a225-c630d758f68e"
   },
   "source": [
    "- 이 노트북에서는 직접 선호도 최적화(Direct Preference Optimization, DPO)를 바닥부터 구현하고, 이를 대규모 언어 모델(LLM)에 적용하여 사용자 선호도에 더 잘 부합하는 응답을 생성하는 능력을 향상시킵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edb3e145-fbaa-4bb3-9e95-186b4145087f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "edb3e145-fbaa-4bb3-9e95-186b4145087f",
    "outputId": "3d449525-76cc-4124-ab30-a93c6a9623ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken 버전: 0.12.0\n",
      "torch 버전: 2.9.1+cu126\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\n",
    "    \"tiktoken\",    # 토크나이저\n",
    "    \"torch\",       # 딥러닝 라이브러리\n",
    "]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} 버전: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ec20a3-a26c-4f9b-8a33-bfd3d67860e2",
   "metadata": {
    "id": "49ec20a3-a26c-4f9b-8a33-bfd3d67860e2"
   },
   "source": [
    "&nbsp;\n",
    "# 1) DPO에 대한 간략한 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17804afd-786b-4600-bad0-f5805454e3d6",
   "metadata": {
    "id": "17804afd-786b-4600-bad0-f5805454e3d6"
   },
   "source": [
    "- [Direct Preference Optimization: Your Language Model is Secretly a Reward Model](https://arxiv.org/abs/2305.18290) 논문에서 제안된 DPO는 LLM 미세 조정에 사용되는 인간 피드백 기반 강화 학습(RLHF)의 대안입니다.\n",
    "- DPO는 모델이 사용자의 기대와 지시사항에 더 잘 부합하는 응답을 생성하도록 미세 조정(또는 정렬)하는 데 사용할 수 있습니다.\n",
    "\n",
    "<img src=\"images/llm_from_scratch/dpo/1.webp\" width=500px>\n",
    "\n",
    "- 지시어 미세 조정(Instruction finetuning)에서는 주어진 프롬프트에 대해 올바른 답을 생성하도록 LLM을 학습시킵니다.\n",
    "- 그러나 실제로는 올바른 답을 제공하는 방법이 여러 가지가 있으며, 그 스타일이 다를 수 있습니다. 예를 들어 아래 그림처럼 노트북 구매 추천을 요청했을 때 기술적인 답변과 사용자 친화적인 답변이 있을 수 있습니다.\n",
    "\n",
    "<img src=\"images/llm_from_scratch/dpo/2.webp\" width=700px>\n",
    "\n",
    "- RLHF와 DPO는 LLM이 특정 답변 스타일을 다른 스타일보다 선호하도록 가르쳐서 사용자 선호도에 더 잘 정렬되도록 하는 방법입니다.\n",
    "- 별도의 보상 모델 학습이 필요한 RLHF 프로세스는 아래와 같습니다.\n",
    "\n",
    "<img src=\"images/llm_from_scratch/dpo/4.webp\" width=600px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9073622f-d537-42bf-8778-43c2adaa2191",
   "metadata": {
    "id": "9073622f-d537-42bf-8778-43c2adaa2191"
   },
   "source": [
    "- RLHF와 비교하여 DPO는 복잡한 보상 모델링 및 정책 최적화 없이 사용자 선호도에 맞게 모델을 직접 최적화하여 프로세스를 단순화하는 것을 목표로 합니다.\n",
    "- 즉, DPO는 인간의 선호도나 특정 목표에 부합하도록 모델의 출력을 직접 최적화하는 데 집중합니다.\n",
    "- 아래는 DPO가 작동하는 방식에 대한 개요입니다.\n",
    "\n",
    "<img src=\"images/llm_from_scratch/dpo/5.webp\" width=600px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c894134a-315c-453e-bbc1-387794b3f4d6",
   "metadata": {
    "id": "c894134a-315c-453e-bbc1-387794b3f4d6"
   },
   "source": [
    "- DPO 손실(loss)을 구현하기 위한 구체적인 수식은 아래와 같습니다. 코드의 뒷부분에서 파이썬으로 구현할 때 이 수식을 다시 살펴보겠습니다.\n",
    "- 선택된 응답의 확률은 높이고, 거부된 응답의 확률은 낮추는 방향으로 학습됩니다.\n",
    "\n",
    "<img src=\"images/llm_from_scratch/dpo/3.webp\" width=600px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7491b5-f619-4501-ad39-2942de57c115",
   "metadata": {
    "id": "dd7491b5-f619-4501-ad39-2942de57c115"
   },
   "source": [
    "- 위 수식에서:\n",
    "  - \"기댓값\" $\\mathbb{E}$는 통계 용어로 랜덤 변수(대괄호 안의 표현식)의 평균값을 의미합니다. $-\\mathbb{E}$를 최적화하면 모델이 사용자 선호도에 더 잘 정렬됩니다.\n",
    "  - $\\pi_{\\theta}$ 변수는 정책(policy, 강화 학습 용어)이라고 불리며 최적화하려는 LLM을 나타냅니다. $\\pi_{ref}$는 참조(reference) LLM으로, 일반적으로 최적화 전의 원본 LLM입니다(학습 시작 시 $\\pi_{\\theta}$와 $\\pi_{ref}$는 대개 동일합니다).\n",
    "  - $\\beta$는 $\\pi_{\\theta}$와 참조 모델 사이의 차이를 제어하는 하이퍼파라미터입니다. $\\beta$를 높이면 전체 손실 함수에서 로그 확률 측면의 두 모델 간 차이 영향이 커져서 두 모델 간의 발산(divergence)을 제어합니다.\n",
    "  - 로지스틱 시그모이드 함수 $\\sigma(\\centerdot)$는 선호되는 응답과 거부되는 응답의 로그 오즈(log-odds)를 확률 점수로 변환합니다.\n",
    "- 노트북이 너무 길어지는 것을 방지하기 위해, 나중에 이러한 개념에 대한 자세한 내용을 담은 별도의 기사를 작성할 수도 있습니다.\n",
    "- 그동안 RLHF와 DPO를 비교해보고 싶다면 제 기사 [Tips for LLM Pretraining and Evaluating Reward Models](https://magazine.sebastianraschka.com/p/tips-for-llm-pretraining-and-evaluating-rms)의 [2.2. RLHF vs Direct Preference Optimization (DPO)](https://magazine.sebastianraschka.com/i/142924793/rlhf-vs-direct-preference-optimization-dpo) 섹션을 참조하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xqVAgsyQ6LuG",
   "metadata": {
    "id": "xqVAgsyQ6LuG",
    "tags": []
   },
   "source": [
    "&nbsp;\n",
    "# 2) DPO를 위한 선호도 데이터셋 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b2195d-8734-469b-a52e-5031ca7ea6b1",
   "metadata": {
    "id": "60b2195d-8734-469b-a52e-5031ca7ea6b1"
   },
   "source": [
    "- DPO 손실 수식을 다시 살펴보기 전에 데이터셋을 로드하고 준비하는 것부터 시작하겠습니다. 이 과정에서 궁금했던 점들이 많이 해결될 수 있습니다.\n",
    "- 여기서는 지시어 프롬프트에 대해 더 정중한 응답과 덜 정중한 응답이 포함된 데이터셋을 사용합니다(구체적인 예시는 다음 섹션에서 확인).\n",
    "- 데이터셋은 [create-preference-data-ollama.ipynb](create-preference-data-ollama.ipynb) 노트북을 통해 생성되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wHLB62Nj7haD",
   "metadata": {
    "id": "wHLB62Nj7haD"
   },
   "source": [
    "&nbsp;\n",
    "## 2.1) 선호도 데이터셋 로드하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e09f99-1b18-4923-ba36-af46d8e3075f",
   "metadata": {
    "id": "13e09f99-1b18-4923-ba36-af46d8e3075f"
   },
   "source": [
    "- 데이터셋은 1100개의 항목이 포함된 JSON 파일입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5266e66c-5ec0-45e6-a654-148971f6aee7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5266e66c-5ec0-45e6-a654-148971f6aee7",
    "outputId": "04e8ee70-3076-441d-d2bf-7641da3d0c1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 항목 수: 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "    if not os.path.exists(file_path):\n",
    "        response = requests.get(url, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        text_data = response.text\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    else:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text_data = file.read()\n",
    "\n",
    "    data = json.loads(text_data)\n",
    "    return data\n",
    "\n",
    "\n",
    "file_path = \"datas/instruction-data-with-preference.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/04_preference-tuning-with-dpo/instruction-data-with-preference.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"전체 항목 수:\", len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725d2b9a-d6d2-46e2-89f8-5ab87e040e3b",
   "metadata": {
    "id": "725d2b9a-d6d2-46e2-89f8-5ab87e040e3b"
   },
   "source": [
    "- 두 개의 예시 항목을 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c11916f-9a26-4367-a16e-7b0c121a20a6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5c11916f-9a26-4367-a16e-7b0c121a20a6",
    "outputId": "00a432cc-19b1-484f-80e2-e897ee5e4024"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Identify the correct spelling of the following word.',\n",
      " 'input': 'Ocassion',\n",
      " 'output': \"The correct spelling is 'Occasion.'\",\n",
      " 'rejected': \"The correct spelling is obviously 'Occasion.'\",\n",
      " 'chosen': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pp(data[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01ef804a-8c13-4a0b-9b2e-b65a4d0a870d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "01ef804a-8c13-4a0b-9b2e-b65a4d0a870d",
    "outputId": "078cd643-83fb-4b42-ecf9-3256e8c9d239"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': \"What is an antonym of 'complicated'?\",\n",
      " 'input': '',\n",
      " 'output': \"An antonym of 'complicated' is 'simple'.\",\n",
      " 'chosen': \"A suitable antonym for 'complicated' would be 'simple'.\",\n",
      " 'rejected': \"An antonym of 'complicated' is 'simple'.\"}\n"
     ]
    }
   ],
   "source": [
    "pprint.pp(data[999])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56db5697-a089-4b40-a1f3-e928e8018220",
   "metadata": {
    "id": "56db5697-a089-4b40-a1f3-e928e8018220"
   },
   "source": [
    "- 위에서 볼 수 있듯이 데이터셋은 5개의 키로 구성됩니다.\n",
    "    - `'instruction'` 및 `'input'`: LLM 입력으로 사용됩니다.\n",
    "    - `'output'`: 7장에서 지시어 미세 조정 단계를 통해 모델이 학습한 응답을 포함합니다.\n",
    "    - `'chosen'` 및 `'rejected'`: DPO에 사용하는 항목입니다. 여기서 `'chosen'`은 선호되는 응답이고, `'rejected'`는 선호되지 않는 응답입니다.\n",
    "- 목표는 모델이 거부된 응답보다 선택된 응답의 스타일을 따르도록 하는 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86257468-a6ab-4ba3-9c9f-2fdc2c0cc284",
   "metadata": {
    "id": "86257468-a6ab-4ba3-9c9f-2fdc2c0cc284"
   },
   "source": [
    "- 아래는 7장([../01_main-chapter-code/ch07.ipynb](../01_main-chapter-code/ch07.ipynb))과 유사하게 Alpaca 프롬프트 스타일을 적용하여 모델 입력을 구성하는 유틸리티 함수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4564d55c-1c5d-46a6-b5e8-46ab568ad627",
   "metadata": {
    "id": "4564d55c-1c5d-46a6-b5e8-46ab568ad627"
   },
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f38b49f-63fd-48c5-bde8-a4717b7923ea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3f38b49f-63fd-48c5-bde8-a4717b7923ea",
    "outputId": "9ad07c59-05b3-42ae-c5bc-68780aaf6780"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[50])\n",
    "print(model_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd9e4c9-88a3-463a-8c16-c60ed7e6b51e",
   "metadata": {
    "id": "7dd9e4c9-88a3-463a-8c16-c60ed7e6b51e"
   },
   "source": [
    "- 마찬가지로 Alpaca 프롬프트 스타일을 사용하여 선택된 응답과 거부된 응답의 형식을 구성할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ad5831a-e936-44e5-a5cf-02953fe7d848",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ad5831a-e936-44e5-a5cf-02953fe7d848",
    "outputId": "2c0a0cbf-c13d-43cf-fcc1-a4585c21e66f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "desired_response = f\"### Response:\\n{data[50]['chosen']}\"\n",
    "print(desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc0991f6-fef7-48ab-8dee-fbd2863f784c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fc0991f6-fef7-48ab-8dee-fbd2863f784c",
    "outputId": "cd85406c-3470-48f8-9792-63f91affd50a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Response:\n",
      "The correct spelling is obviously 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "possible_response = f\"### Response:\\n{data[50]['rejected']}\"\n",
    "print(possible_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6G3j2Q987t_g",
   "metadata": {
    "id": "6G3j2Q987t_g"
   },
   "source": [
    "&nbsp;\n",
    "## 2.2) 훈련, 검증, 테스트 세트 분할 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ce2b1e-32d7-414c-8e6b-01f21a2488c2",
   "metadata": {
    "id": "53ce2b1e-32d7-414c-8e6b-01f21a2488c2"
   },
   "source": [
    "- 다음으로 데이터셋을 훈련 데이터 85%, 검증 데이터 5%, 테스트 데이터 10%의 세 가지 하위 집합으로 나눕니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36c7b919-8531-4e33-aebf-aaf8e6dbcfbd",
   "metadata": {
    "id": "36c7b919-8531-4e33-aebf-aaf8e6dbcfbd"
   },
   "outputs": [],
   "source": [
    "train_portion = int(len(data) * 0.85)  # 훈련용 85%\n",
    "test_portion = int(len(data) * 0.1)    # 테스트용 10%\n",
    "val_portion = len(data) - train_portion - test_portion  # 나머지 5% 검증용\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "831a6c1b-119b-4622-9862-87f1db36e066",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "831a6c1b-119b-4622-9862-87f1db36e066",
    "outputId": "8e017483-1a75-4336-9540-ac6a69104e27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 길이: 935\n",
      "검증 세트 길이: 55\n",
      "테스트 세트 길이: 110\n"
     ]
    }
   ],
   "source": [
    "print(\"훈련 세트 길이:\", len(train_data))\n",
    "print(\"검증 세트 길이:\", len(val_data))\n",
    "print(\"테스트 세트 길이:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07d09f7-66af-49ed-8b9e-484f46e6a68d",
   "metadata": {
    "id": "c07d09f7-66af-49ed-8b9e-484f46e6a68d"
   },
   "source": [
    "&nbsp;\n",
    "## 2.3) `PreferenceDataset` 클래스 및 배치 처리 함수 개발"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86101174-00c8-485d-8273-d086d5311926",
   "metadata": {
    "id": "86101174-00c8-485d-8273-d086d5311926"
   },
   "source": [
    "- 이 섹션에서는 7장의 `InstructionDataset` 클래스를 DPO를 위해 다시 작성합니다.\n",
    "- 즉, 단일 출력 시퀀스(응답)에 집중하는 대신, 하나가 다른 하나보다 선호되는 응답 쌍(\"chosen\" 및 \"rejected\")을 반환하도록 데이터셋 클래스를 수정합니다.\n",
    "- 전반적으로 `PreferenceDataset`은 7장에서 사용된 `InstructionDataset`과 거의 동일합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db08ad74-6dd4-4e40-b1e5-bc5f037d3d27",
   "metadata": {
    "id": "db08ad74-6dd4-4e40-b1e5-bc5f037d3d27"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class PreferenceDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "\n",
    "        # 텍스트 미리 토큰화\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            prompt = format_input(entry)\n",
    "            rejected_response = entry[\"rejected\"]\n",
    "            chosen_response = entry[\"chosen\"]\n",
    "\n",
    "            prompt_tokens = tokenizer.encode(prompt)\n",
    "            chosen_full_text = f\"{prompt}\\n\\n### Response:\\n{chosen_response}\"\n",
    "            rejected_full_text = f\"{prompt}\\n\\n### Response:\\n{rejected_response}\"\n",
    "            chosen_full_tokens = tokenizer.encode(chosen_full_text)\n",
    "            rejected_full_tokens = tokenizer.encode(rejected_full_text)\n",
    "\n",
    "            self.encoded_texts.append({\n",
    "                \"prompt\": prompt_tokens,\n",
    "                \"chosen\": chosen_full_tokens,\n",
    "                \"rejected\": rejected_full_tokens,\n",
    "            })\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2325d183-75b9-400a-80ac-0b8d2f526561",
   "metadata": {
    "id": "2325d183-75b9-400a-80ac-0b8d2f526561"
   },
   "source": [
    "- 업데이트된 `PreferenceDataset` 클래스와 함께, 각 배치의 시퀀스를 동일한 길이로 패딩하여 배치로 묶을 수 있도록 하는 배치 병합(collation) 함수도 필요합니다.\n",
    "- 프로세스를 설명하기 위해 아래 코드에 주석을 추가했습니다. 그러나 뒷부분에 나오는 예시 입력과 출력을 보는 것이 작동 방식을 이해하는 데 가장 쉬울 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d3a43a6-7704-4bff-9bbc-a38632374f30",
   "metadata": {
    "id": "8d3a43a6-7704-4bff-9bbc-a38632374f30"
   },
   "outputs": [],
   "source": [
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    allowed_max_length=None,\n",
    "    mask_prompt_tokens=True,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # 배치 데이터를 담을 리스트 초기화\n",
    "    batch_data = {\n",
    "        \"prompt\": [],\n",
    "        \"chosen\": [],\n",
    "        \"rejected\": [],\n",
    "        \"rejected_mask\": [],\n",
    "        \"chosen_mask\": []\n",
    "\n",
    "    }\n",
    "\n",
    "    # 공통 패딩 길이를 설정하기 위해 가장 긴 시퀀스 결정\n",
    "    max_length_common = 0\n",
    "    if batch:\n",
    "        for key in [\"chosen\", \"rejected\"]:\n",
    "            current_max = max(len(item[key])+1 for item in batch)\n",
    "            max_length_common = max(max_length_common, current_max)\n",
    "\n",
    "    # 배치의 각 항목 처리\n",
    "    for item in batch:\n",
    "        prompt = torch.tensor(item[\"prompt\"])\n",
    "        batch_data[\"prompt\"].append(prompt)\n",
    "\n",
    "        for key in [\"chosen\", \"rejected\"]:\n",
    "            # 공통 최대 길이에 따라 패딩 조정\n",
    "            sequence = item[key]\n",
    "            padded = sequence + [pad_token_id] * (max_length_common - len(sequence))\n",
    "            mask = torch.ones(len(padded)).bool()\n",
    "\n",
    "            # 모든 패딩 토큰에 대한 마스크를 False로 설정\n",
    "            mask[len(sequence):] = False\n",
    "\n",
    "            # 모든 입력 프롬프트 토큰에 대한 마스크를 False로 설정\n",
    "            # +2는 \"### Response\" 앞의 두 개의 줄바꿈(\"\\n\") 토큰을 False로 설정함\n",
    "            if mask_prompt_tokens:\n",
    "                mask[:prompt.shape[0]+2] = False\n",
    "\n",
    "            batch_data[key].append(torch.tensor(padded))\n",
    "            batch_data[f\"{key}_mask\"].append(mask)\n",
    "\n",
    "    # 최종 처리\n",
    "    for key in [\"chosen\", \"rejected\", \"chosen_mask\", \"rejected_mask\"]:\n",
    "        # 주어진 키의 모든 시퀀스를 텐서로 쌓음(stack)\n",
    "        tensor_stack = torch.stack(batch_data[key])\n",
    "\n",
    "        # 선택적으로 최대 시퀀스 길이로 자름\n",
    "        if allowed_max_length is not None:\n",
    "            tensor_stack = tensor_stack[:, :allowed_max_length]\n",
    "\n",
    "        # 지정된 디바이스로 이동\n",
    "        batch_data[key] = tensor_stack.to(device)\n",
    "\n",
    "    return batch_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f3744b-9bb0-4f1e-b66b-cff35ad8fd9f",
   "metadata": {
    "id": "76f3744b-9bb0-4f1e-b66b-cff35ad8fd9f"
   },
   "source": [
    "- 사용자 정의 collate 함수를 사용하기 전에, 일부 인수가 미리 채워진 버전을 만들어 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3cc137c-7ed7-4758-a518-cc4071b2817a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d3cc137c-7ed7-4758-a518-cc4071b2817a",
    "outputId": "598e9def-9768-441a-f886-01f6ba6e250b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "디바이스: cuda\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    # 안정적인 mps 결과를 위해 PyTorch 2.9 이상 권장\n",
    "    major, minor = map(int, torch.__version__.split(\".\")[:2])\n",
    "    if (major, minor) >= (2, 9):\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"디바이스:\", device)\n",
    "\n",
    "customized_collate_fn = partial(\n",
    "    custom_collate_fn,\n",
    "    device=device,            # 가능한 경우 데이터를 GPU에 직접 배치\n",
    "    mask_prompt_tokens=True,  # 선택 사항\n",
    "    allowed_max_length=1024   # 모델이 지원하는 컨텍스트 길이\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d29e996-e267-4348-bc1d-4ac6b725cf6a",
   "metadata": {
    "id": "5d29e996-e267-4348-bc1d-4ac6b725cf6a"
   },
   "source": [
    "- 이제 `customized_collate_fn`이 실제로 어떻게 작동하는지 선호도 데이터셋의 샘플 데이터(첫 두 항목)에 적용해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1171057d-2a0f-48ff-bad6-4917a072f0f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1171057d-2a0f-48ff-bad6-4917a072f0f5",
    "outputId": "3db3eee8-db29-4ff6-8078-6577a05d953a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'instruction': 'Evaluate the following phrase by transforming it into the '\n",
      "                'spelling given.',\n",
      " 'input': 'freind --> friend',\n",
      " 'output': 'The spelling of the given phrase \"freind\" is incorrect, the '\n",
      "           'correct spelling is \"friend\".',\n",
      " 'rejected': 'The spelling of the given phrase \"freind\" is flat out wrong, get '\n",
      "             'it together, the correct spelling is \"friend\".',\n",
      " 'chosen': 'The spelling of the given phrase \"freind\" is incorrect, the '\n",
      "           'correct spelling is \"friend\".'}\n",
      "\n",
      "{'instruction': 'Edit the following sentence for grammar.',\n",
      " 'input': 'He go to the park every day.',\n",
      " 'output': 'He goes to the park every day.',\n",
      " 'rejected': 'He goes to the stupid park every single day.',\n",
      " 'chosen': 'He goes to the park every day.'}\n"
     ]
    }
   ],
   "source": [
    "example_data = data[:2]\n",
    "\n",
    "for i in example_data:\n",
    "    print()\n",
    "    pprint.pp(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1436cc-fbe5-4581-89d8-1992b5f04042",
   "metadata": {
    "id": "8f1436cc-fbe5-4581-89d8-1992b5f04042"
   },
   "source": [
    "- 다음으로 `example_dataset`을 인스턴스화하고 PyTorch `DataLoader`를 사용하여 나중에 모델 학습에 사용할 데이터 로더를 모방한 `example_dataloader`를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db327575-c34b-4fea-b3c7-e30569c9be78",
   "metadata": {
    "id": "db327575-c34b-4fea-b3c7-e30569c9be78"
   },
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "example_dataset = PreferenceDataset(example_data, tokenizer)\n",
    "\n",
    "example_dataloader = DataLoader(\n",
    "    example_dataset,\n",
    "    batch_size=2,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a446b7-7037-4d9a-9f14-b4ee0f6f37af",
   "metadata": {
    "id": "43a446b7-7037-4d9a-9f14-b4ee0f6f37af"
   },
   "source": [
    "- 데이터셋은 다음 키들을 가지고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87ed4cf9-d70a-4bc7-b676-67e76ed3ee10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "87ed4cf9-d70a-4bc7-b676-67e76ed3ee10",
    "outputId": "fa724d65-b0e1-4239-8090-9263135ad199"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.keys: dict_keys(['prompt', 'chosen', 'rejected', 'rejected_mask', 'chosen_mask'])\n"
     ]
    }
   ],
   "source": [
    "for batch in example_dataloader:\n",
    "    break\n",
    "\n",
    "print(\"batch.keys:\", batch.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bda3193-8c68-478c-98d8-0d9d880e7077",
   "metadata": {
    "id": "5bda3193-8c68-478c-98d8-0d9d880e7077"
   },
   "source": [
    "- 프롬프트는 텐서 리스트이며, 각 텐서는 주어진 예제에 대한 토큰 ID를 포함합니다. 배치 크기를 2로 선택했으므로 여기에는 두 개의 토큰 ID 텐서 리스트가 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "468995ce-2906-498f-ac99-0a3f80d13d12",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "468995ce-2906-498f-ac99-0a3f80d13d12",
    "outputId": "7f3df961-fcb5-4e49-9b0c-c99447c67cc1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
       "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
       "         21017, 46486,    25,   198,    36,  2100,  4985,   262,  1708,  9546,\n",
       "           416, 25449,   340,   656,   262, 24993,  1813,    13,   198,   198,\n",
       "         21017, 23412,    25,   198, 19503,   521, 14610,  1545]),\n",
       " tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
       "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
       "         21017, 46486,    25,   198, 18378,   262,  1708,  6827,   329, 23491,\n",
       "            13,   198,   198, 21017, 23412,    25,   198,  1544,   467,   284,\n",
       "           262,  3952,   790,  1110,    13])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"prompt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cadebe-2516-4ae0-a71f-a8a623f2e1da",
   "metadata": {
    "id": "89cadebe-2516-4ae0-a71f-a8a623f2e1da"
   },
   "source": [
    "- 학습 시 실제로 응답이 필요한 것은 아닙니다. 학습 중에 모델에 공급해야 할 것은 `\"chosen\"` 및 `\"rejected\"` 항목입니다.\n",
    "- `\"chosen\"` 및 `\"rejected\"` 응답 항목은 텐서로 쌓을 수 있도록 패딩되어 있습니다. 프롬프트와 마찬가지로 이러한 응답 텍스트는 토큰 ID로 인코딩됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8f49c56-3989-4fe9-81ac-6bb3cce1a5b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e8f49c56-3989-4fe9-81ac-6bb3cce1a5b8",
    "outputId": "ccc0bd06-6e85-4ee9-893b-d985f26a835d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
       "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
       "         21017, 46486,    25,   198,    36,  2100,  4985,   262,  1708,  9546,\n",
       "           416, 25449,   340,   656,   262, 24993,  1813,    13,   198,   198,\n",
       "         21017, 23412,    25,   198, 19503,   521, 14610,  1545,   198,   198,\n",
       "         21017, 18261,    25,   198,   464, 24993,   286,   262,  1813,  9546,\n",
       "           366, 19503,   521,     1,   318, 11491,    11,   262,  3376, 24993,\n",
       "           318,   366,  6726,  1911, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256],\n",
       "        [21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
       "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
       "         21017, 46486,    25,   198, 18378,   262,  1708,  6827,   329, 23491,\n",
       "            13,   198,   198, 21017, 23412,    25,   198,  1544,   467,   284,\n",
       "           262,  3952,   790,  1110,    13,   198,   198, 21017, 18261,    25,\n",
       "           198,  1544,  2925,   284,   262,  3952,   790,  1110,    13, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256]], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"chosen\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a4cd6d-b2ad-45a6-b00a-ba5b720be4ea",
   "metadata": {
    "id": "35a4cd6d-b2ad-45a6-b00a-ba5b720be4ea"
   },
   "source": [
    "- 위의 토큰 ID는 모델 입력을 나타내지만, 인간이 해석하기에는 어렵습니다.\n",
    "- 따라서 이를 다시 텍스트로 변환하여 쉽게 검사하고 해석할 수 있도록 작은 유틸리티 함수를 구현해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52ea54ba-32cb-4ecb-b38b-923f42fd4615",
   "metadata": {
    "id": "52ea54ba-32cb-4ecb-b38b-923f42fd4615"
   },
   "outputs": [],
   "source": [
    "def decode_tokens_from_batch(token_ids, tokenizer):\n",
    "    ids_in_python_list = token_ids.flatten().tolist()\n",
    "    return tokenizer.decode(ids_in_python_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9dd0ce-1fd4-419c-833f-ea5a1f8d800d",
   "metadata": {
    "id": "bc9dd0ce-1fd4-419c-833f-ea5a1f8d800d"
   },
   "source": [
    "- 배치의 첫 번째 프롬프트 항목에 `decode_tokens_from_batch` 유틸리티 함수를 적용해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55ee481e-3e2c-4ff6-b614-8cb18eb16a41",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "55ee481e-3e2c-4ff6-b614-8cb18eb16a41",
    "outputId": "17ddec15-a09d-45b5-b1e8-600cd59a9600"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Evaluate the following phrase by transforming it into the spelling given.\n",
      "\n",
      "### Input:\n",
      "freind --> friend\n"
     ]
    }
   ],
   "source": [
    "text = decode_tokens_from_batch(\n",
    "    token_ids=batch[\"prompt\"][0],  # [0]은 배치의 첫 번째 항목\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637b95c4-d5c2-4492-9d19-a45b090eee7e",
   "metadata": {
    "id": "637b95c4-d5c2-4492-9d19-a45b090eee7e"
   },
   "source": [
    "- 위에서 볼 수 있듯이 프롬프트 형식이 올바르게 지정되었습니다. 이제 `\"chosen\"` 응답에 대해서도 동일한 작업을 수행해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33a24f20-5ec3-4a89-b57a-52e997163d07",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33a24f20-5ec3-4a89-b57a-52e997163d07",
    "outputId": "e04366ee-3719-4b07-fcef-6e9dddc06310"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Evaluate the following phrase by transforming it into the spelling given.\n",
      "\n",
      "### Input:\n",
      "freind --> friend\n",
      "\n",
      "### Response:\n",
      "The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "text = decode_tokens_from_batch(\n",
    "    token_ids=batch[\"chosen\"][0],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9fbdbd-1cff-401f-8e6c-cd98c134c0f2",
   "metadata": {
    "id": "ac9fbdbd-1cff-401f-8e6c-cd98c134c0f2"
   },
   "source": [
    "- 위에서 볼 수 있듯이, 지시어 미세 조정과 유사하게 학습 중에 모델에 전달되는 응답에도 입력 프롬프트가 포함되어 있습니다.\n",
    "- 또한 배치를 쌓기 위해 응답을 유사한 길이로 확장하는 데 필요한 패딩 토큰으로 `<|endoftext|>` 토큰을 포함했습니다.\n",
    "- 걱정하지 마세요. `<|endoftext|>` 토큰은 나중에 손실 계산에서 무시되므로 학습 결과에 영향을 미치지 않습니다.\n",
    "- 이제 상응하는 거부된 응답도 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db382be5-c727-4299-8597-c05424ba9308",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "db382be5-c727-4299-8597-c05424ba9308",
    "outputId": "edbd8c4a-0528-4361-aeba-9b3c3bbde33b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Evaluate the following phrase by transforming it into the spelling given.\n",
      "\n",
      "### Input:\n",
      "freind --> friend\n",
      "\n",
      "### Response:\n",
      "The spelling of the given phrase \"freind\" is flat out wrong, get it together, the correct spelling is \"friend\".<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "text = decode_tokens_from_batch(\n",
    "    token_ids=batch[\"rejected\"][0],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715dc968-aa64-4388-b577-7c295831bdcf",
   "metadata": {
    "id": "715dc968-aa64-4388-b577-7c295831bdcf"
   },
   "source": [
    "- 이 경우 위에서 볼 수 있듯이 거부된 응답은 선택된 응답보다 무례한 버전입니다(모델이 무례한 응답을 생성하는 것을 원치 않습니다).\n",
    "- 마지막으로 데이터 마스크에 대해 이야기해 보겠습니다. 위에서 구현한 사용자 정의 collate 함수를 자세히 살펴보면 각 데이터셋 항목에 대해 `\"chosen_mask\"`와 `\"rejected_mask\"`를 생성했습니다.\n",
    "- 마스크는 아래 `\"chosen\"` 항목에 대해 표시된 것처럼 응답 항목과 동일한 모양을 가집니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c324eab-cf1d-4071-b3ba-797d8ec4d1da",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5c324eab-cf1d-4071-b3ba-797d8ec4d1da",
    "outputId": "742a5742-1bc0-4f74-9eb9-cbf81f936ecb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "선택된 입력 모양: torch.Size([81])\n",
      "선택된 마스크 모양: torch.Size([81])\n"
     ]
    }
   ],
   "source": [
    "print(\"선택된 입력 모양:\", batch[\"chosen\"][0].shape)\n",
    "print(\"선택된 마스크 모양:\", batch[\"chosen_mask\"][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880e95f7-cfc3-4f5f-be5e-c279fba5f674",
   "metadata": {
    "id": "880e95f7-cfc3-4f5f-be5e-c279fba5f674"
   },
   "source": [
    "- 이 마스크의 내용은 불리언(`True` 및 `False`) 값입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da75b550-5da4-4292-9a7e-a05b842bdcb7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "da75b550-5da4-4292-9a7e-a05b842bdcb7",
    "outputId": "e5f012c3-33ba-4e6b-aa55-3e331865218f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True, False, False, False, False, False, False,\n",
       "        False], device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"chosen_mask\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e67b862-4430-4c99-9157-90955dde29b6",
   "metadata": {
    "id": "0e67b862-4430-4c99-9157-90955dde29b6"
   },
   "source": [
    "- `True` 값은 실제 응답에 해당하는 토큰 ID를 나타냅니다.\n",
    "- `False` 토큰은 프롬프트 토큰(`customized_collate_fn` 함수에서 `mask_prompt_tokens=True`로 설정한 경우) 또는 패딩 토큰에 해당하는 토큰 ID를 나타냅니다.\n",
    "- 따라서 마스크를 선택 마스크로 사용하여 실제 응답에 해당하는 토큰 ID만 선택할 수 있습니다. 즉, 아래에서 볼 수 있듯이 모든 프롬프트 및 패딩 토큰을 제거할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1114c6fe-524b-401c-b9fe-02260e6f0541",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1114c6fe-524b-401c-b9fe-02260e6f0541",
    "outputId": "6d99af1d-940a-4012-c5d9-21d463a66e40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Response:\n",
      "The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".\n"
     ]
    }
   ],
   "source": [
    "text = decode_tokens_from_batch(\n",
    "    token_ids=batch[\"chosen\"][0][batch[\"chosen_mask\"][0]],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a89f83a4-d16e-40d2-ba43-bd410affd967",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a89f83a4-d16e-40d2-ba43-bd410affd967",
    "outputId": "1d439c7e-c079-4594-d02a-fa83a3cb275d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Response:\n",
      "The spelling of the given phrase \"freind\" is flat out wrong, get it together, the correct spelling is \"friend\".\n"
     ]
    }
   ],
   "source": [
    "text = decode_tokens_from_batch(\n",
    "    token_ids=batch[\"rejected\"][0][batch[\"rejected_mask\"][0]],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e525287f-137c-4d71-94ae-cfd6db7b057c",
   "metadata": {
    "id": "e525287f-137c-4d71-94ae-cfd6db7b057c"
   },
   "source": [
    "- 나중에 DPO 손실을 계산할 때 프롬프트와 패딩 토큰을 무시하기 위해 이 마스크를 활용할 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jbafhM_R8z5q",
   "metadata": {
    "id": "jbafhM_R8z5q"
   },
   "source": [
    "&nbsp;\n",
    "## 2.4) 훈련, 검증, 테스트 세트 데이터 로더 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c29eb8-d1b9-4abe-a155-52b3270d759a",
   "metadata": {
    "id": "b3c29eb8-d1b9-4abe-a155-52b3270d759a"
   },
   "source": [
    "- 위에서는 설명을 위해 선호도 데이터셋의 작은 예제 하위 집합을 사용했습니다.\n",
    "- 이제 실제 훈련, 검증 및 테스트 세트 데이터 로더를 만들어 보겠습니다.\n",
    "- 이 프로세스는 사전 학습 및 지시어 미세 조정 장에서의 데이터 로더 생성과 동일하므로 자명할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c0068bf-bda0-4d9e-9f79-2fc4b94cbd1c",
   "metadata": {
    "id": "5c0068bf-bda0-4d9e-9f79-2fc4b94cbd1c"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = PreferenceDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f4a257b-6835-4194-abe2-5831d6a44885",
   "metadata": {
    "id": "2f4a257b-6835-4194-abe2-5831d6a44885"
   },
   "outputs": [],
   "source": [
    "val_dataset = PreferenceDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = PreferenceDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe1ba19-a6d5-4a77-8283-7a17d7ec06e2",
   "metadata": {
    "id": "1fe1ba19-a6d5-4a77-8283-7a17d7ec06e2"
   },
   "source": [
    "- 데이터 로더를 반복하며 데이터셋의 모양(shape)을 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80d61f15-facb-4eb8-a9be-6427887d24b2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "80d61f15-facb-4eb8-a9be-6427887d24b2",
    "outputId": "dacd3bdf-f069-4b36-da2c-d6c1c6cc5405"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 로더:\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 94]) torch.Size([8, 94])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 99]) torch.Size([8, 99])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 97]) torch.Size([8, 97])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 101]) torch.Size([8, 101])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n",
      "torch.Size([8, 92]) torch.Size([8, 92])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 100]) torch.Size([8, 100])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 92]) torch.Size([8, 92])\n",
      "torch.Size([8, 93]) torch.Size([8, 93])\n",
      "torch.Size([8, 115]) torch.Size([8, 115])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 95]) torch.Size([8, 95])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 94]) torch.Size([8, 94])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 90]) torch.Size([8, 90])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 85]) torch.Size([8, 85])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 93]) torch.Size([8, 93])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 99]) torch.Size([8, 99])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 86]) torch.Size([8, 86])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 97]) torch.Size([8, 97])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 85]) torch.Size([8, 85])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 85]) torch.Size([8, 85])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 92]) torch.Size([8, 92])\n",
      "torch.Size([8, 85]) torch.Size([8, 85])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 93]) torch.Size([8, 93])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 93]) torch.Size([8, 93])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 90]) torch.Size([8, 90])\n",
      "torch.Size([8, 99]) torch.Size([8, 99])\n",
      "torch.Size([8, 104]) torch.Size([8, 104])\n",
      "torch.Size([8, 101]) torch.Size([8, 101])\n",
      "torch.Size([8, 98]) torch.Size([8, 98])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 85]) torch.Size([8, 85])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n"
     ]
    }
   ],
   "source": [
    "print(\"훈련 로더:\")\n",
    "for batch in train_loader:\n",
    "    print(\n",
    "        batch[\"chosen\"].shape,\n",
    "        batch[\"rejected\"].shape,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff958a6-5e61-49f5-9a97-360aa34e3758",
   "metadata": {
    "id": "7ff958a6-5e61-49f5-9a97-360aa34e3758"
   },
   "source": [
    "- 각 행은 각 배치의 `\"chosen\"` 및 `\"rejected\"` 항목의 모양을 보여줍니다.\n",
    "- 배치별로 패딩을 적용했기 때문에 각 행마다 모양이 다릅니다.\n",
    "- 이는 효율성을 위한 것으로, 전체 데이터셋에서 가장 긴 샘플에 맞춰 모든 샘플을 패딩하는 것은 비효율적이기 때문입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cb0543-1142-4374-8825-3384e20c6ac0",
   "metadata": {
    "id": "29cb0543-1142-4374-8825-3384e20c6ac0"
   },
   "source": [
    "&nbsp;\n",
    "# 3) DPO 정렬을 위한 미세 조정된 LLM 로드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b08881-b769-4b26-8153-5ec0e8573ed2",
   "metadata": {
    "id": "22b08881-b769-4b26-8153-5ec0e8573ed2"
   },
   "source": [
    "- RLHF 또는 DPO와 같은 LLM 정렬 단계는 이미 지시어 미세 조정된 모델이 있다고 가정합니다.\n",
    "- 이 섹션에는 7장에서 지시어 미세 조정을 거쳐 저장된 모델을 로드하기 위한 최소한의 코드가 포함되어 있습니다.\n",
    "- 진행하기 전에 7장 코드를 먼저 실행하여 미세 조정된 모델을 생성했는지 확인하세요.\n",
    "- 아래 코드는 미세 조정된 모델을 현재 디렉토리로 복사합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3c6d82b-63f7-459a-b901-7125ab225e56",
   "metadata": {
    "id": "b3c6d82b-63f7-459a-b901-7125ab225e56"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "\n",
    "finetuned_model_path = Path(\"outputs/gpt2-medium355M-sft.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c8585e-4569-4033-84a7-3903d0e8aaf8",
   "metadata": {
    "id": "71c8585e-4569-4033-84a7-3903d0e8aaf8"
   },
   "source": [
    "- 다음으로 이전 장의 기본 설정을 재사용하여 모델 가중치를 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a8333fee-e7fe-4f8c-9411-8c1db6252d98",
   "metadata": {
    "id": "a8333fee-e7fe-4f8c-9411-8c1db6252d98"
   },
   "outputs": [],
   "source": [
    "from previous_chapters import GPTModel\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # 어휘 사전 크기\n",
    "    \"context_length\": 1024,  # 컨텍스트 길이\n",
    "    \"drop_rate\": 0.0,        # 드롭아웃 비율\n",
    "    \"qkv_bias\": True         # Query-key-value 바이어스\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c2821403-605c-4071-a4ff-e23f4c9a11fd",
   "metadata": {
    "id": "c2821403-605c-4071-a4ff-e23f4c9a11fd"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        \"outputs/gpt2-medium355M-sft.pth\",\n",
    "        map_location=torch.device(\"cpu\"),\n",
    "        weights_only=True\n",
    "    )\n",
    ")\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61863bec-bd42-4194-b994-645bfe2df8be",
   "metadata": {
    "id": "61863bec-bd42-4194-b994-645bfe2df8be"
   },
   "source": [
    "- DPO로 로드된 모델을 학습하기 전에, 샘플 데이터로 테스트하여 미세 조정된 모델이 올바르게 저장되고 로드되었는지 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4357aec5-0db2-4d73-b37b-539cd8fa80a3",
   "metadata": {
    "id": "4357aec5-0db2-4d73-b37b-539cd8fa80a3"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"Below is an instruction that describes a task. Write a response\n",
    "that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "541e7988-38d3-47f6-bd52-9da6564479fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "541e7988-38d3-47f6-bd52-9da6564479fa",
    "outputId": "278f7ddf-37c2-4c3a-d069-c510ef6f8d7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response\n",
      "that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "### Response:\n",
      "The meal is cooked every day by the chef.\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import (\n",
    "    generate,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(prompt, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256\n",
    ")\n",
    "\n",
    "response = token_ids_to_text(token_ids, tokenizer)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be87ed19-fded-4e56-8585-6c7c0367b354",
   "metadata": {
    "id": "be87ed19-fded-4e56-8585-6c7c0367b354"
   },
   "source": [
    "- 위에서 볼 수 있듯이 모델은 합리적이고 올바른 응답을 제공합니다.\n",
    "- 7장에서 설명했듯이 실제로는 프롬프트와 프롬프트 스타일이 제거된 응답 텍스트만 반환하도록 응답을 정리합니다(예: ChatGPT와 유사하게)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c30c4e2-af84-4ab4-95d0-9641e32c1e7f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0c30c4e2-af84-4ab4-95d0-9641e32c1e7f",
    "outputId": "70192bbe-fdf6-43eb-c673-f573f8c70156"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The meal is cooked every day by the chef.\n"
     ]
    }
   ],
   "source": [
    "def extract_response(response_text, input_text):\n",
    "    return response_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "\n",
    "response = extract_response(response, prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80442cb9-83b1-46b8-bad0-7d44297ca52d",
   "metadata": {
    "id": "80442cb9-83b1-46b8-bad0-7d44297ca52d"
   },
   "source": [
    "- 이제 DPO 파트로 들어갈 준비가 거의 다 되었습니다.\n",
    "- 이 노트북의 시작 부분에서 언급했듯이, DPO는 두 개의 LLM과 함께 작동합니다. 하나는 정책(policy) 모델(최적화하려는 LLM)이고 다른 하나는 참조(reference) 모델(변경하지 않고 유지하는 원본 모델)입니다.\n",
    "- **참조 모델(Reference Model)**이 반드시 필요한 이유는, 학습 중인 정책 모델(Policy Model)이 \"말도 안 되는 소리를 하면서 점수만 따려는 꼼수\"를 부리지 못하게 막는 '안전장치(Anchor)' 역할을 하기 때문입니다.\n",
    "- 아래에서는 `model`의 이름을 `policy_model`로 변경하고 `reference_model`이라는 두 번째 모델 인스턴스를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5d88cc3a-312e-4b29-bc6d-de8354c1eb9f",
   "metadata": {
    "id": "5d88cc3a-312e-4b29-bc6d-de8354c1eb9f"
   },
   "outputs": [],
   "source": [
    "policy_model = model\n",
    "\n",
    "reference_model = GPTModel(BASE_CONFIG)\n",
    "reference_model.load_state_dict(\n",
    "    torch.load(\n",
    "        \"outputs/gpt2-medium355M-sft.pth\",\n",
    "        map_location=torch.device(\"cpu\"),\n",
    "        weights_only=True\n",
    "    )\n",
    ")\n",
    "reference_model.eval()\n",
    "\n",
    "policy_model.to(device)\n",
    "reference_model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6c1469-0038-4914-8aa5-15b1f81877cc",
   "metadata": {
    "id": "9c6c1469-0038-4914-8aa5-15b1f81877cc"
   },
   "source": [
    "&nbsp;\n",
    "# 4) DPO 손실 함수 코딩하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dbe60c-e4ce-413e-beec-22eff0237d11",
   "metadata": {
    "id": "75dbe60c-e4ce-413e-beec-22eff0237d11"
   },
   "source": [
    "- 이전 섹션에서 모델 로딩과 데이터셋 준비를 마쳤으므로 이제 핵심인 DPO 손실 함수를 코딩해 보겠습니다.\n",
    "- 아래 DPO 손실 코드는 [Direct Preference Optimization: Your Language Model is Secretly a Reward Model](https://arxiv.org/abs/2305.18290) 논문에서 제안된 방법을 기반으로 합니다.\n",
    "- 참고로 핵심 DPO 방정식은 아래와 같습니다.\n",
    "\n",
    "<img src=\"images/llm_from_scratch/dpo/3.webp\" width=800px>\n",
    "\n",
    "- 수식의 구성 요소:\n",
    "  - 기댓값 $\\mathbb{E}$를 최적화하여 모델을 사용자 선호도에 정렬합니다.\n",
    "  - $\\pi_{\\theta}$는 최적화할 정책 모델, $\\pi_{ref}$는 참조 모델입니다.\n",
    "  - $\\beta$는 정책 모델과 참조 모델 간의 차이 영향을 제어하는 하이퍼파라미터입니다.\n",
    "  - $\\sigma(\\centerdot)$는 로지스틱 시그모이드 함수입니다.\n",
    "- 코드에서 DPO 손실은 다음과 같이 구현할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "38CsrrwJIZiV",
   "metadata": {
    "id": "38CsrrwJIZiV"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def compute_dpo_loss(\n",
    "    policy_chosen_logps,   # Policy 모델의 선호 답변 로그 확률\n",
    "    policy_rejected_logps, # Policy 모델의 비선호 답변 로그 확률\n",
    "    ref_chosen_logps,      # Reference 모델의 선호 답변 로그 확률\n",
    "    ref_rejected_logps,    # Reference 모델의 비선호 답변 로그 확률\n",
    "    beta=0.1,              # KL Divergence 제약 강도 (하이퍼파라미터)\n",
    "):\n",
    "    \"\"\"\n",
    "    DPO 손실을 계산하는 함수\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. 선호 답변에 대한 점수 (Policy - Reference)\n",
    "    # Policy가 Reference보다 얼마나 더 이 답변을 \"확신\"하는가?\n",
    "    chosen_logratios = policy_chosen_logps - ref_chosen_logps\n",
    "    \n",
    "    # 2. 비선호 답변에 대한 점수 (Policy - Reference)\n",
    "    rejected_logratios = policy_rejected_logps - ref_rejected_logps\n",
    "    \n",
    "    # 3. 두 점수의 차이 계산\n",
    "    # 목표: (선호 답변 점수) > (비선호 답변 점수)가 되어야 함\n",
    "    logits = chosen_logratios - rejected_logratios\n",
    "    \n",
    "    # 4. 손실 계산\n",
    "    # -log(sigmoid(beta * logits))\n",
    "    # logits가 클수록(양수일수록) sigmoid는 1에 가까워지고, -log는 0에 가까워짐 (Loss 감소)\n",
    "    # 반대로 logits가 음수면 Loss가 커짐\n",
    "    losses = -F.logsigmoid(beta * logits)\n",
    "    \n",
    "    # 5. 보상(Reward) 추적 (학습 모니터링 용도)\n",
    "    # 실제 학습에는 losses만 쓰이지만, 디버깅을 위해 보상값도 리턴\n",
    "    chosen_rewards = beta * chosen_logratios.detach()\n",
    "    rejected_rewards = beta * rejected_logratios.detach()\n",
    "    \n",
    "    return losses.mean(), chosen_rewards, rejected_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693be65b-38fc-4d18-bf53-a260a15436e1",
   "metadata": {
    "id": "693be65b-38fc-4d18-bf53-a260a15436e1"
   },
   "source": [
    "- 로그에 익숙하다면 $\\log\\left(\\frac{a}{b}\\right) = \\log a - \\log b$ 관계가 코드에 적용되었음을 알 수 있습니다.\n",
    "- 이를 염두에 두고 단계를 살펴보겠습니다(나중에 별도의 함수로 `logprobs`를 계산할 것입니다).\n",
    "- 다음 줄부터 시작합니다.\n",
    "\n",
    "    ```python\n",
    "    model_logratios = model_chosen_logprobs - model_rejected_logprobs\n",
    "    reference_logratios = reference_chosen_logprobs - reference_rejected_logprobs\n",
    "    ```\n",
    "\n",
    "- 위 줄은 정책 모델과 참조 모델 모두에 대해 선택된 샘플과 거부된 샘플의 로그 확률 차이(logits)를 계산합니다.\n",
    "\n",
    "$$\\log \\left( \\frac{\\pi_\\theta (y_w \\mid x)}{\\pi_\\theta (y_l \\mid x)} \\right) \\quad \\text{및} \\quad \\log \\left( \\frac{\\pi_{\\text{ref}}(y_w \\mid x)}{\\pi_{\\text{ref}}(y_l \\mid x)} \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5458d217-e0ad-40a5-925c-507a8fcf5795",
   "metadata": {
    "id": "5458d217-e0ad-40a5-925c-507a8fcf5795"
   },
   "source": [
    "- 다음으로 코드 `logits = model_logratios - reference_logratios`는 모델의 로그 비율과 참조 모델의 로그 비율 간의 차이를 계산합니다.\n",
    "\n",
    "$$\\beta \\log \\left( \\frac{\\pi_\\theta (y_w \\mid x)}{\\pi_{\\text{ref}} (y_w \\mid x)} \\right)\n",
    "- \\beta \\log \\left( \\frac{\\pi_\\theta (y_l \\mid x)}{\\pi_{\\text{ref}} (y_l \\mid x)} \\right)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18e3e36-f5f1-407f-b662-4c20a0ac0354",
   "metadata": {
    "id": "f18e3e36-f5f1-407f-b662-4c20a0ac0354"
   },
   "source": [
    "- 마지막으로 `losses = -F.logsigmoid(beta * logits)`는 로그 시그모이드 함수를 사용하여 손실을 계산합니다. 원본 수식에서 기댓값 내부 항은 다음과 같습니다.\n",
    "\n",
    "$$\\log \\sigma \\left( \\beta \\log \\left( \\frac{\\pi_\\theta (y_w \\mid x)}{\\pi_{\\text{ref}} (y_w \\mid x)} \\right)\n",
    "- \\beta \\log \\left( \\frac{\\pi_\\theta (y_l \\mid x)}{\\pi_{\\text{ref}} (y_l \\mid x)} \\right) \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a6f92d-7d64-41fe-bcaa-2bddd46027e1",
   "metadata": {
    "id": "00a6f92d-7d64-41fe-bcaa-2bddd46027e1"
   },
   "source": [
    "- 위에서는 로그 확률이 이미 계산되었다고 가정했습니다. 이제 `compute_dpo_loss` 함수로 전달될 $\\pi_\\theta (y_w \\mid x)$, ${\\pi_\\theta (y_l \\mid x)}$ 등의 값을 계산하는 `compute_logprobs` 함수를 정의해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "71e6507b-d2e2-4469-86b9-f057b08b5df9",
   "metadata": {
    "id": "71e6507b-d2e2-4469-86b9-f057b08b5df9"
   },
   "outputs": [],
   "source": [
    "def compute_logprobs(logits, labels, selection_mask=None):\n",
    "    \"\"\"\n",
    "    로그 확률을 계산합니다.\n",
    "\n",
    "    인수:\n",
    "      logits: (batch_size, num_tokens, vocab_size) 모양의 텐서\n",
    "      labels: (batch_size, num_tokens) 모양의 텐서\n",
    "      selection_mask: (batch_size, num_tokens) 모양의 텐서\n",
    "\n",
    "    반환:\n",
    "      mean_log_prob: 패딩 토큰을 제외한 평균 로그 확률.\n",
    "    \"\"\"\n",
    "\n",
    "    # 레이블은 입력을 한 칸씩 밀어낸 것임\n",
    "    labels = labels[:, 1:].clone()\n",
    "\n",
    "    # 레이블의 num_tokens에 맞게 로짓을 자름\n",
    "    logits = logits[:, :-1, :]\n",
    "\n",
    "    log_probs = F.log_softmax(logits, dim=-1)\n",
    "\n",
    "    # 실제 레이블에 해당하는 로그 확률 수집\n",
    "    selected_log_probs = torch.gather(\n",
    "        input=log_probs,\n",
    "        dim=-1,\n",
    "        index=labels.unsqueeze(-1)\n",
    "    ).squeeze(-1)\n",
    "\n",
    "    if selection_mask is not None:\n",
    "        mask = selection_mask[:, 1:].clone()\n",
    "\n",
    "        # 패딩 토큰을 필터링하기 위해 마스크 적용\n",
    "        selected_log_probs = selected_log_probs * mask\n",
    "\n",
    "        # 패딩 토큰을 제외한 평균 로그 확률 계산\n",
    "        avg_log_prob = selected_log_probs.sum(-1) / mask.sum(-1)\n",
    "\n",
    "        return avg_log_prob\n",
    "\n",
    "    else:\n",
    "        return selected_log_probs.mean(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6a71ac-3fcc-44a4-befc-1c56bbd378d7",
   "metadata": {
    "id": "cf6a71ac-3fcc-44a4-befc-1c56bbd378d7"
   },
   "source": [
    "- `torch.gather` 함수 때문에 처음에는 이 함수가 다소 위협적으로 보일 수 있지만, 실제로는 PyTorch의 `cross_entropy` 함수 내부에서 일어나는 일과 매우 유사합니다.\n",
    "- 예를 들어 다음 샘플 데이터를 고려해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "59873470-464d-4be2-860f-cbb7ac2d80ba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "59873470-464d-4be2-860f-cbb7ac2d80ba",
    "outputId": "8f7b47d4-73fe-4605-c17d-ad6cfd909a9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4185) tensor(1.4185)\n"
     ]
    }
   ],
   "source": [
    "# 샘플 데이터\n",
    "logits = torch.tensor(\n",
    "    [[2.0, 1.0, 0.1],\n",
    "     [0.5, 2.5, 0.3]])  # 모양: (2, 3)\n",
    "targets = torch.tensor([0, 2])  # 모양: (2,)\n",
    "\n",
    "\n",
    "# torch.gather를 사용한 수동 손실 계산\n",
    "log_softmax_logits = F.log_softmax(logits, dim=1)  # 모양: (2, 3)\n",
    "selected_log_probs = torch.gather(\n",
    "    input=log_softmax_logits,\n",
    "    dim=1,\n",
    "    index=targets.unsqueeze(1), # 모양 2, 1\n",
    ").squeeze(1)  # 모양: (2,)\n",
    "manual_loss = -selected_log_probs.mean()  # 배치의 평균 계산\n",
    "\n",
    "\n",
    "# PyTorch 손실\n",
    "cross_entropy_loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "print(manual_loss, cross_entropy_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86d7add-f7ff-4a87-9193-7878c42bf0e7",
   "metadata": {
    "id": "f86d7add-f7ff-4a87-9193-7878c42bf0e7"
   },
   "source": [
    "- 따라서 위 두 구현이 동일함을 확인할 수 있습니다. `torch.gather` 메커니즘을 좀 더 좁혀서 살펴보겠습니다.\n",
    "- 다음 두 텐서를 고려해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "508db6ba-cc40-479f-a996-2250cf862388",
   "metadata": {
    "id": "508db6ba-cc40-479f-a996-2250cf862388"
   },
   "outputs": [],
   "source": [
    "t = torch.tensor(\n",
    "  [[1., 2.,],\n",
    "   [3., 4.]]\n",
    ")\n",
    "\n",
    "m = torch.tensor(\n",
    "  [[1, 1],\n",
    "   [0, 1]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821cbf45-8fbb-47b7-bae8-6c3271e36979",
   "metadata": {
    "id": "821cbf45-8fbb-47b7-bae8-6c3271e36979"
   },
   "source": [
    "- 위에서 `t`는 선택하려는 텐서이고, `m`은 선택 방법을 지정하는 마스크입니다.\n",
    " - 예를 들어 `m`의 첫 번째 행이 `[1, 1]`이므로 `t`의 인덱스 1 위치에 있는 값(값 2)을 두 번 선택합니다.\n",
    " - `m`의 두 번째 행 `[0, 1]`은 `t`의 두 번째 행에서 인덱스 0과 1 위치인 `3.`과 `4.`를 선택합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4fdN5q1YPAbM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4fdN5q1YPAbM",
    "outputId": "e935e8ad-1519-4c4b-dbff-65adae0a15a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.gather(input=t, dim=-1, index=m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10eeaf4-f24b-4e79-916a-abedf74fe4a3",
   "metadata": {
    "id": "d10eeaf4-f24b-4e79-916a-abedf74fe4a3"
   },
   "source": [
    "- 즉, `torch.gather`는 선택 함수입니다.\n",
    "- 앞서 손실을 계산할 때 50,257개의 토큰 어휘 사전에서 올바른 토큰에 해당하는 로그 확률을 가져오는 데 이를 사용했습니다.\n",
    "- 여기서 \"올바른\" 토큰은 응답 항목에 주어진 토큰입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d10a43-ee5b-47ed-9d55-ddd96e66cf0b",
   "metadata": {
    "id": "d5d10a43-ee5b-47ed-9d55-ddd96e66cf0b"
   },
   "source": [
    "- `compute_logprobs` 함수에 관해서, 우리는 `cross_entropy`보다 조금 더 많은 제어를 할 수 있기 때문에 여기서 `torch.gather`를 사용하지만 본질적으로는 유사한 개념입니다.\n",
    "- 여기서 사용하는 `selection_mask`는 선택적으로 프롬프트 및 패딩 토큰을 무시하기 위한 것입니다.\n",
    "- 그런 다음 `compute_logprobs` 함수를 다음과 같이 사용하여 `compute_dpo_loss` 손실 함수에 대한 입력을 계산할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dfa7a4db-eba0-47d8-ad6d-7b5e7676e318",
   "metadata": {
    "id": "dfa7a4db-eba0-47d8-ad6d-7b5e7676e318"
   },
   "outputs": [],
   "source": [
    "def compute_dpo_loss_batch(batch, policy_model, reference_model, beta):\n",
    "    \"\"\"입력 배치에 대한 DPO 손실 계산\"\"\"\n",
    "\n",
    "    policy_chosen_log_probas = compute_logprobs(\n",
    "        logits=policy_model(batch[\"chosen\"]),\n",
    "        labels=batch[\"chosen\"],\n",
    "        selection_mask=batch[\"chosen_mask\"]\n",
    "    )\n",
    "    policy_rejected_log_probas = compute_logprobs(\n",
    "        logits=policy_model(batch[\"rejected\"]),\n",
    "        labels=batch[\"rejected\"],\n",
    "        selection_mask=batch[\"rejected_mask\"]\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        ref_chosen_log_probas = compute_logprobs(\n",
    "            logits=reference_model(batch[\"chosen\"]),\n",
    "            labels=batch[\"chosen\"],\n",
    "            selection_mask=batch[\"chosen_mask\"]\n",
    "        )\n",
    "        ref_rejected_log_probas = compute_logprobs(\n",
    "            logits=reference_model(batch[\"rejected\"]),\n",
    "            labels=batch[\"rejected\"],\n",
    "            selection_mask=batch[\"rejected_mask\"]\n",
    "        )\n",
    "    loss, chosen_rewards, rejected_rewards = compute_dpo_loss(\n",
    "        policy_chosen_logps=policy_chosen_log_probas,   # 정의된 이름으로 수정\n",
    "        policy_rejected_logps=policy_rejected_log_probas,\n",
    "        ref_chosen_logps=ref_chosen_log_probas,\n",
    "        ref_rejected_logps=ref_rejected_log_probas,\n",
    "        beta=beta\n",
    "    )\n",
    "    return loss, chosen_rewards, rejected_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28caafb-f378-4332-a142-3e0f9ef67fbb",
   "metadata": {
    "id": "b28caafb-f378-4332-a142-3e0f9ef67fbb"
   },
   "source": [
    "- 위 함수는 단일 배치에 대해 작동합니다. 예를 들어:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dd74fcc4-4280-41e9-9a22-838e85c84ee4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dd74fcc4-4280-41e9-9a22-838e85c84ee4",
    "outputId": "65a70828-7dd2-4f72-ffec-45aeaf8afad0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(0.6931, device='cuda:0'), tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'), tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    loss = compute_dpo_loss_batch(batch, policy_model, reference_model, beta=0.1)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17429cd-2a00-41c8-9f16-38b1c9a5179f",
   "metadata": {
    "id": "b17429cd-2a00-41c8-9f16-38b1c9a5179f"
   },
   "source": [
    "- 아래에서는 데이터 로더의 지정된 `num_batches`에 대해 작동하도록 이 함수를 확장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "682e9ad5-c5de-4d1b-9e93-3918bf5d5302",
   "metadata": {
    "id": "682e9ad5-c5de-4d1b-9e93-3918bf5d5302"
   },
   "outputs": [],
   "source": [
    "def compute_dpo_loss_loader(data_loader, policy_model, reference_model, beta, num_batches=None):\n",
    "    \"\"\"전체 데이터 로더에 compute_dpo_loss_batch 적용\"\"\"\n",
    "\n",
    "    total_loss, total_chosen_rewards, total_rejected_rewards = 0., 0., 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss, chosen_rewards, rejected_rewards = compute_dpo_loss_batch(\n",
    "                batch=batch,\n",
    "                policy_model=policy_model,\n",
    "                reference_model=reference_model,\n",
    "                beta=beta\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "            total_chosen_rewards += chosen_rewards.item()\n",
    "            total_rejected_rewards += rejected_rewards.item()\n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # 평균 계산\n",
    "    total_loss /= num_batches\n",
    "    total_chosen_rewards /= num_batches\n",
    "    total_rejected_rewards /= num_batches\n",
    "    return total_loss, total_chosen_rewards, total_rejected_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852e4c09-d285-44d5-be12-d29769950cb6",
   "metadata": {
    "id": "852e4c09-d285-44d5-be12-d29769950cb6"
   },
   "source": [
    "- 왜 `num_batches`를 지정하나요? 그것은 순전히 효율성을 위해서입니다. 매번 전체 데이터셋에 대해 손실을 계산하면 학습 속도가 현저히 느려지기 때문입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cca95b7-18fe-4076-9138-f70f21607b8c",
   "metadata": {
    "id": "2cca95b7-18fe-4076-9138-f70f21607b8c"
   },
   "source": [
    "- 마지막으로 나중에 학습 함수에서 사용할 편의 함수를 정의합니다. 이 `evaluate_dpo_loss_loader` 함수는 로깅 목적으로 훈련 및 검증 로더 모두에 대해 DPO 손실과 보상을 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c3d214ec-49ba-4bf0-ac80-f90fa0d832e9",
   "metadata": {
    "id": "c3d214ec-49ba-4bf0-ac80-f90fa0d832e9"
   },
   "outputs": [],
   "source": [
    "def evaluate_dpo_loss_loader(policy_model, reference_model, train_loader, val_loader, beta, eval_iter):\n",
    "    \"\"\"훈련 및 검증 데이터셋에 대한 DPO 손실 계산\"\"\"\n",
    "\n",
    "    policy_model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss, train_chosen_rewards, train_rejected_rewards = compute_dpo_loss_loader(\n",
    "            data_loader=train_loader,\n",
    "            policy_model=policy_model,\n",
    "            reference_model=reference_model,\n",
    "            beta=beta,\n",
    "            num_batches=eval_iter\n",
    "        )\n",
    "\n",
    "        val_loss, val_chosen_rewards, val_rejected_rewards = compute_dpo_loss_loader(\n",
    "            data_loader=val_loader,\n",
    "            policy_model=policy_model,\n",
    "            reference_model=reference_model,\n",
    "            beta=beta,\n",
    "            num_batches=eval_iter\n",
    "        )\n",
    "\n",
    "    res = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_chosen_reward\": train_chosen_rewards,\n",
    "        \"train_rejected_reward\": train_rejected_rewards,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_chosen_reward\": val_chosen_rewards,\n",
    "        \"val_rejected_reward\": val_rejected_rewards\n",
    "    }\n",
    "\n",
    "    policy_model.train()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e95ed92-6743-4f13-8b91-0fbf2e540de1",
   "metadata": {
    "id": "6e95ed92-6743-4f13-8b91-0fbf2e540de1"
   },
   "source": [
    "- 이 섹션에서 많은 내용을 다루었습니다. 간략하게 요약하면 다음과 같습니다.\n",
    "  - 흐름: 모델을 통해 `logits` 계산 $\\rightarrow$ 로짓으로부터 `compute_logprobs` 계산 $\\rightarrow$ 로그 확률로부터 `compute_dpo_loss` 계산.\n",
    "  - 이 과정을 돕는 `compute_dpo_loss_batch` 함수를 만들었습니다.\n",
    "  - `compute_dpo_loss_loader` 유틸리티 함수는 이를 데이터 로더에 적용합니다.\n",
    "  - `evaluate_dpo_loss_loader` 함수는 로깅을 위해 훈련 및 검증 세트 데이터 로더에 적용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8a8f18-536e-4d83-a0d0-ac518a85f157",
   "metadata": {
    "id": "cb8a8f18-536e-4d83-a0d0-ac518a85f157"
   },
   "source": [
    "&nbsp;\n",
    "# 5) 모델 훈련하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b11d63d-3ddc-4070-9b2b-5ca0edb08d0c",
   "metadata": {
    "id": "4b11d63d-3ddc-4070-9b2b-5ca0edb08d0c"
   },
   "source": [
    "- 이전 섹션에서 DPO 손실 함수를 설정했으므로 이제 마침내 모델을 훈련할 수 있습니다.\n",
    "- 이 훈련 함수는 몇 가지 사소한 차이점을 제외하고는 사전 학습 및 지시어 미세 조정에 사용했던 것과 동일합니다.\n",
    " - 교차 엔트로피 손실을 새로운 DPO 손실 함수로 교체했습니다.\n",
    " - 학습 진행 상황을 추적하기 위해 RLHF 및 DPO 컨텍스트에서 흔히 사용되는 보상(reward) 및 보상 마진(reward margins)도 추적합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820d4904-f819-4d62-bfb4-85cf28863683",
   "metadata": {
    "id": "820d4904-f819-4d62-bfb4-85cf28863683"
   },
   "source": [
    "- 학습을 시작하기 전에 초기 손실과 보상을 출력해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f90d9325-77b2-417f-88ff-0a5174889413",
   "metadata": {
    "id": "f90d9325-77b2-417f-88ff-0a5174889413"
   },
   "outputs": [],
   "source": [
    "from previous_chapters import generate_and_print_sample\n",
    "\n",
    "def train_model_dpo_simple(\n",
    "    policy_model, reference_model, train_loader, val_loader,\n",
    "    optimizer, num_epochs, beta,\n",
    "    eval_freq, eval_iter, start_context, tokenizer\n",
    "):\n",
    "\n",
    "    # 손실 및 토큰 수 추적을 위한 리스트 초기화\n",
    "    tracking = {\n",
    "        \"train_losses\": [],\n",
    "        \"train_chosen_rewards\": [],\n",
    "        \"train_rejected_rewards\": [],\n",
    "        \"val_losses\": [],\n",
    "        \"val_chosen_rewards\": [],\n",
    "        \"val_rejected_rewards\": [],\n",
    "        \"tokens_seen\": []\n",
    "    }\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # 메인 훈련 루프\n",
    "    for epoch in range(num_epochs):\n",
    "        policy_model.train()  # 모델을 훈련 모드로 설정\n",
    "\n",
    "        for batch in train_loader:\n",
    "\n",
    "            optimizer.zero_grad()  # 이전 배치의 그래디언트 초기화\n",
    "\n",
    "            loss, chosen_rewards, rejected_rewards = compute_dpo_loss_batch(\n",
    "                batch=batch,\n",
    "                policy_model=policy_model,\n",
    "                reference_model=reference_model,\n",
    "                beta=beta\n",
    "            )\n",
    "\n",
    "            loss.backward()  # 손실 그래디언트 계산\n",
    "            optimizer.step()  # 모델 가중치 업데이트\n",
    "\n",
    "            tokens_seen += batch[\"chosen\"].numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # 선택적 평가 단계\n",
    "            if global_step % eval_freq == 0:\n",
    "                res = evaluate_dpo_loss_loader(\n",
    "                    policy_model=policy_model,\n",
    "                    reference_model=reference_model,\n",
    "                    train_loader=train_loader,\n",
    "                    val_loader=val_loader,\n",
    "                    beta=beta,\n",
    "                    eval_iter=eval_iter\n",
    "                )\n",
    "                tracking[\"train_losses\"].append(res[\"train_loss\"])\n",
    "                tracking[\"train_chosen_rewards\"].append(res[\"train_chosen_reward\"])\n",
    "                tracking[\"train_rejected_rewards\"].append(res[\"train_rejected_reward\"])\n",
    "                tracking[\"val_losses\"].append(res[\"val_loss\"])\n",
    "                tracking[\"val_chosen_rewards\"].append(res[\"val_chosen_reward\"])\n",
    "                tracking[\"val_rejected_rewards\"].append(res[\"val_rejected_reward\"])\n",
    "                tracking[\"tokens_seen\"].append(tokens_seen)\n",
    "                train_reward_margin = res[\"train_chosen_reward\"] - res[\"train_rejected_reward\"]\n",
    "                val_reward_margin = res[\"val_chosen_reward\"] - res[\"val_rejected_reward\"]\n",
    "\n",
    "                print(\n",
    "                    f\"에포크 {epoch+1} (스텝 {global_step:06d}): \"\n",
    "                    f\"훈련 손실 {res['train_loss']:.3f}, 검증 손실 {res['val_loss']:.3f}, \"\n",
    "                    f\"훈련 보상 마진 {train_reward_margin:.3f}, \"\n",
    "                    f\"검증 보상 마진 {val_reward_margin:.3f}\"\n",
    "                )\n",
    "\n",
    "        # 에포크가 끝날 때마다 샘플 텍스트 출력\n",
    "        generate_and_print_sample(\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            device=loss.device,\n",
    "            start_context=start_context\n",
    "        )\n",
    "\n",
    "    return tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d53210c5-6d9c-46b0-af22-ee875c2806c5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d53210c5-6d9c-46b0-af22-ee875c2806c5",
    "outputId": "8b1d2b39-16c5-4b99-e920-5b33d3c0f34d"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "a Tensor with 8 elements cannot be converted to Scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m torch.manual_seed(\u001b[32m123\u001b[39m) \u001b[38;5;66;03m# 데이터 로더 셔플링을 위한 재현성 설정\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m res = \u001b[43mevaluate_dpo_loss_loader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpolicy_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpolicy_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreference_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreference_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m훈련 손실:\u001b[39m\u001b[33m\"\u001b[39m, res[\u001b[33m\"\u001b[39m\u001b[33mtrain_loss\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m검증 손실:\u001b[39m\u001b[33m\"\u001b[39m, res[\u001b[33m\"\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mevaluate_dpo_loss_loader\u001b[39m\u001b[34m(policy_model, reference_model, train_loader, val_loader, beta, eval_iter)\u001b[39m\n\u001b[32m      4\u001b[39m policy_model.eval()\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     train_loss, train_chosen_rewards, train_rejected_rewards = \u001b[43mcompute_dpo_loss_loader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpolicy_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpolicy_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreference_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreference_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_iter\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     val_loss, val_chosen_rewards, val_rejected_rewards = compute_dpo_loss_loader(\n\u001b[32m     15\u001b[39m         data_loader=val_loader,\n\u001b[32m     16\u001b[39m         policy_model=policy_model,\n\u001b[32m   (...)\u001b[39m\u001b[32m     19\u001b[39m         num_batches=eval_iter\n\u001b[32m     20\u001b[39m     )\n\u001b[32m     22\u001b[39m res = {\n\u001b[32m     23\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtrain_loss\u001b[39m\u001b[33m\"\u001b[39m: train_loss,\n\u001b[32m     24\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtrain_chosen_reward\u001b[39m\u001b[33m\"\u001b[39m: train_chosen_rewards,\n\u001b[32m   (...)\u001b[39m\u001b[32m     28\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mval_rejected_reward\u001b[39m\u001b[33m\"\u001b[39m: val_rejected_rewards\n\u001b[32m     29\u001b[39m }\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mcompute_dpo_loss_loader\u001b[39m\u001b[34m(data_loader, policy_model, reference_model, beta, num_batches)\u001b[39m\n\u001b[32m     14\u001b[39m     loss, chosen_rewards, rejected_rewards = compute_dpo_loss_batch(\n\u001b[32m     15\u001b[39m         batch=batch,\n\u001b[32m     16\u001b[39m         policy_model=policy_model,\n\u001b[32m     17\u001b[39m         reference_model=reference_model,\n\u001b[32m     18\u001b[39m         beta=beta\n\u001b[32m     19\u001b[39m     )\n\u001b[32m     20\u001b[39m     total_loss += loss.item()\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     total_chosen_rewards += \u001b[43mchosen_rewards\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m     total_rejected_rewards += rejected_rewards.item()\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mRuntimeError\u001b[39m: a Tensor with 8 elements cannot be converted to Scalar"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123) # 데이터 로더 셔플링을 위한 재현성 설정\n",
    "\n",
    "res = evaluate_dpo_loss_loader(\n",
    "    policy_model=policy_model,\n",
    "    reference_model=reference_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    beta=0.1,\n",
    "    eval_iter=5\n",
    ")\n",
    "\n",
    "print(\"훈련 손실:\", res[\"train_loss\"])\n",
    "print(\"검증 손실:\", res[\"val_loss\"])\n",
    "\n",
    "print(\"훈련 보상 마진:\", res[\"train_chosen_reward\"] - res[\"train_rejected_reward\"])\n",
    "print(\"검증 보상 마진:\", res[\"val_chosen_reward\"] - res[\"val_rejected_reward\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a006e91-df94-43ca-8025-1ba791e37bc4",
   "metadata": {
    "id": "4a006e91-df94-43ca-8025-1ba791e37bc4"
   },
   "source": [
    "- 또한 초기 모델 응답(검증 세트의 처음 3개 예제)도 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "q4Ro9DrBa7zH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q4Ro9DrBa7zH",
    "outputId": "b974d4bd-b92a-4a2a-bb7a-5a2a0d1eca11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "정답 응답:\n",
      ">> The meal is cooked by the chef every day.\n",
      "\n",
      "모델 응답:\n",
      ">> The meal is cooked every day by the chef.\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Classify an input string as either a noun or a verb.\n",
      "\n",
      "### Input:\n",
      "Dance\n",
      "\n",
      "정답 응답:\n",
      ">> 'Dance' can be classified as a verb.\n",
      "\n",
      "모델 응답:\n",
      ">> Dance is a verb.\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a metaphor.\n",
      "\n",
      "### Input:\n",
      "The book is very interesting.\n",
      "\n",
      "정답 응답:\n",
      ">> The book is a page-turner.\n",
      "\n",
      "모델 응답:\n",
      ">> The book is like a treasure.\n",
      "\n",
      "-------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "\n",
    "for entry in val_data[:3]:\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    ")\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\n정답 응답:\\n>> {entry['output']}\")\n",
    "    print(f\"\\n모델 응답:\\n>> {response_text.strip()}\")\n",
    "    print(\"\\n-------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2386ae-5c4c-448e-bfbf-4ec0604b171e",
   "metadata": {
    "id": "ac2386ae-5c4c-448e-bfbf-4ec0604b171e"
   },
   "source": [
    "- 위에서 원본 모델 응답을 확인했습니다.\n",
    "- DPO의 목표는 약간의 스타일 변화를 유도하는 것입니다. 즉, 모델이 유사하지만 조금 더 정중한 응답을 생성하도록 하는 것입니다.\n",
    "- 학습을 시작하기 전에 몇 가지 설정에 대한 참고 사항입니다.\n",
    " - 정책 모델의 매개변수만 `AdamW` 옵티마이저에 전달합니다. (참조 모델은 수정하지 않습니다.)\n",
    " - 1 에포크만 학습합니다. DPO는 붕괴(collapse)에 매우 취약하기 때문입니다(손실은 개선될 수 있지만 모델이 무의미한 텍스트를 생성하기 시작할 수 있음).\n",
    " - DPO에서는 아주 작은 학습률을 사용하는 것이 가장 좋습니다.\n",
    " - DPO 효과를 줄이려면 beta 값을 0.1에서 0.5로 늘릴 수 있습니다(여기서는 결과를 더 뚜렷하게 보기 위해 0.1을 사용함).\n",
    " - 학습은 A100 GPU에서 약 2분, L4 GPU에서 4분, M3 MacBook Air에서 약 30분 정도 걸립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54b739be-871e-4c97-bf14-ffd2c58e1311",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "54b739be-871e-4c97-bf14-ffd2c58e1311",
    "outputId": "d98b08b0-c325-411e-a1a4-05e7403f0345"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크 1 (스텝 000000): 훈련 손실 0.692, 검증 손실 0.693, 훈련 보상 마진 0.014, 검증 보상 마진 0.007\n",
      "에포크 1 (스텝 000005): 훈련 손실 0.691, 검증 손실 0.692, 훈련 보상 마진 0.045, 검증 보상 마진 0.032\n",
      "에포크 1 (스텝 000010): 훈련 손실 0.687, 검증 손실 0.690, 훈련 보상 마진 0.117, 검증 보상 마진 0.055\n",
      "에포크 1 (스텝 000015): 훈련 손실 0.682, 검증 손실 0.688, 훈련 보상 마진 0.229, 검증 보상 마진 0.095\n",
      "에포크 1 (스텝 000020): 훈련 손실 0.682, 검증 손실 0.686, 훈련 보상 마진 0.234, 검증 보상 마진 0.151\n",
      "에포크 1 (스텝 000025): 훈련 손실 0.674, 검증 손실 0.682, 훈련 보상 마진 0.405, 검증 보상 마진 0.232\n",
      "에포크 1 (스텝 000030): 훈련 손실 0.677, 검증 손실 0.677, 훈련 보상 마진 0.336, 검증 보상 마진 0.341\n",
      "에포크 1 (스텝 000035): 훈련 손실 0.669, 검증 손실 0.672, 훈련 보상 마진 0.522, 검증 보상 마진 0.438\n",
      "에포크 1 (스텝 000040): 훈련 손실 0.674, 검증 손실 0.668, 훈련 보상 마진 0.417, 검증 보상 마진 0.530\n",
      "에포크 1 (스텝 000045): 훈련 손실 0.652, 검증 손실 0.662, 훈련 보상 마진 0.894, 검증 보상 마진 0.671\n",
      "에포크 1 (스텝 000050): 훈련 손실 0.658, 검증 손실 0.657, 훈련 보상 마진 0.796, 검증 보상 마진 0.796\n",
      "에포크 1 (스텝 000055): 훈련 손실 0.644, 검증 손실 0.653, 훈련 보상 마진 1.082, 검증 보상 마진 0.888\n",
      "에포크 1 (스텝 000060): 훈련 손실 0.654, 검증 손실 0.649, 훈련 보상 마진 0.886, 검증 보상 마진 0.978\n",
      "에포크 1 (스텝 000065): 훈련 손실 0.628, 검증 손실 0.646, 훈련 보상 마진 1.464, 검증 보상 마진 1.066\n",
      "에포크 1 (스텝 000070): 훈련 손실 0.616, 검증 손실 0.641, 훈련 보상 마진 1.796, 검증 보상 마진 1.175\n",
      "에포크 1 (스텝 000075): 훈련 손실 0.611, 검증 손실 0.637, 훈련 보상 마진 1.910, 검증 보상 마진 1.271\n",
      "에포크 1 (스텝 000080): 훈련 손실 0.584, 검증 손실 0.634, 훈련 보상 마진 2.564, 검증 보상 마진 1.343\n",
      "에포크 1 (스텝 000085): 훈련 손실 0.606, 검증 손실 0.630, 훈련 보상 마진 2.021, 검증 보상 마진 1.431\n",
      "에포크 1 (스텝 000090): 훈련 손실 0.648, 검증 손실 0.626, 훈련 보상 마진 1.042, 검증 보상 마진 1.529\n",
      "에포크 1 (스텝 000095): 훈련 손실 0.593, 검증 손실 0.624, 훈련 보상 마진 2.335, 검증 보상 마진 1.606\n",
      "에포크 1 (스텝 000100): 훈련 손실 0.589, 검증 손실 0.621, 훈련 보상 마진 2.450, 검증 보상 마진 1.678\n",
      "에포크 1 (스텝 000105): 훈련 손실 0.576, 검증 손실 0.619, 훈련 보상 마진 2.851, 검증 보상 마진 1.737\n",
      "에포크 1 (스텝 000110): 훈련 손실 0.599, 검증 손실 0.615, 훈련 보상 마진 2.235, 검증 보상 마진 1.829\n",
      "에포크 1 (스텝 000115): 훈련 손실 0.609, 검증 손실 0.612, 훈련 보상 마진 1.918, 검증 보상 마진 1.908\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Rewrite the sentence using a metaphor.  ### Input: The book is very interesting.  ### Response: The book is filled with ideas.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of the Netherlands?  ###\n",
      "학습 완료 소요 시간: 2.43 분.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(policy_model.parameters(), lr=5e-6, weight_decay=0.01)\n",
    "\n",
    "num_epochs = 1\n",
    "tracking = train_model_dpo_simple(\n",
    "    policy_model=policy_model,\n",
    "    reference_model=reference_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=num_epochs,\n",
    "    beta=0.1, # 0.1 ~ 0.5 사이의 값\n",
    "    eval_freq=5,\n",
    "    eval_iter=5,\n",
    "    start_context=format_input(val_data[2]),\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"학습 완료 소요 시간: {execution_time_minutes:.2f} 분.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba8ea88-8771-4eb9-855d-2fe1ca2dc2fa",
   "metadata": {
    "id": "eba8ea88-8771-4eb9-855d-2fe1ca2dc2fa"
   },
   "source": [
    "- 추적된 결과에서 알 수 있듯이 손실이 개선되었습니다.\n",
    "- 또한 선택된 응답과 거부된 응답의 보상 차이인 보상 마진도 개선되었으며 이는 좋은 징조입니다.\n",
    "- 다음 섹션에서 이 결과들을 더 구체적으로 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e23989-92bd-4ac2-a4bc-65d4c7ac334e",
   "metadata": {
    "id": "11e23989-92bd-4ac2-a4bc-65d4c7ac334e"
   },
   "source": [
    "&nbsp;\n",
    "# 6) 결과 분석하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d7d5fe-c617-45cb-8ea9-ddc7baa22654",
   "metadata": {
    "id": "66d7d5fe-c617-45cb-8ea9-ddc7baa22654"
   },
   "source": [
    "- DPO 손실을 그래프로 그려서 결과를 분석해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8ddcc66f-cd7c-4f46-96ea-af919ea1a199",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "8ddcc66f-cd7c-4f46-96ea-af919ea1a199",
    "outputId": "c7164b26-8d32-41d1-8c6a-ab835d58d4c5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from previous_chapters import plot_losses\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(tracking[\"train_losses\"]))\n",
    "plot_losses(\n",
    "    epochs_seen=epochs_tensor,\n",
    "    tokens_seen=tracking[\"tokens_seen\"],\n",
    "    train_losses=tracking[\"train_losses\"],\n",
    "    val_losses=tracking[\"val_losses\"],\n",
    "    label=\"loss\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8bc233-895f-46d5-8e01-202b991cd60c",
   "metadata": {
    "id": "7f8bc233-895f-46d5-8e01-202b991cd60c"
   },
   "source": [
    "- 위에서 보듯 손실이 계속 개선되고 있으며 좋은 신호입니다.\n",
    "- 하향 곡선을 보면 모델을 조금 더 학습시키고 싶을 수도 있지만(시도해 보길 권장합니다), DPO는 모델이 무의미한 응답을 생성하기 시작하는 붕괴 현상이 발생하기 쉽다는 점에 유의하세요.\n",
    "- 다음으로 보상 마진을 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dmbq6ruuf0Cl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "dmbq6ruuf0Cl",
    "outputId": "c2886c16-57da-41bd-c9f0-e936da9d9e4d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_reward_margins = [i-j for i,j in zip(tracking[\"train_chosen_rewards\"], tracking[\"train_rejected_rewards\"])]\n",
    "val_reward_margins = [i-j for i,j in zip(tracking[\"val_chosen_rewards\"], tracking[\"val_rejected_rewards\"])]\n",
    "\n",
    "plot_losses(\n",
    "    epochs_seen=epochs_tensor,\n",
    "    tokens_seen=tracking[\"tokens_seen\"],\n",
    "    train_losses=train_reward_margins,\n",
    "    val_losses=val_reward_margins,\n",
    "    label=\"reward margins\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69756011-acd6-404c-a5fc-7fe252cf20c8",
   "metadata": {
    "id": "69756011-acd6-404c-a5fc-7fe252cf20c8"
   },
   "source": [
    "- 의도한 대로 보상 마진이 개선되었습니다. 이는 손실 곡선과 대칭을 이루며 긍정적인 신호입니다.\n",
    "- DPO 손실과 보상 마진은 학습 중 추적할 가치가 있는 지표이지만, 그것이 전부는 아닙니다.\n",
    "- 마지막으로, 가장 중요하게 응답에 대한 정성적 검사를 수행해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5EfUXJGOali8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5EfUXJGOali8",
    "outputId": "7ec7db47-d775-4646-f660-0d7f7e7c8503"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "정답 응답:\n",
      ">> The meal is cooked by the chef every day.\n",
      "\n",
      "참조 모델 응답:\n",
      ">> The meal is cooked every day by the chef.\n",
      "\n",
      "정책 모델 응답:\n",
      ">> The active sentence should be replaced by the passive voice.\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Classify an input string as either a noun or a verb.\n",
      "\n",
      "### Input:\n",
      "Dance\n",
      "\n",
      "정답 응답:\n",
      ">> 'Dance' can be classified as a verb.\n",
      "\n",
      "참조 모델 응답:\n",
      ">> Dance is a verb.\n",
      "\n",
      "정책 모델 응답:\n",
      ">> The input 'Dance' could be classified as a verb.\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a metaphor.\n",
      "\n",
      "### Input:\n",
      "The book is very interesting.\n",
      "\n",
      "정답 응답:\n",
      ">> The book is a page-turner.\n",
      "\n",
      "참조 모델 응답:\n",
      ">> The book is like a treasure.\n",
      "\n",
      "정책 모델 응답:\n",
      ">> The book is filled with ideas.\n",
      "\n",
      "-------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "\n",
    "for entry in val_data[:3]:\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=reference_model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    reference_response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=policy_model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    policy_response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\n정답 응답:\\n>> {entry['output']}\")\n",
    "    print(f\"\\n참조 모델 응답:\\n>> {reference_response_text.strip()}\")\n",
    "    print(f\"\\n정책 모델 응답:\\n>> {policy_response_text.strip()}\")\n",
    "    print(\"\\n-------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RmcKVg0JlHVF",
   "metadata": {
    "id": "RmcKVg0JlHVF"
   },
   "source": [
    "- 참조 모델과 정책 모델의 응답을 비교해보면, 최적화된 모델(정책 모델)이 원본 모델(참조 모델)에 비해 스타일이 약간 변경되었음을 알 수 있습니다.\n",
    "- 예를 들어 `\"Dance\" can be classified as a verb.`가 `The input string \"Dance\" could be classified as a verb.`로 바뀌었는데, 이는 \"can\" 대신 \"could\"를 사용하여 조금 더 정중하고 덜 단정적인 느낌을 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "jJSwb2hzQwdP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jJSwb2hzQwdP",
    "outputId": "6e755db4-9524-42a8-a58b-2218bf03e39a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "정답 응답:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "참조 모델 응답:\n",
      ">> The car is as fast as a bullet.\n",
      "\n",
      "정책 모델 응답:\n",
      ">> The car would be very fast.\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "정답 응답:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "참조 모델 응답:\n",
      ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
      "\n",
      "정책 모델 응답:\n",
      ">> The type of cloud typically associated with thunderstorms is a cumulus.\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "정답 응답:\n",
      ">> Jane Austen.\n",
      "\n",
      "참조 모델 응답:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "\n",
      "정책 모델 응답:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "\n",
      "-------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=reference_model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    reference_response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=policy_model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    policy_response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\n정답 응답:\\n>> {entry['output']}\")\n",
    "    print(f\"\\n참조 모델 응답:\\n>> {reference_response_text.strip()}\")\n",
    "    print(f\"\\n정책 모델 응답:\\n>> {policy_response_text.strip()}\")\n",
    "    print(\"\\n-------------------------------------\\n\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
