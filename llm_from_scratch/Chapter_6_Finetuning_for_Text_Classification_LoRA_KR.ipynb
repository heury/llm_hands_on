{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c024bfa4-1a7a-4751-b5a1-827225a3478b",
   "metadata": {
    "id": "c024bfa4-1a7a-4751-b5a1-827225a3478b"
   },
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<font size=\"2\">\n",
    "<a href=\"https://sebastianraschka.com\">Sebastian Raschka</a>의 저서 <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a>의 보충 코드입니다.<br>\n",
    "<br>코드 저장소: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
    "</font>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<a href=\"http://mng.bz/orYv\"><img src=\"images/llm_from_scratch/ch06_compressed/cover-small.webp\" width=\"100px\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b8c870-fb72-490e-8916-d8129bd5d1ff",
   "metadata": {
    "id": "58b8c870-fb72-490e-8916-d8129bd5d1ff"
   },
   "source": [
    "# LoRA를 이용한 파라미터 효율적 미세 조정(Finetuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
    "outputId": "316166b4-027a-4756-e9b4-fe88ae75dd4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib 버전: 3.10.8\n",
      "numpy 버전: 2.4.0\n",
      "tiktoken 버전: 0.12.0\n",
      "torch 버전: 2.9.1+cu126\n",
      "pandas 버전: 2.3.3\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\",\n",
    "        \"numpy\",\n",
    "        \"tiktoken\",\n",
    "        \"torch\",\n",
    "        # \"tensorflow\", # OpenAI의 사전 훈련된 가중치를 로드하기 위함\n",
    "        \"pandas\"      # 데이터셋 로딩용\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} 버전: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21532056-0ef4-4c98-82c7-e91f61c6485e",
   "metadata": {
    "id": "21532056-0ef4-4c98-82c7-e91f61c6485e"
   },
   "source": [
    "## E.1 LoRA 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66edc999-3d91-4a1c-a157-9d056392e8d8",
   "metadata": {
    "id": "66edc999-3d91-4a1c-a157-9d056392e8d8"
   },
   "source": [
    "- 이 섹션에는 코드가 없습니다.\n",
    "- 저차원 적응(Low-rank adaptation, LoRA)은 모델 파라미터 중 작고 낮은 랭크(low-rank)를 가진 일부 하위 집합만 조정하여, 사전 훈련된 모델을 특정 데이터셋(주로 작은 데이터셋)에 더 잘 맞도록 수정하는 머신러닝 기법입니다.\n",
    "- 이 접근 방식은 대규모 모델을 특정 작업 데이터에 맞춰 효율적으로 미세 조정할 수 있게 해주며, 미세 조정에 필요한 계산 비용과 시간을 크게 줄여준다는 점에서 중요합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb75b5d-d59c-4948-821a-1594a5883dc1",
   "metadata": {
    "id": "5bb75b5d-d59c-4948-821a-1594a5883dc1"
   },
   "source": [
    "- 주어진 레이어에 대한 거대한 가중치 행렬 $W$가 있다고 가정해 봅시다.\n",
    "- 역전파(backpropagation) 동안 우리는 $\\Delta W$ 행렬을 학습하게 되는데, 이 행렬은 훈련 중 손실 함수를 최소화하기 위해 원래 가중치를 얼마나 업데이트해야 하는지에 대한 정보를 담고 있습니다.\n",
    "- 일반적인 훈련 및 미세 조정에서 가중치 업데이트는 다음과 같이 정의됩니다:\n",
    "\n",
    "$$W_{\\text{updated}} = W + \\Delta W$$\n",
    "\n",
    "- [Hu 등](https://arxiv.org/abs/2106.09685)이 제안한 LoRA 방법은 $\\Delta W$의 근사치인 $\\Delta W \\approx AB$를 학습함으로써 가중치 업데이트를 계산하는 더 효율적인 대안을 제공합니다.\n",
    "- 즉, LoRA에서는 두 개의 작은 가중치 행렬 $A$와 $B$를 사용하여 다음과 같이 나타냅니다:\n",
    "\n",
    "$$W_{\\text{updated}} = W + AB$$\n",
    "\n",
    "- 아래 그림은 전체 미세 조정(full finetuning)과 LoRA의 공식을 나란히 비교하여 보여줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a7419d-cae9-4525-bb44-1641f6ef4f3b",
   "metadata": {
    "id": "a8a7419d-cae9-4525-bb44-1641f6ef4f3b"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/appendix-e_compressed/lora-1.webp\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edd43c9-8ec5-48e6-b3fc-5fb3c16037cc",
   "metadata": {
    "id": "4edd43c9-8ec5-48e6-b3fc-5fb3c16037cc"
   },
   "source": [
    "- 자세히 살펴보면 위 그림의 전체 미세 조정과 LoRA 묘사가 앞서 보여드린 공식과 약간 다르게 보일 수 있습니다.\n",
    "- 이는 행렬 곱셈의 분배 법칙 때문입니다. 가중치와 업데이트 가중치를 더할 필요 없이 별도로 유지할 수 있습니다.\n",
    "- 예를 들어 $x$가 입력 데이터라면, 일반적인 미세 조정에 대해 다음과 같이 쓸 수 있습니다:\n",
    "\n",
    "$$x (W+\\Delta W) = x W + x \\Delta W$$\n",
    "\n",
    "- 마찬가지로 LoRA에 대해서도 다음과 같이 쓸 수 있습니다:\n",
    "\n",
    "$$x (W+A B) = x W + x A B$$\n",
    "\n",
    "- LoRA 가중치 행렬을 별도로 유지할 수 있다는 점이 LoRA를 특히 매력적으로 만듭니다.\n",
    "- 실제 적용 시, 이는 사전 훈련된 모델의 가중치를 전혀 수정할 필요가 없음을 의미하며, 필요할 때 실시간으로(on the fly) LoRA 행렬을 적용할 수 있습니다.\n",
    "- 데이터셋을 설정하고 모델을 로드한 후, 이러한 개념들이 덜 추상적으로 느껴지도록 코드로 LoRA를 구현해 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf",
   "metadata": {
    "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf"
   },
   "source": [
    "## E.2 데이터셋 준비하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669c64df-4431-4d27-834d-2bb38a01fc02",
   "metadata": {
    "id": "669c64df-4431-4d27-834d-2bb38a01fc02"
   },
   "source": [
    "- 이 섹션은 데이터셋을 로드하고 준비하기 위해 6장의 코드를 반복합니다.\n",
    "- 코드를 반복하는 대신 6장 노트북을 열어 실행한 다음, 그곳에 섹션 E.4의 LoRA 코드를 삽입할 수도 있습니다.\n",
    "- (LoRA 코드는 원래 6장의 마지막 섹션이었으나 6장의 분량 문제로 인해 부록으로 이동되었습니다.)\n",
    "- 이와 유사한 방식으로 7장의 모델들에 LoRA를 적용하여 명령 미세 조정(instruction finetuning)을 수행할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
    "outputId": "a67a7afe-b401-4463-c731-87025d20f72d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datas\\sms_spam_collection\\SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "# import urllib\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from previous_chapters import (\n",
    "    download_and_unzip_spam_data,\n",
    "    create_balanced_dataset,\n",
    "    random_split\n",
    ")\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"datas/sms_spam_collection.zip\"\n",
    "extracted_path = \"datas/sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "try:\n",
    "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
    "except (requests.exceptions.RequestException, TimeoutError) as e:\n",
    "    print(f\"기본 URL 실패: {e}. 백업 URL 시도 중...\")\n",
    "    url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/sms%2Bspam%2Bcollection.zip\"\n",
    "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
    "\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "train_df.to_csv(\"datas/train.csv\", index=None)\n",
    "validation_df.to_csv(\"datas/validation.csv\", index=None)\n",
    "test_df.to_csv(\"datas/test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
   "metadata": {
    "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import tiktoken\n",
    "from previous_chapters import SpamDataset\n",
    "\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "train_dataset = SpamDataset(\"datas/train.csv\", max_length=None, tokenizer=tokenizer)\n",
    "val_dataset = SpamDataset(\"datas/validation.csv\", max_length=train_dataset.max_length, tokenizer=tokenizer)\n",
    "test_dataset = SpamDataset(\"datas/test.csv\", max_length=train_dataset.max_length, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542",
   "metadata": {
    "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7335db-e0bb-4e27-80c5-eea11e593a57",
   "metadata": {
    "id": "ab7335db-e0bb-4e27-80c5-eea11e593a57"
   },
   "source": [
    "- 검증 단계로, 데이터 로더를 순회하며 각 배치가 8개의 훈련 사례를 포함하고 각 사례가 120개의 토큰으로 구성되어 있는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
    "outputId": "2ae34de1-dd01-4f99-d2c8-ba4dca400754"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 로더:\n",
      "입력 배치 차원: torch.Size([8, 120])\n",
      "레이블 배치 차원 torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(\"훈련 로더:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(\"입력 배치 차원:\", input_batch.shape)\n",
    "print(\"레이블 배치 차원\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdd7947-7039-49bf-8a5e-c0a2f4281ca1",
   "metadata": {
    "id": "5cdd7947-7039-49bf-8a5e-c0a2f4281ca1"
   },
   "source": [
    "- 마지막으로, 각 데이터셋의 총 배치 수를 출력해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "IZfw-TYD2zTj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZfw-TYD2zTj",
    "outputId": "4d19ed61-cf7a-4ec4-b822-c847dd1c5d77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130개 훈련 배치\n",
      "19개 검증 배치\n",
      "38개 테스트 배치\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)}개 훈련 배치\")\n",
    "print(f\"{len(val_loader)}개 검증 배치\")\n",
    "print(f\"{len(test_loader)}개 테스트 배치\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec9aa4a-ffd2-4d9f-a835-cce1059fe604",
   "metadata": {
    "id": "dec9aa4a-ffd2-4d9f-a835-cce1059fe604"
   },
   "source": [
    "## E.3 모델 초기화하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36ebdaf-810e-46a2-9ad9-e017a04051b1",
   "metadata": {
    "id": "f36ebdaf-810e-46a2-9ad9-e017a04051b1"
   },
   "source": [
    "- 이 섹션은 모델을 로드하고 준비하기 위해 6장의 코드를 반복합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "692d2fa4-3f4c-4641-88ba-4d832f6bd3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미 파일이 존재합니다: models/gpt2\\gpt2-small-124M.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from previous_chapters import GPTModel, load_gpt2_model\n",
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # 어휘사전 크기\n",
    "    \"context_length\": 1024,  # 문맥 길이\n",
    "    \"drop_rate\": 0.0,        # 드롭아웃 비율\n",
    "    \"qkv_bias\": True         # 쿼리-키-값 편향\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12}, #트랜스포머 블록(Transformer Block)을 몇 층으로 쌓아 올렸는지\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_name = \"gpt2-small-124M.pth\"\n",
    "model = load_gpt2_model(model_name, BASE_CONFIG)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252614cd-7ce6-4908-83e6-3761f519904e",
   "metadata": {
    "id": "252614cd-7ce6-4908-83e6-3761f519904e"
   },
   "source": [
    "- 모델이 올바르게 로드되었는지 확인하기 위해, 일관성 있는 텍스트를 생성하는지 다시 한 번 체크합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b6ce20c-0700-4783-8be0-4cf17c200a7f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8b6ce20c-0700-4783-8be0-4cf17c200a7f",
    "outputId": "28ccbca5-8de9-41a0-c093-da00fcbaa91c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import (\n",
    "    generate_text_simple,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "\n",
    "text_1 = \"Every effort moves you\"\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8174b31b-1ab5-4115-b01c-245369da5af3",
   "metadata": {
    "id": "8174b31b-1ab5-4115-b01c-245369da5af3"
   },
   "source": [
    "- 그런 다음, 6장과 유사하게 출력 레이어를 교체하여 분류 미세 조정을 위한 모델을 준비합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e255ce91-d73a-4854-90a4-95804928eb16",
   "metadata": {
    "id": "e255ce91-d73a-4854-90a4-95804928eb16"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=768, out_features=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02e6f057-1383-4ece-8444-0a88e71ac75d",
   "metadata": {
    "id": "02e6f057-1383-4ece-8444-0a88e71ac75d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용 장치: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"사용 장치:\", device)\n",
    "\n",
    "model.to(device);  # nn.Module 클래스의 경우 model = model.to(device)와 같은 할당이 필요 없습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e951cd6-5e42-44d2-b21f-895cb61004fe",
   "metadata": {
    "id": "8e951cd6-5e42-44d2-b21f-895cb61004fe"
   },
   "source": [
    "- 마지막으로, 미세 조정되지 않은 모델의 초기 분류 정확도를 계산해 봅니다. (약 50% 정도를 예상하며, 이는 모델이 아직 스팸과 일반 메시지를 안정적으로 구분하지 못함을 의미합니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc7dd72c-73a2-4881-ade0-0a9605f1ab8c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fc7dd72c-73a2-4881-ade0-0a9605f1ab8c",
    "outputId": "74848515-5a49-4125-fecb-9f4bac23f812"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 정확도: 46.25%\n",
      "검증 정확도: 45.00%\n",
      "테스트 정확도: 48.75%\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import calc_accuracy_loader\n",
    "# 대안:\n",
    "# from llms_from_scratch.ch06 import calc_accuracy_loader\n",
    "\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"훈련 정확도: {train_accuracy*100:.2f}%\")\n",
    "print(f\"검증 정확도: {val_accuracy*100:.2f}%\")\n",
    "print(f\"테스트 정확도: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398a1ec9-e2a1-43d6-bf9f-12ee54b46a7b",
   "metadata": {
    "id": "398a1ec9-e2a1-43d6-bf9f-12ee54b46a7b"
   },
   "source": [
    "## E.4 LoRA를 이용한 파라미터 효율적 미세 조정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652a4a82-61ef-4d0a-9858-8988e844f12c",
   "metadata": {
    "id": "652a4a82-61ef-4d0a-9858-8988e844f12c"
   },
   "source": [
    "- 먼저 행렬 $A$와 $B$를 생성하는 `LoRALayer`를 초기화합니다. 여기에는 `alpha` 스케일링 하이퍼파라미터와 `rank` ($r$) 하이퍼파라미터가 포함됩니다.\n",
    "- 이 레이어는 아래 그림과 같이 입력을 받아 그에 상응하는 출력을 계산할 수 있습니다.\n",
    "\n",
    "<img src=\"images/llm_from_scratch/appendix-e_compressed/lora-2.webp\" width=\"500px\">\n",
    "\n",
    "코드에서 위 그림의 LoRA 레이어는 다음과 같이 구현됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ds9ywjMwvIW",
   "metadata": {
    "id": "2ds9ywjMwvIW"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "\n",
    "class LoRALayer(torch.nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, rank, alpha):\n",
    "        \"\"\"\n",
    "        LoRA(Low-Rank Adaptation) 레이어 초기화\n",
    "        \n",
    "        Args:\n",
    "            in_dim: 입력 데이터의 차원 크기 (예: 768)\n",
    "            out_dim: 출력 데이터의 차원 크기 (예: 768)\n",
    "            rank: 병목 구간의 크기 (Rank, r). 작을수록 파라미터가 적어짐 (예: 8, 16)\n",
    "            alpha: 스케일링 상수. 학습된 값의 영향력을 조절함\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # 1. 행렬 A (Down-projection)\n",
    "        # 입력(in_dim)을 작은 차원(rank)으로 압축하는 가중치입니다.\n",
    "        # 파라미터로 등록하여 학습되도록 합니다.\n",
    "        self.A = torch.nn.Parameter(torch.empty(in_dim, rank))\n",
    "        \n",
    "        # A는 무작위 값(Kaiming Uniform)으로 초기화합니다.\n",
    "        # 이렇게 해야 다양한 특징을 학습할 준비가 됩니다.\n",
    "        torch.nn.init.kaiming_uniform_(self.A, a=math.sqrt(5))\n",
    "        \n",
    "        # 2. 행렬 B (Up-projection)\n",
    "        # 압축된 정보(rank)를 다시 원래 출력 차원(out_dim)으로 복원하는 가중치입니다.\n",
    "        self.B = torch.nn.Parameter(torch.zeros(rank, out_dim))\n",
    "        \n",
    "        # 중요: B는 '0'으로 초기화합니다.\n",
    "        # 이유: 학습 시작 시점에는 A @ B의 결과가 0이 되어야 합니다.\n",
    "        # 그래야 LoRA를 붙여도 기존 모델의 원래 출력값에 아무런 영향을 주지 않은 채로 시작할 수 있습니다.\n",
    "        \n",
    "        self.alpha = alpha\n",
    "        self.rank = rank\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        순전파(Forward) 단계: 입력 x에 대한 LoRA 변화량(Delta)을 계산\n",
    "        \"\"\"\n",
    "        # 1. 행렬 연산 (x @ A @ B)\n",
    "        # 입력 x를 A와 곱해 차원을 줄이고(압축), \n",
    "        # 그 결과를 다시 B와 곱해 차원을 늘립니다(복원).\n",
    "        # 연산 순서: (Batch, in) -> (Batch, rank) -> (Batch, out)\n",
    "        \n",
    "        # 2. 스케일링 (alpha / rank)\n",
    "        # 학습된 결과에 상수배를 해줍니다. \n",
    "        # alpha는 강도 조절, rank로 나누는 것은 rank값이 바뀌어도 \n",
    "        # 학습률(Learning Rate)을 크게 수정하지 않기 위한 정규화(Normalization) 과정입니다.\n",
    "        x = (self.alpha / self.rank) * (x @ self.A @ self.B)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad21faa8-0614-4257-93cd-68952193e14a",
   "metadata": {
    "id": "ad21faa8-0614-4257-93cd-68952193e14a"
   },
   "source": [
    "- 위의 코드에서 `rank`는 행렬 $A$와 $B$의 내부 차원을 제어하는 하이퍼파라미터입니다.\n",
    "- 즉, 이 파라미터는 LoRA에 의해 도입되는 추가 파라미터의 수를 제어하며, 모델의 적응력과 파라미터 효율성 사이의 균형을 결정하는 핵심 요소입니다.\n",
    "- 두 번째 하이퍼파라미터인 `alpha`는 저차원 적응의 출력에 적용되는 스케일링 하이퍼파라미터입니다.\n",
    "- 이는 기본적으로 적응된 레이어의 출력이 적응 대상인 원래 레이어의 출력에 미치는 영향력을 조절합니다.\n",
    "- 이는 저차원 적응이 레이어 출력에 주는 영향을 규제하는 방법으로 볼 수 있습니다.\n",
    "- 지금까지 구현한 `LoRALayer` 클래스는 레이어 입력 $x$를 변환할 수 있게 해줍니다.\n",
    "- 하지만 LoRA에서는 보통 아래 그림처럼 가중치 업데이트가 기존의 사전 훈련된 가중치에 적용되도록 기존의 `Linear` 레이어를 대체하는 데 관심이 있습니다.\n",
    "\n",
    "<img src=\"images/llm_from_scratch/appendix-e_compressed/lora-3.webp\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6d5da0-dfce-4808-b89b-29ff333f563f",
   "metadata": {
    "id": "3e6d5da0-dfce-4808-b89b-29ff333f563f"
   },
   "source": [
    "- 위 그림과 같이 원래의 `Linear` 레이어 가중치를 포함하기 위해, 아래에 `LinearWithLoRA` 레이어를 구현합니다. 이 레이어는 앞서 구현한 `LoRALayer`를 사용하며, 신경망(예: LLM의 자기 주의 모듈이나 피드 포워드 모듈) 내의 기존 `Linear` 레이어를 대체하는 데 사용될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127d3a64-8359-4b21-b056-78d58cc75fe8",
   "metadata": {
    "id": "127d3a64-8359-4b21-b056-78d58cc75fe8"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class LinearWithLoRA(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    기존의 Linear 레이어를 감싸서(Wrapping), \n",
    "    LoRA 어댑터를 추가한 새로운 복합 레이어를 만드는 클래스\n",
    "    \"\"\"\n",
    "    def __init__(self, linear, rank, alpha):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 1. 기존 레이어 저장 (Frozen Weights)\n",
    "        # 이미 학습된 레이어 가중치(W)를 그대로 가져옵니다.\n",
    "        # 실제 사용 시에는 이 레이어의 가중치를 고정(freeze)시켜 학습되지 않게 합니다.\n",
    "        self.linear = linear\n",
    "        \n",
    "        # 2. LoRA 레이어 생성 (Trainable Adapter)\n",
    "        # 기존 레이어와 똑같은 입/출력 차원을 가지지만, 내부는 훨씬 가벼운 LoRA 레이어를 만듭니다.\n",
    "        # linear.in_features, linear.out_features: 기존 레이어의 스펙을 그대로 베껴옵니다.\n",
    "        self.lora = LoRALayer(\n",
    "            linear.in_features, linear.out_features, rank, alpha\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 3. 결과 합치기 (The Core Logic)\n",
    "        # 원래 모델이 하던 계산 결과 : self.linear(x)\n",
    "        # LoRA가 새로 학습한 변화량 : self.lora(x)\n",
    "        # 최종 결과 = 원래 결과 + 변화량\n",
    "        return self.linear(x) + self.lora(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1145a90-35ff-462c-820b-15483fa5b051",
   "metadata": {
    "id": "e1145a90-35ff-462c-820b-15483fa5b051"
   },
   "source": [
    "- 가중치 행렬 $B$(`LoRALayer` 내의 `self.B`)를 LoRA 레이어에서 0으로 초기화하기 때문에, $A$와 $B$의 행렬 곱셈 결과는 0으로 구성된 행렬이 되며 원래 가중치에 영향을 주지 않습니다. (원래 가중치에 0을 더해도 변하지 않기 때문입니다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98a6d36-7bc9-434c-a7f1-533f26aff06d",
   "metadata": {
    "id": "e98a6d36-7bc9-434c-a7f1-533f26aff06d"
   },
   "source": [
    "- 앞서 정의한 GPT 모델에 LoRA를 시도해보기 위해, 모델 내의 모든 `Linear` 레이어를 새로운 `LinearWithLoRA` 레이어로 교체하는 `replace_linear_with_lora` 함수를 정의합니다.\n",
    "\n",
    "<img src=\"images/llm_from_scratch/appendix-e_compressed/lora-4.webp\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WlQZ8ygqzN_g",
   "metadata": {
    "id": "WlQZ8ygqzN_g"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def replace_linear_with_lora(model, rank, alpha):\n",
    "    \"\"\"\n",
    "    모델 내의 모든 Linear 레이어를 찾아 LoRA가 적용된 레이어로 교체하는 재귀 함수\n",
    "    \n",
    "    Args:\n",
    "        model: 수정할 파이토치 모델 (또는 모델의 하위 모듈)\n",
    "        rank: LoRA의 Rank (r)\n",
    "        alpha: LoRA의 Alpha (스케일링 계수)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. 자식 모듈 순회 (Iterate Children)\n",
    "    # named_children(): 현재 모듈 바로 아래에 있는 구성 요소들을 (이름, 객체) 쌍으로 가져옵니다.\n",
    "    # 예: (\"attn\", AttentionModule), (\"mlp\", MLPModule) ...\n",
    "    for name, module in model.named_children():\n",
    "        \n",
    "        # 2. 교체 대상 확인 (Check Target)\n",
    "        # 현재 보고 있는 모듈이 'torch.nn.Linear'인지 확인합니다.\n",
    "        # (즉, 우리가 LoRA를 붙이고 싶은 기본 선형 층인지 확인)\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            \n",
    "            # 3. 레이어 교체 (Swap Layer)\n",
    "            # setattr(객체, 속성이름, 새로운값): 객체의 속성을 동적으로 변경하는 파이썬 내장 함수\n",
    "            # model의 'name'에 해당하는 레이어를 -> 'LinearWithLoRA'로 덮어씌웁니다.\n",
    "            # 이때 기존 module을 인자로 넘겨줘서 가중치를 그대로 보존하게 합니다.\n",
    "            setattr(model, name, LinearWithLoRA(module, rank, alpha))\n",
    "            \n",
    "        else:\n",
    "            # 4. 재귀 호출 (Dig Deeper)\n",
    "            # 만약 Linear 레이어가 아니라면(예: 트랜스포머 블록, 어텐션 층 등 컨테이너라면),\n",
    "            # 그 내부에도 Linear 레이어가 숨어있을 수 있으므로\n",
    "            # 그 안으로 들어가서 다시 똑같은 작업(replace_linear_with_lora)을 수행하라고 시킵니다.\n",
    "            replace_linear_with_lora(module, rank, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c172164-cdde-4489-b7d7-aaed9cc2f5f2",
   "metadata": {
    "id": "8c172164-cdde-4489-b7d7-aaed9cc2f5f2"
   },
   "source": [
    "- 그런 다음 원래 모델 파라미터를 동결(freeze)하고, 아래 코드를 사용하여 언급된 `Linear` 레이어들을 교체합니다.\n",
    "- 이를 통해 LLM 내의 `Linear` 레이어들이 `LinearWithLoRA` 레이어로 바뀝니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe15350-4da9-4829-9d23-98bbd3d0b1a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dbe15350-4da9-4829-9d23-98bbd3d0b1a1",
    "outputId": "fd4c208f-854a-4701-d9d3-9d73af733364"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이전의 총 학습 가능 파라미터 수: 124,441,346\n",
      "이후의 총 학습 가능 파라미터 수: 0\n"
     ]
    }
   ],
   "source": [
    "# 1. 현재 학습 가능한(Trainable) 파라미터 개수 계산\n",
    "# - model.parameters(): 모델 내부의 모든 가중치(W)와 편향(b)을 가져옵니다.\n",
    "# - p.numel(): 각 파라미터 텐서의 전체 원소 개수(Number of Elements)를 셉니다.\n",
    "# - if p.requires_grad: 현재 '학습 대상(True)'으로 설정된 것들만 필터링합니다.\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# {total_params:,} : 천 단위마다 쉼표(,)를 찍어서 보기 좋게 출력 (예: 1,000,000)\n",
    "print(f\"이전의 총 학습 가능 파라미터 수: {total_params:,}\")\n",
    "\n",
    "\n",
    "# 2. 모든 파라미터 얼리기 (Freezing)\n",
    "# 모델의 모든 파라미터를 하나씩 꺼내서 반복합니다.\n",
    "for param in model.parameters():\n",
    "    # requires_grad = False:\n",
    "    # \"이 파라미터는 이제 학습시키지 마(기울기 계산 X)\"라고 설정합니다.\n",
    "    # 이렇게 하면 역전파(Backpropagation) 때 이 값들은 업데이트되지 않고 고정됩니다.\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "# 3. 얼린 후 학습 가능 파라미터 수 재계산\n",
    "# 위에서 모든 param의 requires_grad를 False로 바꿨으므로, \n",
    "# 조건(if p.requires_grad)을 만족하는 파라미터가 하나도 없게 됩니다.\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# 결과적으로 0이 출력되어야 정상입니다.\n",
    "print(f\"이후의 총 학습 가능 파라미터 수: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "mLk_fPq0yz_u",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mLk_fPq0yz_u",
    "outputId": "0a93b8fc-05d7-4ace-ee47-e2fc6bdd7d75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 학습 가능 LoRA 파라미터 수: 2,666,528\n"
     ]
    }
   ],
   "source": [
    "replace_linear_with_lora(model, rank=16, alpha=16)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"총 학습 가능 LoRA 파라미터 수: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b6819e-ef7a-4f0d-841a-1b467496bef9",
   "metadata": {
    "id": "b8b6819e-ef7a-4f0d-841a-1b467496bef9"
   },
   "source": [
    "- 보시다시피, LoRA를 사용함으로써 학습 가능한 파라미터 수를 거의 50배 줄였습니다.\n",
    "- 이제 모델 아키텍처를 출력하여 레이어들이 의도한 대로 수정되었는지 다시 한 번 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1711be61-bb2c-466f-9b5b-24f4aa5ccd9c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1711be61-bb2c-466f-9b5b-24f4aa5ccd9c",
    "outputId": "acff8eca-3775-45a2-b62d-032a986ef037"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): LinearWithLoRA(\n",
      "    (linear): Linear(in_features=768, out_features=2, bias=True)\n",
      "    (lora): LoRALayer()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bbc9d7-65ec-4675-bab8-2e56eb0cfb55",
   "metadata": {
    "id": "c4bbc9d7-65ec-4675-bab8-2e56eb0cfb55"
   },
   "source": [
    "- 위의 모델 아키텍처를 보면, 모델이 이제 우리의 새로운 `LinearWithLoRA` 레이어들을 포함하고 있음을 알 수 있습니다.\n",
    "- 또한, 행렬 $B$를 0으로 초기화했기 때문에 초기 모델 성능은 이전과 변함이 없을 것으로 기대합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "DAlrb_I00VEU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DAlrb_I00VEU",
    "outputId": "3da44ac4-230b-4358-d996-30b63f0d962a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 정확도: 46.25%\n",
      "검증 정확도: 45.00%\n",
      "테스트 정확도: 48.75%\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"훈련 정확도: {train_accuracy*100:.2f}%\")\n",
    "print(f\"검증 정확도: {val_accuracy*100:.2f}%\")\n",
    "print(f\"테스트 정확도: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13735b3e-f0c3-4dba-ae3d-4141b2878101",
   "metadata": {
    "id": "13735b3e-f0c3-4dba-ae3d-4141b2878101"
   },
   "source": [
    "- 이제 흥미로운 부분인 미세 조정을 진행해 봅시다. 6장의 훈련 함수를 재사용합니다.\n",
    "- 훈련은 M3 MacBook Air 노트북에서 약 15분 정도 소요되며, V100이나 A100 GPU에서는 30초도 걸리지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "wCParRvr0eff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wCParRvr0eff",
    "outputId": "ce910a9c-ee89-48bb-bfa6-49c6aee1e450"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 3.820, Val loss 3.462\n",
      "Ep 1 (Step 000050): Train loss 0.346, Val loss 0.325\n",
      "Ep 1 (Step 000100): Train loss 0.063, Val loss 0.144\n",
      "Training accuracy: 100.00% | Validation accuracy: 92.50%\n",
      "Ep 2 (Step 000150): Train loss 0.054, Val loss 0.045\n",
      "Ep 2 (Step 000200): Train loss 0.058, Val loss 0.122\n",
      "Ep 2 (Step 000250): Train loss 0.041, Val loss 0.199\n",
      "Training accuracy: 100.00% | Validation accuracy: 95.00%\n",
      "Ep 3 (Step 000300): Train loss 0.020, Val loss 0.153\n",
      "Ep 3 (Step 000350): Train loss 0.019, Val loss 0.193\n",
      "Training accuracy: 100.00% | Validation accuracy: 95.00%\n",
      "Ep 4 (Step 000400): Train loss 0.021, Val loss 0.084\n",
      "Ep 4 (Step 000450): Train loss 0.005, Val loss 0.115\n",
      "Ep 4 (Step 000500): Train loss 0.022, Val loss 0.115\n",
      "Training accuracy: 100.00% | Validation accuracy: 95.00%\n",
      "Ep 5 (Step 000550): Train loss 0.013, Val loss 0.066\n",
      "Ep 5 (Step 000600): Train loss 0.042, Val loss 0.029\n",
      "Training accuracy: 100.00% | Validation accuracy: 95.00%\n",
      "훈련이 1.08분 만에 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from previous_chapters import train_classifier_simple\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=8e-4, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"훈련이 {execution_time_minutes:.2f}분 만에 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7410ae-ed73-4f89-9cfa-0893312fe9c7",
   "metadata": {},
   "source": [
    "- 다양한 장치에서의 실행 시간은 다음과 같습니다.\n",
    "  - 12.10분: MacBook M1 (CPU)\n",
    "  - 2.16분: MacMini M4 Pro (MPS)\n",
    "  - 3.50분: Jetson Nano (CUDA), 독자가 [공유](https://livebook.manning.com/forum?product=raschka&comment=581806)한 결과\n",
    "  - 1.02분: DGX Spark (CUDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c89e82-3aa8-44c6-b046-0b16200b8e6c",
   "metadata": {
    "id": "d0c89e82-3aa8-44c6-b046-0b16200b8e6c"
   },
   "source": [
    "- 마지막으로 모델을 평가해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bawWGijA0iF3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "id": "bawWGijA0iF3",
    "outputId": "af70782a-d605-4376-fa6c-d33b38979cfa"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from previous_chapters import plot_values\n",
    "# 대안:\n",
    "# from llms_from_scratch.ch06 import plot_values\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses, label=\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa074723-e3f7-4f7e-a267-855531a037dc",
   "metadata": {
    "id": "aa074723-e3f7-4f7e-a267-855531a037dc"
   },
   "source": [
    "- 이전에는 `eval_iter=5` 설정을 통해 5개 배치에 대해서만 정확도를 계산했었습니다. 아래에서는 전체 데이터셋에 대해 정확도를 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1D2awlEq0gZi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1D2awlEq0gZi",
    "outputId": "d603eda1-d912-43eb-ec9c-af6a622510a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 정확도: 99.81%\n",
      "검증 정확도: 97.99%\n",
      "테스트 정확도: 98.00%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"훈련 정확도: {train_accuracy*100:.2f}%\")\n",
    "print(f\"검증 정확도: {val_accuracy*100:.2f}%\")\n",
    "print(f\"테스트 정확도: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f87f5e6-339e-4fcf-900b-6d845d3c713d",
   "metadata": {
    "id": "1f87f5e6-339e-4fcf-900b-6d845d3c713d"
   },
   "source": [
    "- 위에서 확인한 상대적으로 높은 정확도 수치를 통해 LoRA 미세 조정이 성공적이었음을 알 수 있습니다."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "llm-hands-on",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
