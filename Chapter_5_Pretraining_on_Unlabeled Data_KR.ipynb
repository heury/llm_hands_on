{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11feef31",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/rickiepark/llm-from-scratch/blob/main/ch05/01_main-chapter-code/ch05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45398736-7e89-4263-89c8-92153baff553",
   "metadata": {
    "id": "45398736-7e89-4263-89c8-92153baff553"
   },
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<font size=\"2\">\n",
    "세바스찬 라시카(Sebastian Raschka)가 쓴 <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a>의 번역서 <br><<b><a href=\"<a href=\"http://tensorflow.blog/llm-from-scratch\">밑바닥부터 만들면서 배우는 LLM</a></b>>의 예제 코드입니다.<br>\n",
    "<br>코드 저장소: <a href=\"https://github.com/rickiepark/llm-from-scratch\">https://github.com/rickiepark/llm-from-scratch</a>\n",
    "</font>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<a href=\"http://tensorflow.blog/llm-from-scratch\"><img src=\"https://tensorflowkorea.wordpress.com/wp-content/uploads/2025/09/ebb091ebb094eb8ba5llm_ebb3b8ecb185_ec959eeba9b4.jpg\" width=\"100px\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dd524e-864c-4012-b0a2-ccfc56e80024",
   "metadata": {
    "id": "66dd524e-864c-4012-b0a2-ccfc56e80024"
   },
   "source": [
    "# 5장: 레이블이 없는 데이터를 활용한 사전 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92b989e9-da36-4159-b212-799184764dd9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "92b989e9-da36-4159-b212-799184764dd9",
    "outputId": "323b4987-fed4-4cbb-c5bd-3949099e9e71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib 버전: 3.10.8\n",
      "numpy 버전: 2.4.0\n",
      "tiktoken 버전: 0.12.0\n",
      "torch 버전: 2.8.0+cu126\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\",\n",
    "        \"numpy\",\n",
    "        \"tiktoken\",\n",
    "        \"torch\",\n",
    "        # \"tensorflow\" # OpenAI의 사전 훈련된 가중치를 위해서\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} 버전: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3bdf9e-2ff0-4a57-abab-ede2d955a237",
   "metadata": {
    "id": "0a3bdf9e-2ff0-4a57-abab-ede2d955a237"
   },
   "source": [
    "- 이 장에서 LLM을 사전 훈련하기 위해 훈련 루프를 구현하고 기본적인 모델 평가 방법을 알아 보겠습니다.\n",
    "- 이 장의 끝에서는 OpenAI의 사전 훈련된 가중치를 우리가 직접 구현한 모델에 로드해 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd27fcc-2886-47cb-b544-046c2c31f02a",
   "metadata": {
    "id": "efd27fcc-2886-47cb-b544-046c2c31f02a"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch05_compressed/01.webp\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d214765-7a73-42d5-95e9-302154b29db9",
   "metadata": {
    "id": "0d214765-7a73-42d5-95e9-302154b29db9"
   },
   "source": [
    "- 이 장에서 다루는 주제는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67711d4-8391-4fee-aeef-07ea53dd5841",
   "metadata": {
    "id": "f67711d4-8391-4fee-aeef-07ea53dd5841"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch05_compressed/02.webp\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d824183-145c-4865-89e1-1f0d0a338f19",
   "metadata": {
    "id": "0d824183-145c-4865-89e1-1f0d0a338f19"
   },
   "source": [
    "## 5.1 텍스트 생성 모델 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3350f8c-5181-4f9b-a789-4523105e98f2",
   "metadata": {
    "id": "a3350f8c-5181-4f9b-a789-4523105e98f2"
   },
   "source": [
    "- 이전 장에 코드를 사용하여 GPT 모델을 초기화하는 방법을 간략히 정리합니다.\n",
    "- 그다음 LLM을 위한 기본적인 평가 지표를 소개합니다.\n",
    "- 이 절의 마지막에서 이 평가 지표를 훈련 세트와 검증 세트에 적용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc1cf3f-82d8-46c7-9ecc-58979ce87cdd",
   "metadata": {
    "id": "bdc1cf3f-82d8-46c7-9ecc-58979ce87cdd"
   },
   "source": [
    "### 5.1.1 GPT를 사용해 텍스트 생성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3415fd-9f4a-4548-908e-9dfa56edc9bc",
   "metadata": {
    "id": "5b3415fd-9f4a-4548-908e-9dfa56edc9bc"
   },
   "source": [
    "- 이전 장의 코드를 사용하여 GPT 모델을 초기화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86000d74-624a-48f0-86da-f41926cb9e04",
   "metadata": {
    "id": "86000d74-624a-48f0-86da-f41926cb9e04"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "# 이전에 작성했던 GPTModel 클래스를 가져옵니다.\n",
    "from previous_chapters import GPTModel\n",
    "\n",
    "# 1. 모델 설정값 정의 (Hyperparameters)\n",
    "# GPT-2 (Small 버전 - 124M 파라미터)의 구조를 본뜬 설정입니다.\n",
    "# 딕셔너리 형태로 묶어서 관리하면 나중에 설정을 바꾸기 편합니다.\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # 어휘 사전 크기 (OpenAI의 BPE 토크나이저 기준)\n",
    "                           # 즉, 모델이 알 수 있는 단어(토큰)의 총개수입니다.\n",
    "\n",
    "    \"context_length\": 256, # 문맥 길이 (Context Window)\n",
    "                           # 원본 GPT-2는 1024지만, 여기서는 학습 속도와 메모리 절약을 위해\n",
    "                           # 256으로 줄여서 테스트합니다. (한 번에 볼 수 있는 최대 단어 수)\n",
    "\n",
    "    \"emb_dim\": 768,        # 임베딩 차원 (Embedding Dimension)\n",
    "                           # 하나의 단어를 768개의 숫자로 표현하겠다는 뜻입니다.\n",
    "                           # 이 숫자가 클수록 단어의 의미를 더 정밀하게 표현할 수 있습니다.\n",
    "\n",
    "    \"n_heads\": 12,         # 멀티 헤드 어텐션의 헤드 개수\n",
    "                           # 768차원을 12명이 나눠서(64차원씩) 병렬로 처리합니다.\n",
    "\n",
    "    \"n_layers\": 12,        # 트랜스포머 블록(층)의 개수\n",
    "                           # 이 블록을 12층으로 쌓아 올려서 '깊은(Deep)' 신경망을 만듭니다.\n",
    "\n",
    "    \"drop_rate\": 0.1,      # 드롭아웃 비율 (Dropout Rate)\n",
    "                           # 학습 시 10%의 뉴런을 랜덤하게 꺼서 과적합(Overfitting)을 막습니다.\n",
    "\n",
    "    \"qkv_bias\": False      # 편향(Bias) 사용 여부\n",
    "                           # 쿼리(Q), 키(K), 값(V)을 만드는 선형 계층에 편향값을 더할지 결정합니다.\n",
    "                           # (최신 모델들은 종종 이를 False로 설정하여 파라미터를 줄입니다.)\n",
    "}\n",
    "\n",
    "# 2. 랜덤 시드 고정\n",
    "# 모델의 가중치 초기화가 매번 똑같이 일어나도록 하여,\n",
    "# 언제 실행하든 같은 결과가 나오게 합니다. (재현성 확보)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# 3. 모델 인스턴스 생성\n",
    "# 위에서 정의한 설계도(GPT_CONFIG_124M)를 넣어 실제 모델을 만듭니다.\n",
    "# 이제 'model' 변수 안에는 12층짜리 거대한 신경망이 들어있습니다.\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "# 4. 평가 모드로 전환 (매우 중요!)\n",
    "# 모델을 학습(Training)이 아닌 사용(Inference/Evaluation) 모드로 바꿉니다.\n",
    "# 이 함수를 실행해야 드롭아웃(drop_rate=0.1)이 비활성화되어,\n",
    "# 모든 뉴런이 100% 능력을 발휘하며 일관된 결과를 냅니다.\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c6cf0f-7458-48a2-97fd-aa5068d65e8c",
   "metadata": {
    "id": "09c6cf0f-7458-48a2-97fd-aa5068d65e8c"
   },
   "source": [
    "- 위에서 드롭아웃을 0.1로 지정했지만 요즘에는 드롭아웃을 사용하지 않고 LLM을 훈련하는 경우가 많습니다.\n",
    "- 최신 LLM은 (초기 GPT 모델과 달리) 쿼리, 키, 값 행렬을 위한 `nn.Linear` 층에서 편향 벡터를 사용하지 않습니다. 그래서 `\"qkv_bias\": False`로 지정합니다.\n",
    "- 모델 훈련에 필요한 계산 자원을 절감하기 위해 문맥 길이(`context_length`)를 256 토큰으로 줄입니다. 원본 1억 2,400만 파라미터의 GPT-2 모델은 1024개의 토큰을 사용했습니다.\n",
    "  - 대부분의 독자들은 이 코드 예제를 랩탑 컴퓨터에서 실행하기 때문입니다.\n",
    "  - 하지만 `context_length`를 1,024개 토큰으로 늘려서 실험해도 괜찮습니다(어떤 코드도 바꿀 필요가 없습니다)\n",
    "  - 나중에 `context_length`가 1,024인 모델을 사전 훈련된 가중치에서 로드하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f80895-be35-4bb5-81cb-f357ef7367fe",
   "metadata": {
    "id": "59f80895-be35-4bb5-81cb-f357ef7367fe"
   },
   "source": [
    "- 그 다음이 이전 장에서 만든 `generate_text_simple` 함수를 사용해 텍스트를 생성합니다.\n",
    "- 또한 두 개 유틸리티 함수 `text_to_token_ids`와 `token_ids_to_text`를 정의합니다. 이 장에서 토큰과 텍스트 표현 사이를 전환하는데 사용하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741881f3-cee0-49ad-b11d-b9df3b3ac234",
   "metadata": {
    "id": "741881f3-cee0-49ad-b11d-b9df3b3ac234"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch05_compressed/03.webp\" width=900px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e062b82-3540-48ce-8eb4-009686d0d16c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5e062b82-3540-48ce-8eb4-009686d0d16c",
    "outputId": "dad3e6ea-4617-417d-97ac-dfc14447e520"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출력 텍스트:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "import torch\n",
    "from previous_chapters import generate_text_simple\n",
    "\n",
    "# 1. 입력 변환 함수 (Encoding Helper)\n",
    "# 사람의 언어(Text)를 모델이 이해하는 숫자 텐서(Tensor)로 변환합니다.\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    # tokenizer.encode: 텍스트를 정수 리스트로 변환합니다.\n",
    "    # allowed_special: '<|endoftext|>' 같은 특수 토큰을 문자로 취급하지 않고 \n",
    "    #                  기능을 가진 토큰으로 인식하도록 허용합니다.\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    \n",
    "    # 리스트를 파이토치 텐서로 변환합니다.\n",
    "    encoded_tensor = torch.tensor(encoded)\n",
    "    \n",
    "    # unsqueeze(0): 배치 차원을 추가합니다.\n",
    "    # 모델은 항상 [배치 크기, 시퀀스 길이] 형태의 입력을 기대합니다.\n",
    "    # 예: [1, 2, 3] -> [[1, 2, 3]] (1개의 문장이라는 것을 명시)\n",
    "    encoded_tensor = encoded_tensor.unsqueeze(0) \n",
    "    \n",
    "    return encoded_tensor\n",
    "\n",
    "# 2. 출력 변환 함수 (Decoding Helper)\n",
    "# 모델이 내뱉은 숫자 텐서(Tensor)를 다시 사람의 언어(Text)로 변환합니다.\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    # squeeze(0): 불필요한 배치 차원을 제거합니다.\n",
    "    # 예: [[1, 2, 3]] -> [1, 2, 3]\n",
    "    flat = token_ids.squeeze(0) \n",
    "    \n",
    "    # tokenizer.decode: 정수 리스트(.tolist())를 받아서 문자열로 복원합니다.\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "# --- 실행 코드 ---\n",
    "\n",
    "# 3. 초기 설정\n",
    "start_context = \"Every effort moves you\" # 모델에게 줄 첫 문장(프롬프트)\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\") # GPT-2용 토크나이저 로드\n",
    "\n",
    "# 4. 텍스트 생성 실행\n",
    "# 입력 텍스트를 텐서로 바꾸고 -> 모델에 넣어 생성하고 -> 결과 텐서를 받습니다.\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer), # \"Every...\"를 텐서로 변환\n",
    "    max_new_tokens=10, # 10개의 단어를 추가로 생성\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "# 5. 결과 확인\n",
    "# 생성된 숫자 텐서를 다시 텍스트로 바꿔서 출력합니다.\n",
    "print(\"출력 텍스트:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d3249b-b2a0-44c4-b589-ae4b403b8305",
   "metadata": {
    "id": "e4d3249b-b2a0-44c4-b589-ae4b403b8305"
   },
   "source": [
    "- 위해서 볼 수 있듯이 모델이 아직 훈련되지 않았기 때문에 좋은 텍스트를 생성하지 못합니다.\n",
    "- 훈련 과정에서 어떤 것이 좋은 텍스트인지 어떻게 정량적으로 측정할 수 있을까요?\n",
    "- 다음 절에서 훈련 과정을 모니터링할 수 있도록 생성된 출력의 손실을 계산하는 지표를 소개합니다.\n",
    "- LLM 미세 튜닝을 다루는 다음 장에서 모델의 품질을 측정하는 또 다른 방법을 소개하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3d7ea2-637f-4490-bc76-e361fc81ae98",
   "metadata": {
    "id": "0f3d7ea2-637f-4490-bc76-e361fc81ae98"
   },
   "source": [
    "### 5.1.2 텍스트 생성 손실 계산하기: 크로스 엔트로피와 혼잡도"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1ba8aa-fb03-4d25-957f-fe8778762440",
   "metadata": {
    "id": "9e1ba8aa-fb03-4d25-957f-fe8778762440"
   },
   "source": [
    "- 두 개의 훈련 샘플(행)에 대한 토큰 ID를 담고 있는 `inputs` 텐서가 있다고 가정해보죠.\n",
    "- `inputs`에 해당하는 `targets`은 모델이 생성 해야할 토큰 ID를 담고 있습니다.\n",
    "- 2장에서 데이터 로더를 구현할 때 설명했듯이 `targets`은 `inputs`에서 한 토큰씩 앞으로 이동한 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b5402f8-ec0c-4a44-9892-18a97779ee4f",
   "metadata": {
    "id": "6b5402f8-ec0c-4a44-9892-18a97779ee4f"
   },
   "outputs": [],
   "source": [
    "# 1. 데이터셋 준비 (Next Token Prediction)\n",
    "# 입력(inputs): 모델이 현재 보고 있는 단어들입니다.\n",
    "# 정답(targets): 각 입력 단어 바로 '다음에 와야 할' 단어들입니다. (오른쪽으로 한 칸 Shift 된 형태)\n",
    "# 예: \"Every effort moves\" -> 다음 단어 예측 -> \"effort moves you\"\n",
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every\", \"effort\", \"moves\"]\n",
    "                       [40,    1107, 588]])   # [\"I\",     \"really\", \"like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345],    # [\"effort\", \"moves\", \"you\"]\n",
    "                        [1107, 588, 11311]])  # [\"really\", \"like\", \"chocolate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dc0645-ac2c-4973-9b40-6da40515bede",
   "metadata": {
    "id": "33dc0645-ac2c-4973-9b40-6da40515bede"
   },
   "source": [
    "- `inputs`을 모델에 주입하면 각각 세 개의 토큰으로 구성된 두 개의 입력 샘플에 대한 로짓 벡터를 얻습니다.\n",
    "- 각각의 토큰는 어휘 사전 크기에 해당하는 50,257차원의 벡터입니다.\n",
    "- 소프트맥스 함수를 적용하여 로짓 텐서을 확률 점수를 담고 있는 동일 차원의 텐서로 바꿀 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7b6ec51-6f8c-49bd-a349-95ba38b46fb6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e7b6ec51-6f8c-49bd-a349-95ba38b46fb6",
    "outputId": "2fb80348-8746-4509-bb8e-3f5292ac5846"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "확률 텐서 크기: torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "# 2. 모델 추론 (Forward Pass)\n",
    "# torch.no_grad(): 지금은 학습(가중치 업데이트)을 하는 게 아니라 결과만 볼 것이므로, \n",
    "# 미분값(Gradient) 계산을 꺼서 메모리를 아끼고 속도를 높입니다.\n",
    "with torch.no_grad():\n",
    "    # inputs(2x3)가 들어가면 -> logits(2x3x50257)이 나옵니다.\n",
    "    logits = model(inputs)\n",
    "\n",
    "# 3. 확률 변환\n",
    "# logits은 -무한대 ~ +무한대의 점수이므로, softmax를 통해 0~1 사이의 확률값으로 바꿉니다.\n",
    "# dim=-1: 마지막 차원(단어장 크기)에 대해 확률 합이 1이 되도록 계산합니다.\n",
    "probas = torch.softmax(logits, dim=-1) \n",
    "\n",
    "print(\"확률 텐서 크기:\", probas.shape) \n",
    "# 예상 출력: torch.Size([2, 3, 50257])\n",
    "# 의미: (문장 2개, 각 문장의 단어 3개, 각 단어마다 50257개의 후보 단어 확률)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c36a382-b5e2-4de6-9e65-0b69b685013b",
   "metadata": {
    "id": "5c36a382-b5e2-4de6-9e65-0b69b685013b"
   },
   "source": [
    "- 매우 작은 어휘 사전을 사용하는 아래 그림에서 확률 점수를 텍스트로 바꾸는 방법을 보여 줍니다. 이 장의 끝에서 이에 대해 논의하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384d86a9-0013-476c-bb6b-274fd5f20b29",
   "metadata": {
    "id": "384d86a9-0013-476c-bb6b-274fd5f20b29"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch05_compressed/04.webp\" width=900px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8480efd-d419-4954-9ecc-2876055334bd",
   "metadata": {
    "id": "e8480efd-d419-4954-9ecc-2876055334bd"
   },
   "source": [
    "- 이전 장에서 설명했듯이 `argmax` 함수를 적용하여 확률 점수를 토큰 ID 바꿀 수 있습니다.\n",
    "- 앞의 소프트맥스 함수는 각 토큰에 대해서 50,257 차원의 벡터를 생성합니다. `argmax` 함수는 이 벡터에서 가장 높은 확률을 가진 위치를 반환합니다. 이것이 주어진 토큰에 대한 예측 토큰의 아이디입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b84c9f-dd08-482e-b903-a86fe44e1144",
   "metadata": {
    "id": "f3b84c9f-dd08-482e-b903-a86fe44e1144"
   },
   "source": [
    "- 배치에는 각각 세 개 토큰으로 구성된 두 개의 입력 샘플이 있으므로 2x3 크기의 예측 토큰을 얻습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34ebd76a-16ec-4c17-8958-8a135735cc1c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34ebd76a-16ec-4c17-8958-8a135735cc1c",
    "outputId": "b5f6d08c-71a6-4858-a543-b97545ffb7d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토큰 ID:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"토큰 ID:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee4072c-21ed-4df7-8721-dd2535362573",
   "metadata": {
    "id": "cee4072c-21ed-4df7-8721-dd2535362573"
   },
   "source": [
    "- 이 토큰을 디코딩하면 모델이 예측해야 할 토큰, 즉 타겟 토큰과 매우 다른 것을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c990ead6-53cd-49a7-a6d1-14d8c1518249",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c990ead6-53cd-49a7-a6d1-14d8c1518249",
    "outputId": "290fbe6c-aa20-4011-b7eb-b4ea1d292d44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫 번째 샘플의 타깃:  effort moves you\n",
      "첫 번째 샘플의 타깃:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"첫 번째 샘플의 타깃: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"첫 번째 샘플의 타깃: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53eb8a7-070e-46d6-930c-314ba55a6ff2",
   "metadata": {
    "id": "a53eb8a7-070e-46d6-930c-314ba55a6ff2"
   },
   "source": [
    "- 이는 모델이 아직 훈련되지 않았기 때문입니다.\n",
    "- 모델을 훈련하려면 정답 예측(타깃)에서 얼만큼 떨어져 있는지 알아야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad90592f-0d5d-4ec8-9ff5-e7675beab10e",
   "metadata": {
    "id": "ad90592f-0d5d-4ec8-9ff5-e7675beab10e"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch05_compressed/06.webp\" width=900px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7251bf5-a079-4782-901d-68c9225d3157",
   "metadata": {
    "id": "c7251bf5-a079-4782-901d-68c9225d3157"
   },
   "source": [
    "- 타겟 인덱스에 해당하는 토큰 확률은 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54aef09c-d6e3-4238-8653-b3a1b0a1077a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "54aef09c-d6e3-4238-8653-b3a1b0a1077a",
    "outputId": "51ada8d3-ead5-4c95-da8c-a79a9a12d45f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트 1: tensor([7.4540e-05, 3.1061e-05, 1.1563e-05])\n",
      "텍스트 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]] # [2, 3, 50257]\n",
    "print(\"텍스트 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"텍스트 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e89a19-73c2-4e49-93b4-861f699f1cbf",
   "metadata": {
    "id": "a0e89a19-73c2-4e49-93b4-861f699f1cbf"
   },
   "source": [
    "- 확률이 1에 가까워지도록 이 값들을 최대화하는 것이 목표입니다.\n",
    "- 수학적 최적화에서는 확률 점수 자체를 최대화하는 것보다 확률 점수의 로그를 최대화하는 것이 쉽습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31402a67-a16e-4aeb-977e-70abb9c9949b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "31402a67-a16e-4aeb-977e-70abb9c9949b",
    "outputId": "9633daea-c621-40f9-eb65-d1fa2f7ee7b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "# 토큰 확률의 로그를 계산합니다.\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4261441-a511-4633-9c4c-67998af31b84",
   "metadata": {
    "id": "c4261441-a511-4633-9c4c-67998af31b84"
   },
   "source": [
    "- 그 다음 로그 확률의 평균을 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b003797-161b-4d98-81dc-e68320e09fec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9b003797-161b-4d98-81dc-e68320e09fec",
    "outputId": "f3a0d3df-c21b-48d3-d743-118e8b6459b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "# 각 토큰에 대한 평균 확률을 계산합니다.\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d51994-ad17-4ba3-a6ec-f588b4b13585",
   "metadata": {
    "id": "36d51994-ad17-4ba3-a6ec-f588b4b13585"
   },
   "source": [
    "- 모델 가중치를 최적화하여 평균 로그 확률을 가능한 크게 만드는 것이 목표입니다.\n",
    "- 로그 때문에 가장 큰 가능한 값은 0이며, 현재는 0에서 부터 멀리 떨어져 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de388a1-8a0a-4c94-8894-9041dc6ad514",
   "metadata": {
    "id": "3de388a1-8a0a-4c94-8894-9041dc6ad514"
   },
   "source": [
    "- 딥러닝 에서는 평균 로그 확률을 최대화하는 것 대신에 음의 평균 로그 확률을 최소화하는 것이 일반적입니다. 이 예제의 경우 -10.7722를 최대화하여 0에 가깝게 만드는 것 대신에 10.7722을 최소화하여 0에 가깝게 만듭니다.\n",
    "- -10.7722의 음수 값, 즉 10.7722을 딥러닝에서는 크로스 엔트로피 손실이라고 부릅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "176ddf35-1c5f-4d7c-bf17-70f3e7069bd4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "176ddf35-1c5f-4d7c-bf17-70f3e7069bd4",
    "outputId": "f4232ec9-3c65-4f2f-85db-aaf3875750bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eeb868-abd8-4028-82db-107546bf7c2c",
   "metadata": {
    "id": "84eeb868-abd8-4028-82db-107546bf7c2c"
   },
   "source": [
    "- 파이토치는 이전 단계를 수행하는 `cross_entropy` 함수를 제공합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd24b7f-b760-47ad-bc84-86d13794aa54",
   "metadata": {
    "id": "5bd24b7f-b760-47ad-bc84-86d13794aa54"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch05_compressed/07.webp\" width=600px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aaf9dd-3ee6-42bf-a63f-6e93dbfb989d",
   "metadata": {
    "id": "e8aaf9dd-3ee6-42bf-a63f-6e93dbfb989d"
   },
   "source": [
    "- `cross_entropy` 함수를 적용하기 전에 로짓과 타깃의 크기를 확인해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "695d6f64-5084-4c23-aea4-105c9e38cfe4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "695d6f64-5084-4c23-aea4-105c9e38cfe4",
    "outputId": "1e90e870-badc-40e3-bd42-d4355cea8dac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로짓 크기: torch.Size([2, 3, 50257])\n",
      "타깃 크기: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# 로짓의 크기는 (batch_size, num_tokens, vocab_size)입니다.\n",
    "print(\"로짓 크기:\", logits.shape)\n",
    "\n",
    "# 타깃의 크기는 (batch_size, num_tokens)입니다.\n",
    "print(\"타깃 크기:\", targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3d65f0-6566-4865-93e4-0c0bcb10cd06",
   "metadata": {
    "id": "1d3d65f0-6566-4865-93e4-0c0bcb10cd06"
   },
   "source": [
    "- 파이토치의 `cross_entropy` 함수를 위해 배치 차원을 기준으로 합쳐서 텐서를 펼쳐야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e17e027-ab9f-4fb5-ac9b-a009b831c122",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0e17e027-ab9f-4fb5-ac9b-a009b831c122",
    "outputId": "52a46bbb-bdd8-42af-c5c3-903a37ee80b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "펼친 로짓: torch.Size([6, 50257])\n",
      "펼친 타깃: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "# 4. 손실 계산을 위한 평탄화 (Flattening)\n",
    "# CrossEntropyLoss 함수는 [배치, 클래스] 형태의 2차원 입력을 선호합니다.\n",
    "# 따라서 \"2개의 문장에 있는 3개의 단어\"를 -> \"총 6개의 단어 문제\"로 일렬로 폅니다.\n",
    "\n",
    "# (2, 3, 50257) -> (6, 50257) : 배치와 시퀀스 길이를 합칩니다.\n",
    "logits_flat = logits.flatten(0, 1)\n",
    "\n",
    "# (2, 3) -> (6) : 정답지도 일렬로 쭉 폅니다.\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\"펼친 로짓:\", logits_flat.shape)   # torch.Size([6, 50257])\n",
    "print(\"펼친 타깃:\", targets_flat.shape)  # torch.Size([6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4921a57f-3a79-473e-a863-6d63b495010f",
   "metadata": {
    "id": "4921a57f-3a79-473e-a863-6d63b495010f"
   },
   "source": [
    "- 타깃은 토큰 ID이며, 최대화해야 할 로짓 텐서의 인덱스를 나타냅니다.\n",
    "- 파이토치의 `cross_entropy` 함수는 최대화할 토큰 인덱스에 대해 자동으로 소프트맥스와 로그 확률 계산을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62d0816e-b29a-4c8f-a9a5-a167562de978",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62d0816e-b29a-4c8f-a9a5-a167562de978",
    "outputId": "3ee41d42-6315-4eab-fc49-6e22af1f02f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "손실값(Loss): tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "# 손실(Loss) 계산: Cross Entropy\n",
    "# 모델의 예측값(logits_flat)과 실제 정답(targets_flat)을 비교하여 오차를 계산합니다.\n",
    "# 주의: 이 함수는 내부적으로 Softmax를 자동으로 수행합니다. \n",
    "#       따라서 확률값(probas)이 아닌 생(Raw) 로짓(logits)을 넣어야 합니다.\n",
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "\n",
    "print(\"손실값(Loss):\", loss) \n",
    "# 출력 예시: tensor(10.82...) -> 숫자가 작을수록 정답에 가깝다는 뜻입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f15ce17-fd7b-4d8e-99da-b237523a7a80",
   "metadata": {
    "id": "0f15ce17-fd7b-4d8e-99da-b237523a7a80"
   },
   "source": [
    "- 크로스 엔트로피 손실에 관련된 개념은 LLM의 혼잡도입니다.\n",
    "- 혼잡도는 크로스 엔트로피 손실에 지수 함수를 적용한 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "168952a1-b964-4aa7-8e49-966fa26add54",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "168952a1-b964-4aa7-8e49-966fa26add54",
    "outputId": "9822b33e-c224-4816-aafb-e4991ab847bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "펄플렉서티(Perplexity): tensor(48725.8203)\n"
     ]
    }
   ],
   "source": [
    "# 펄플렉서티(Perplexity, PPL) 계산\n",
    "# 손실값(Loss)은 로그 스케일이라 직관적으로 와닿지 않습니다.\n",
    "# 이를 지수함수(exp)에 통과시켜 사람이 이해하기 쉬운 수치로 변환합니다.\n",
    "# 공식: PPL = e^(Loss)\n",
    "perplexity = torch.exp(loss)\n",
    "\n",
    "print(\"펄플렉서티(Perplexity):\", perplexity)\n",
    "# 의미: \"모델이 다음 단어를 고를 때, 평균적으로 몇 개의 단어 중에서 고민(헷갈림)하는가?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ae26dd-d77e-41fd-b924-6bd103dd4ee7",
   "metadata": {
    "id": "71ae26dd-d77e-41fd-b924-6bd103dd4ee7"
   },
   "source": [
    "- 혼잡도는 모델이 각 단계에서 불확실해하는 실제 어휘사전 크기를 나타내기 때문에 원시 손실 값보다 이해하기 더 쉽습니다(이 예에서는 48,725개 단어 또는 토큰).\n",
    "- 다른 말로 하면, 혼잡도는 모델이 예측한 확률 분포가 데이터셋에 있는 단어의 실제 분포와 얼마나 잘 맞는지를 측정합니다.\n",
    "- 손실과 비슷하게 낮은 혼잡도는 모델 예측이 실제 분포에 가깝다는 것을 나타냅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec6c217-e429-40c7-ad71-5d0a9da8e487",
   "metadata": {
    "id": "2ec6c217-e429-40c7-ad71-5d0a9da8e487"
   },
   "source": [
    "### 5.1.3 훈련 세트와 검증 세트의 손실 계산하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530da89e-2448-436c-8f1b-28e8a31ef85c",
   "metadata": {
    "id": "530da89e-2448-436c-8f1b-28e8a31ef85c"
   },
   "source": [
    "- LLM 훈련을 위해 비교적 작은 데이터셋을 사용합니다(사실 단편 소설 하나를 사용합니다).\n",
    "- 이유는 다음과 같습니다.\n",
    "  - 적절한 GPU가 없는 랩탑 컴퓨터에서 몇 분 안에 코드 예제가 실행되어야 합니다.\n",
    "  - 교육 목적을 위해 훈련이 비교적 빨리 끝나야 합니다(몇 주가 아니라 몇 분 만에).\n",
    "  - 사용 권리를 위반하지 않으며 깃허브 저장소에 저장할 수 있는 크기의 공개된 텍스트를 사용해야 합니다.\n",
    "- 예를 들어, Llama 2 7B는 2조 개의 토큰에서 훈련하기 위해 A100 GPU에서 184,320 GPU 시간이 필요합니다.\n",
    "  - 이 글을 쓰는 시점에, AWS의 8xA100 클라우드 서버의 시간당 가격은 약 \\$30입니다.\n",
    "  - 따라서 대략 계산하면 이 LLM을 훈련하는데 184,320 / 8 * \\$30 =  \\$690,000이 듭니다.\n",
    "- 아래에서는 2장에서 다루었던 데이터셋을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "654fde37-b2a9-4a20-a8d3-0206c056e2ff",
   "metadata": {
    "id": "654fde37-b2a9-4a20-a8d3-0206c056e2ff"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "file_path = \"datas/the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    response = requests.get(url, timeout=30)\n",
    "    response.raise_for_status()\n",
    "    text_data = response.text\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379330f1-80f4-4e34-8724-41d892b04cee",
   "metadata": {
    "id": "379330f1-80f4-4e34-8724-41d892b04cee"
   },
   "source": [
    "- 다운로드한 텍스트를 확인하기 위해 처음과 끝에서 100 개의 문자를 출력하여 보죠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6kgJbe4ehI4q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6kgJbe4ehI4q",
    "outputId": "b08c7968-afe4-4e88-b111-f09daecca3cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "# 처음 99개 문자\n",
    "print(text_data[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "j2XPde_ThM_e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j2XPde_ThM_e",
    "outputId": "5197ff45-c5d2-4c5b-e135-3261bd1b5790"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n"
     ]
    }
   ],
   "source": [
    "# 마지막 99개 문자\n",
    "print(text_data[-99:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b46a952-d50a-4837-af09-4095698f7fd1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6b46a952-d50a-4837-af09-4095698f7fd1",
    "outputId": "786c8b83-cf2f-4918-a666-d5093c1f330d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문자: 20479\n",
      "토큰: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"문자:\", total_characters)\n",
    "print(\"토큰:\", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8830cb9-90f6-4e7c-8620-beeabc2d39f7",
   "metadata": {
    "id": "a8830cb9-90f6-4e7c-8620-beeabc2d39f7"
   },
   "source": [
    "이 텍스트의 토큰이 5,145개 뿐이라 LLM을 훈련하기에 너무 적어 보일 수 있습니다. 하지만 이는 교육적인 목적을 위해서입니다(나중에 사전 훈련된 가중치를 로드하겠습니다)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedcad87-a0e8-4b9d-ac43-4e927ccbb50f",
   "metadata": {
    "id": "bedcad87-a0e8-4b9d-ac43-4e927ccbb50f"
   },
   "source": [
    "- 그 다음 데이터셋을 훈련 세트와 검증 세트로 나누고 2장의 데이터 로더를 사용해 LLM 훈련을 위한 배치를 준비합니다.\n",
    "- 시각화때문에 아래 그림은 `max_length=6`라고 가정하지만, 훈련 데이터 로더에서 `max_length`는 LLM이 지원하는 문맥 길이와 같습니다.\n",
    "- 아래 그림은 간단하게 나타내려고 입력 토큰만 보여줍니다.\n",
    "  - LLM을 텍스트에 있는 다음 단어를 예측하도록 훈련하기 때문에 타깃은 한 토큰씩 이동한 것외에는 입력과 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bdaa07-ba96-4ac1-9d71-b3cc153910d9",
   "metadata": {
    "id": "46bdaa07-ba96-4ac1-9d71-b3cc153910d9"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch05_compressed/09.webp\" width=900px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0959c855-f860-4358-8b98-bc654f047578",
   "metadata": {
    "id": "0959c855-f860-4358-8b98-bc654f047578"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from previous_chapters import create_dataloader_v1\n",
    "\n",
    "# 1. 데이터 분할 (Data Splitting)\n",
    "# 전체 데이터를 9:1 비율로 나눕니다.\n",
    "# - 90% (Train): 모델이 패턴을 배우는 데 사용\n",
    "# - 10% (Validation): 모델이 잘 배우고 있는지 평가하는 데 사용 (본 적 없는 데이터)\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data)) # 분할 기준점 인덱스 계산\n",
    "\n",
    "train_data = text_data[:split_idx] # 처음부터 90% 지점까지\n",
    "val_data = text_data[split_idx:]   # 90% 지점부터 끝까지\n",
    "\n",
    "# \n",
    "\n",
    "# 2. 랜덤 시드 고정\n",
    "# 데이터 로더 내부에서 데이터를 섞는(Shuffle) 순서가 매번 같도록 고정합니다.\n",
    "# 이는 실험 결과를 재현 가능하게 만드는 데 중요합니다.\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# 3. 학습용 데이터 로더 생성 (Train Loader)\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,         # 한 번에 2개의 샘플씩 묶어서 처리\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"], # 한 샘플당 토큰 길이 (예: 256)\n",
    "    \n",
    "    # stride(보폭): 윈도우가 이동하는 간격\n",
    "    # stride와 max_length가 같으면 데이터가 겹치지 않고 딱딱 끊어서 가져옵니다.\n",
    "    # (반면, stride가 작으면 데이터가 겹치게 되어 학습 데이터 양이 늘어나는 효과가 있습니다)\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    \n",
    "    # drop_last=True: \n",
    "    # 데이터 개수가 배치 사이즈로 딱 나누어떨어지지 않을 때, \n",
    "    # 마지막에 남는 짜투리 데이터를 버립니다. (학습 안정성을 위해 주로 사용)\n",
    "    drop_last=True,\n",
    "    \n",
    "    # shuffle=True:\n",
    "    # 데이터를 무작위로 섞어서 모델이 순서 자체를 외우는 것을 방지합니다. (학습 시 필수!)\n",
    "    shuffle=True,\n",
    "    num_workers=0 # 데이터 로딩에 사용할 프로세스 수 (0은 메인 프로세스만 사용)\n",
    ")\n",
    "\n",
    "# 4. 검증용 데이터 로더 생성 (Validation Loader)\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    \n",
    "    # drop_last=False:\n",
    "    # 검증할 때는 모든 데이터를 빠짐없이 평가해야 하므로 남는 데이터도 버리지 않습니다.\n",
    "    drop_last=False,\n",
    "    \n",
    "    # shuffle=False:\n",
    "    # 검증 결과의 일관성을 위해 섞지 않고 순서대로 평가합니다.\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f37b3eb0-854e-4895-9898-fa7d1e67566e",
   "metadata": {
    "id": "f37b3eb0-854e-4895-9898-fa7d1e67566e"
   },
   "outputs": [],
   "source": [
    "# 유효성 검사\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"훈련 데이터 로더에 토큰이 충분하지 않습니다. \"\n",
    "          \"`GPT_CONFIG_124M['context_length']`를 낮추거나 \"\n",
    "          \"`training_ratio`를 증가시키세요.\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"훈련 데이터 로더에 토큰이 충분하지 않습니다. \"\n",
    "          \"`GPT_CONFIG_124M['context_length']`를 낮추거나 \"\n",
    "          \"`training_ratio`를 증가시키세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ac3296-a4d1-4303-9ac5-376518960c33",
   "metadata": {
    "id": "e7ac3296-a4d1-4303-9ac5-376518960c33"
   },
   "source": [
    "- 컴퓨팅 자원을 절감하고 데이터셋이 매우 작기 때문에 비교적 작은 배치 크기를 사용합니다.\n",
    "- 예를 들어 Llama 2 7B는 배치 크기 1024에서 훈련되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e0514d-b990-4dc0-9afb-7721993284a0",
   "metadata": {
    "id": "a8e0514d-b990-4dc0-9afb-7721993284a0"
   },
   "source": [
    "- 데이터가 올바르게 로드되었는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca0116d0-d229-472c-9fbf-ebc229331c3e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ca0116d0-d229-472c-9fbf-ebc229331c3e",
    "outputId": "16bde066-4c1e-41b3-d375-06b94b2c3c89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 로더:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "검증 데이터 로더:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"훈련 데이터 로더:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\n검증 데이터 로더:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b9b1a4-863d-456f-a8dd-c07fb5c024ed",
   "metadata": {
    "id": "f7b9b1a4-863d-456f-a8dd-c07fb5c024ed"
   },
   "source": [
    "- 토큰 크기가 예상 범위 안에 있는지 추가로 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb860488-5453-41d7-9870-23b723f742a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eb860488-5453-41d7-9870-23b723f742a0",
    "outputId": "adf4ea59-6c5a-4fd0-c8f5-0807894858e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 토큰 수: 4608\n",
      "검증 토큰 수: 512\n",
      "모든 토큰 수: 5120\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"훈련 토큰 수:\", train_tokens)\n",
    "print(\"검증 토큰 수:\", val_tokens)\n",
    "print(\"모든 토큰 수:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3085e8-665e-48eb-bb41-cdde61537e06",
   "metadata": {
    "id": "5c3085e8-665e-48eb-bb41-cdde61537e06"
   },
   "source": [
    "- 주어진 배치에서 크로스 엔트로피 손실을 계산 하는 유틸리티 함수를 작성 합니다\n",
    "- 또한 데이터 로더에서 사용자가 지정한 배치 개수 만큼 추출하여 손실을 계산하는 두 번째 유틸리티 함수를 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b9de31e-4096-47b3-976d-b6d2fdce04bc",
   "metadata": {
    "id": "7b9de31e-4096-47b3-976d-b6d2fdce04bc"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 함수 1: 단일 배치에 대한 손실 계산\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    # 1. 장치 이동 (CPU -> GPU)\n",
    "    # 데이터를 모델이 있는 장치(device)로 옮깁니다. (예: cuda:0)\n",
    "    # 모델과 데이터가 서로 다른 장치에 있으면 에러가 발생합니다.\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "    # 2. 모델 예측 (Forward Pass)\n",
    "    # 입력을 넣어 예측값(Logits)을 얻습니다.\n",
    "    logits = model(input_batch)\n",
    "\n",
    "    # 3. 손실(Loss) 계산\n",
    "    # CrossEntropyLoss는 (N, Class) 형태의 2차원 입력을 기대합니다.\n",
    "    # 따라서 (Batch, Sequence, Vocab) 형태인 logits를 -> (Batch*Sequence, Vocab)으로 폅니다.\n",
    "    # target_batch도 (Batch, Sequence) -> (Batch*Sequence)로 일렬로 폅니다.\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "# 함수 2: 데이터 로더(여러 배치)에 대한 평균 손실 계산\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    \n",
    "    # 예외 처리: 데이터 로더가 비어있으면 NaN(Not a Number)을 반환\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    \n",
    "    # 1. 평가할 배치 개수 설정\n",
    "    # num_batches가 지정되지 않았다면(None), 데이터 로더의 전체 데이터를 다 사용합니다.\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # 사용자가 요청한 개수(num_batches)가 실제 데이터 개수보다 많으면\n",
    "        # 실제 데이터 개수(len(data_loader))까지만 확인하도록 제한합니다.\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    # 2. 배치 반복문 실행\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        # 지정된 배치 개수만큼만 루프를 돕니다.\n",
    "        if i < num_batches:\n",
    "            # 위에서 만든 함수를 재사용해 현재 배치의 손실을 구합니다.\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            \n",
    "            # 3. 손실 누적 (.item()의 중요성)\n",
    "            # loss는 텐서(Tensor)입니다. 이를 그대로 더하면 계산 그래프가 계속 메모리에 남습니다.\n",
    "            # .item()을 써서 순수 파이썬 실수형(float) 값만 뽑아내야 메모리 누수를 막을 수 있습니다.\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            # 정해진 횟수를 채웠으면 루프를 중단합니다.\n",
    "            break\n",
    "            \n",
    "    # 4. 평균 손실 반환\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0691332-84d0-48b3-b462-a885ddeb4fca",
   "metadata": {
    "id": "f0691332-84d0-48b3-b462-a885ddeb4fca"
   },
   "source": [
    "- CUDA를 지원하는 GPU를 가지고 있다면 어떤 코드도 변경할 필요 없이 GPU 에서 LLM을 훈련할 수 있습니다.\n",
    "- `device` 설정을 통해 데이터를 LLM 모델과 동일한 장치에 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56f5b0c9-1065-4d67-98b9-010e42fc1e2a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "56f5b0c9-1065-4d67-98b9-010e42fc1e2a",
    "outputId": "95e16aa8-0f0a-4440-814b-3ab398bb1737"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device.\n",
      "훈련 손실: 10.987583266364204\n",
      "검증 손실: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 1. 장치(Device) 자동 설정\n",
    "# 우선순위: CUDA(NVIDIA GPU) -> MPS(Apple Silicon Mac) -> CPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\") # NVIDIA GPU가 있으면 최우선으로 사용\n",
    "    \n",
    "elif torch.backends.mps.is_available():\n",
    "    # Apple Silicon(M1/M2/M3 등)의 MPS 가속 기능 확인\n",
    "    # 파이토치 버전 정보를 숫자(Major, Minor)로 분리합니다.\n",
    "    major, minor = map(int, torch.__version__.split(\".\")[:2])\n",
    "\n",
    "else:\n",
    "    # 아무런 가속기도 없으면 일반 CPU를 사용합니다.\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using {device} device.\") # 현재 선택된 장치 출력\n",
    "\n",
    "\n",
    "# 2. 모델을 장치로 이동\n",
    "# 중요: nn.Module(모델)은 .to()를 쓰면 제자리(In-place)에서 이동됩니다.\n",
    "# (텐서와 달리 'model = model.to(device)'라고 다시 할당할 필요가 없습니다.)\n",
    "model.to(device) \n",
    "\n",
    "# 3. 랜덤 시드 고정\n",
    "# 데이터 로더가 데이터를 섞을 때(shuffle), 그리고 모델 초기화 등에서 \n",
    "# 매번 같은 결과가 나오도록 시드를 고정합니다.\n",
    "torch.manual_seed(123) \n",
    "\n",
    "# 4. 초기 손실값(Baseline Loss) 확인\n",
    "# 학습을 전혀 하지 않은 상태에서 손실값이 얼마나 나오는지 확인합니다.\n",
    "# 이 값은 일종의 '기준점'이 되며, 학습 후 이보다 낮아져야 정상입니다.\n",
    "with torch.no_grad(): # 평가만 할 것이므로 미분(Gradient) 계산을 끕니다 (메모리 절약).\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"훈련 손실:\", train_loss)\n",
    "print(\"검증 손실:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43875e95-190f-4b17-8f9a-35034ba649ec",
   "metadata": {
    "id": "43875e95-190f-4b17-8f9a-35034ba649ec"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch05_compressed/10.webp\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9339f8d-00cb-4206-af67-58c32bd72055",
   "metadata": {
    "id": "b9339f8d-00cb-4206-af67-58c32bd72055"
   },
   "source": [
    "## 5.2 LLM 훈련하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652a4cf4-e98f-46d9-bdec-60e7ccb8d6bd",
   "metadata": {
    "id": "652a4cf4-e98f-46d9-bdec-60e7ccb8d6bd"
   },
   "source": [
    "- 이 절에서는 LLM 훈련을 위한 코드를 구현합니다.\n",
    "- 여기서는 간단한 훈련 함수를 만듭니다(이 훈련 함수를 학습률 워밍업, 코사인 어닐링, 그레이디언트 클리핑 같은 고급 기법으로 확장하고 싶다면 [부록 D](../../appendix-D/01_main-chapter-code)를 참고하세요).\n",
    "\n",
    "<img src=\"images/llm_from_scratch/ch05_compressed/11.webp\" width=600px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "Mtp4gY0ZO-qq",
   "metadata": {
    "id": "Mtp4gY0ZO-qq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    \"\"\"\n",
    "    모델을 학습시키는 메인 함수입니다.\n",
    "    \n",
    "    Args:\n",
    "        model: 학습할 신경망 모델\n",
    "        train_loader: 훈련 데이터 로더\n",
    "        val_loader: 검증 데이터 로더 (과적합 확인용)\n",
    "        optimizer: 가중치 업데이트를 위한 최적화 도구 (예: AdamW)\n",
    "        device: 학습을 수행할 장치 (CPU 또는 GPU)\n",
    "        num_epochs: 전체 데이터를 몇 번 반복 학습할지 설정\n",
    "        eval_freq: 몇 번의 스텝마다 평가를 진행할지 설정\n",
    "        eval_iter: 평가 시 사용할 배치의 개수\n",
    "        start_context: 샘플 생성 시 시작할 텍스트 문구\n",
    "        tokenizer: 텍스트와 토큰 ID 간의 변환 도구\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. 기록용 리스트 초기화\n",
    "    # 훈련 손실, 검증 손실, 처리한 총 토큰 수를 저장하여 나중에 그래프로 그릴 때 사용합니다.\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # 2. 메인 훈련 루프 시작 (Epoch 단위)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # 모델을 '훈련 모드'로 전환 (드롭아웃, 배치정규화 등이 활성화됨)\n",
    "\n",
    "        # 데이터 로더에서 배치 단위로 데이터를 가져옴\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # [중요] 이전 배치의 기울기(Gradient) 정보 초기화 (누적 방지)\n",
    "            \n",
    "            # 순전파 (Forward Pass) 및 손실 계산\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            \n",
    "            # 역전파 (Backward Pass): 손실에 따른 각 가중치의 기울기 계산\n",
    "            loss.backward() \n",
    "            \n",
    "            # 가중치 업데이트: 계산된 기울기를 바탕으로 모델 파라미터 수정\n",
    "            optimizer.step() \n",
    "            \n",
    "            # 진행 상황 추적\n",
    "            tokens_seen += input_batch.numel() # 처리한 토큰 수 누적\n",
    "            global_step += 1\n",
    "\n",
    "            # 3. 주기적인 평가 (Evaluation Step)\n",
    "            # 지정된 스텝(eval_freq)마다 훈련/검증 손실을 계산해 모델 상태를 체크합니다.\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                \n",
    "                # 기록 저장\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                \n",
    "                # 진행 상황 출력 (로그)\n",
    "                print(f\"에포크 {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"훈련 손실 {train_loss:.3f}, 검증 손실 {val_loss:.3f}\")\n",
    "\n",
    "        # 4. 에포크 종료 후 샘플 생성\n",
    "        # 모델이 학습되면서 문장 생성 능력이 어떻게 변하는지 눈으로 확인합니다.\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    \"\"\"\n",
    "    현재 모델의 성능(손실)을 측정하는 함수입니다. 학습에는 영향을 주지 않습니다.\n",
    "    \"\"\"\n",
    "    model.eval() # 모델을 '평가 모드'로 전환 (드롭아웃 비활성화 등)\n",
    "    \n",
    "    with torch.no_grad(): # [중요] 기울기 계산 비활성화 (메모리 절약 및 속도 향상)\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    \n",
    "    model.train() # 평가가 끝나면 다시 '훈련 모드'로 복구해야 함\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    \"\"\"\n",
    "    모델이 현재 어떻게 텍스트를 생성하는지 확인하기 위한 함수입니다.\n",
    "    \"\"\"\n",
    "    model.eval() # 평가 모드 설정\n",
    "    \n",
    "    context_size = model.pos_emb.weight.shape[0] # 모델이 처리 가능한 최대 문맥 길이\n",
    "    \n",
    "    # 시작 텍스트를 토큰 ID로 변환(Encoding) 후 장치로 이동\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    \n",
    "    with torch.no_grad(): # 생성 과정에서는 학습이 필요 없으므로 기울기 계산 끔\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "        \n",
    "    # 생성된 토큰 ID들을 다시 텍스트로 변환(Decoding)\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    \n",
    "    # 보기 좋게 줄바꿈 문자를 공백으로 치환하여 출력\n",
    "    print(decoded_text.replace(\"\\n\", \" \")) \n",
    "    \n",
    "    model.train() # 다시 훈련 모드로 복구"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a301b333-b9d4-4eeb-a212-3a9874e3ac47",
   "metadata": {
    "id": "a301b333-b9d4-4eeb-a212-3a9874e3ac47"
   },
   "source": [
    "- 위에 정의한 훈련 함수로 LLM을 훈련해 보죠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3422000b-7aa2-485b-92df-99372cd22311",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3422000b-7aa2-485b-92df-99372cd22311",
    "outputId": "c561513b-e8a8-4d9e-9fb8-d2cf513558c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크 1 (Step 000000): 훈련 손실 9.820, 검증 손실 9.932\n",
      "에포크 1 (Step 000005): 훈련 손실 8.065, 검증 손실 8.341\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "에포크 2 (Step 000010): 훈련 손실 6.621, 검증 손실 7.052\n",
      "에포크 2 (Step 000015): 훈련 손실 6.047, 검증 손실 6.601\n",
      "Every effort moves you, and,, and,,,,,,, and,.                                   \n",
      "에포크 3 (Step 000020): 훈련 손실 5.582, 검증 손실 6.480\n",
      "에포크 3 (Step 000025): 훈련 손실 5.524, 검증 손실 6.402\n",
      "Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and\n",
      "에포크 4 (Step 000030): 훈련 손실 5.110, 검증 손실 6.354\n",
      "에포크 4 (Step 000035): 훈련 손실 4.987, 검증 손실 6.386\n",
      "Every effort moves you, and a, and a, and a-- the picture. Gisburn, and a was, and a. I had been. of the of the of the of the of the of the of the of the of the. I had a\n",
      "에포크 5 (Step 000040): 훈련 손실 4.369, 검증 손실 6.264\n",
      "Every effort moves you, one of the picture--as of the picture--as of the of the of the picture--as of the fact of the picture of the picture of the picture of the picture.   \"I had been the of the picture of the\n",
      "에포크 6 (Step 000045): 훈련 손실 3.978, 검증 손실 6.204\n",
      "에포크 6 (Step 000050): 훈련 손실 3.479, 검증 손실 6.194\n",
      "Every effort moves you know the                                                \n",
      "에포크 7 (Step 000055): 훈련 손실 3.510, 검증 손실 6.213\n",
      "에포크 7 (Step 000060): 훈련 손실 2.728, 검증 손실 6.146\n",
      "Every effort moves you know he was not that I felt--I looked, and I felt to have to have to see a little to me to have to see a little of his pictures--I looked.             \n",
      "에포크 8 (Step 000065): 훈련 손실 2.255, 검증 손실 6.148\n",
      "에포크 8 (Step 000070): 훈련 손실 1.922, 검증 손실 6.216\n",
      "Every effort moves you know,\" was not that the picture.  \"I had the last word.           \"I turned back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "에포크 9 (Step 000075): 훈련 손실 1.547, 검증 손실 6.220\n",
      "에포크 9 (Step 000080): 훈련 손실 1.216, 검증 손실 6.279\n",
      "Every effort moves you know,\" was not that my hostess was \"interesting\": on that I had not till I felt to me to me to have to see a smile behind his pictures with a little.   \"I had been the bull--and by his\n",
      "에포크 10 (Step 000085): 훈련 손실 0.922, 검증 손실 6.320\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 노트:\n",
    "# 실행 시간을 계산하고 싶다면 다음 주석을 해제하세요. (학습에 얼마나 걸리는지 측정용)\n",
    "# import time\n",
    "# start_time = time.time()\n",
    "\n",
    "# 1. 재현성(Reproducibility) 설정\n",
    "# 매번 실행할 때마다 결과가 달라지지 않도록 랜덤 시드를 고정합니다.\n",
    "# 이렇게 하면 가중치 초기화 등이 동일하게 시작되어 실험 결과를 비교하기 좋습니다.\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# 2. 모델 인스턴스 생성\n",
    "# 사전에 정의된 설정(GPT_CONFIG_124M)을 사용하여 GPT 모델 구조를 만듭니다.\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "# 3. 모델을 장치로 이동\n",
    "# 모델의 파라미터들을 GPU(cuda) 또는 CPU로 옮깁니다. (이전에 정의한 device 변수 사용)\n",
    "model.to(device)\n",
    "\n",
    "# 4. 옵티마이저(Optimizer) 설정\n",
    "# AdamW: Adam 알고리즘에 가중치 감쇠(Weight Decay)가 개선된 버전으로, LLM 학습에 표준적으로 쓰입니다.\n",
    "# lr=0.0004: 학습률(Learning Rate). 한 번의 업데이트로 가중치를 얼마나 변경할지 결정합니다.\n",
    "# weight_decay=0.1: 과적합(Overfitting)을 막기 위해 가중치가 너무 커지지 않도록 억제하는 규제 값입니다.\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "# 5. 학습 루프 실행\n",
    "num_epochs = 10  # 전체 데이터를 10번 반복해서 학습\n",
    "\n",
    "# train_model_simple 함수를 호출하여 학습을 진행하고, 결과(손실 기록 등)를 반환받습니다.\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=num_epochs,\n",
    "    eval_freq=5,       # 5번의 스텝(배치 업데이트)마다 검증(Validation)을 수행\n",
    "    eval_iter=5,       # 검증 시 5개의 배치만 사용하여 빠르게 손실 계산\n",
    "    start_context=\"Every effort moves you\", # 에포크마다 생성 테스트를 해볼 시작 문구\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Note:\n",
    "# 실행 시간을 계산하고 싶다면 다음 주석을 해제하세요.\n",
    "# end_time = time.time()\n",
    "# execution_time_minutes = (end_time - start_time) / 60\n",
    "# print(f\"훈련 소요 시간: {execution_time_minutes:.2f}분.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8b86f0-b07d-40d7-b9d3-a9218917f204",
   "metadata": {
    "id": "2e8b86f0-b07d-40d7-b9d3-a9218917f204"
   },
   "source": [
    "- 여러분의 결과와 손실 값이 조금 다를 수 있습니다. 대체적으로 비슷하다면 (훈련 손실은 1이하이고 검증 손실은 7이하이면) 걱정할 필요가 없습니다.\n",
    "- GPU 하드웨어와 CUDA 버전 또는 파이토치의 신버전에서 바뀐 변화 때문에 차이가 발생할 수 있습니다.\n",
    "- CPU에서 이 예제를 실행하더라도 작은 차이를 볼 수 있습니다. 이런 차이를 만드는 원인 중 하나는 파이토치가 컴파일된 운영체제에 따라 `nn.Dropout`의 동작 방식이 다르기 때문입니다. 자세한 내용은 파이토치 [깃허브 이슈](https://github.com/pytorch/pytorch/issues/121595)를 참고하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0WSRu2i0iHJE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "0WSRu2i0iHJE",
    "outputId": "843a9009-b1b2-4d60-a0e9-26b75ee0836c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # 에포크에 대한 훈련 손실과 검증 손실의 그래프를 그립니다.\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # 처리한 토큰 수에 대한 두 번째 x 축을 만듭니다.\n",
    "    ax2 = ax1.twiny()  # y 축을 공유하는 두 번째 x 축을 만듭니다.\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # 눈금을 정렬하기 위해 투명한 그래프를 만듭니다.\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(\"outputs/loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc83ded-5f80-4e1c-bf4d-ccb59999d995",
   "metadata": {
    "id": "8bc83ded-5f80-4e1c-bf4d-ccb59999d995"
   },
   "source": [
    "- 위 결과를 보면 모델이 처음에는 이해할 수 없는 단어를 생성하지만 마지막으로 갈수록 문법적으로 어느 정도 정확한 문장을 생성합니다.\n",
    "- 하지만 훈련 세트 손실과 검증 세트 손실을 보면 모델이 과대적합되기 시작합니다.\n",
    "- 마지막 부분의 몇 문장을 확인하면 훈련 세트에 있는 내용이라는 것을 알 수 있습니다. 모델이 단순히 훈련 데이터를 암기한 것입니다.\n",
    "- 매우 작은 훈련 세트를 사용하고 모델을 여러 에포크에서 훈련하고 있기 때문에 과대적합이 일어납니다.\n",
    "  - 여기서는 교육적인 목적을 위해 LLM을 훈련합니다. 모델이 일관된 텍스트를 생성하는 방법을 학습할 수 있는지 확인하는 것이 주요 목적입니다.\n",
    "  - 대량의 고가 하드웨어에서 몇 주 또는 몇 달 동안 이런 모델을 훈련하는 대신에 나중에 사전 훈련된 가중치를 로드하여 사용하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb380c42-b31c-4ee1-b8b9-244094537272",
   "metadata": {
    "id": "eb380c42-b31c-4ee1-b8b9-244094537272"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch05_compressed/13.webp\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5cdf2f-09a5-4eb0-a20a-d7aac5c14c2c",
   "metadata": {
    "id": "6d5cdf2f-09a5-4eb0-a20a-d7aac5c14c2c"
   },
   "source": [
    "- 더 큰 훈련 데이터셋에서 오래 모델을 훈련하고 싶다면 [../03_bonus_pretraining_on_gutenberg](../03_bonus_pretraining_on_gutenberg)을 참고하세요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699f45fc-bf78-42f2-bd24-2355db41b28f",
   "metadata": {
    "id": "699f45fc-bf78-42f2-bd24-2355db41b28f"
   },
   "source": [
    "## 5.3 무작위성을 제어하기 위한 디코딩 전략"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be9086e-2c27-41da-97d0-49137d0ba3c7",
   "metadata": {
    "id": "6be9086e-2c27-41da-97d0-49137d0ba3c7"
   },
   "source": [
    "- 위에서 구현한 GPT 모델처럼 작은 LLM의 추론 비용은 비교적 저렴합니다. 따라서 훈련에 GPU를 사용했더라도 추론에서는 GPU를 사용할 필요가 없습니다.\n",
    "- 이전 장에서 만든 `generate_text_simple` 함수를 사용해 한 번에 하나의 단어(또는 토큰)씩 새로운 텍스트를 생성할 수 있습니다.\n",
    "- 5.1.2절에서 설명했듯이 생성된 다음 토큰은 어휘사전의 모든 토큰 중에서 확률 점수가 가장 높은 토큰입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2734cee0-f6f9-42d5-b71c-fa7e0ef28b6d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2734cee0-f6f9-42d5-b71c-fa7e0ef28b6d",
    "outputId": "a04a6ae7-7be6-4f72-bc2d-4930d0a0fac4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출력 텍스트:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NEW: 이후 코드의 결과를 책과 일치하도록 만들기 위해 CPU를 사용합니다.\n",
    "inference_device = torch.device(\"cpu\")\n",
    "\n",
    "model.to(inference_device)\n",
    "model.eval()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(inference_device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"출력 텍스트:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25dbe31-bb7c-4893-b25b-47d0492d4aa4",
   "metadata": {
    "id": "d25dbe31-bb7c-4893-b25b-47d0492d4aa4"
   },
   "source": [
    "- `generate_text_simple` 함수를 여러번 실행하더라도 LLM은 항상 동일한 출력을 생성합니다.\n",
    "- `generate_text_simple`를 수정하기 위해 두 가지 디코딩 전략을 소개합니다. *온도 스케일링*과 *탑-k* 샘플링입니다.\n",
    "- 이를 사용해 모델이 생성된 텍스트의 무작위성과 다양성을 조절할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb6f380-a798-4fd9-825c-17b7cd29a994",
   "metadata": {
    "id": "4bb6f380-a798-4fd9-825c-17b7cd29a994"
   },
   "source": [
    "### 5.3.1 온도 스케일링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f4f53c-0612-43d3-aa82-52447eac50fa",
   "metadata": {
    "id": "a7f4f53c-0612-43d3-aa82-52447eac50fa"
   },
   "source": [
    "- 이전에는 `torch.argmax`를 사용해 항상 가장 높은 확률을 가진 토큰을 다음 토큰으로 샘플링했습니다.\n",
    "- 다양성을 추가하기 위해 확률 분포에서 샘플링하도록 `torch.multinomial(probs, num_samples=1)`을 사용해 토큰을 샘플링할 수 있습니다.\n",
    "- 여기서 각 인덱스 선택 가능성은 입력 텐서에 있는 확률에 따라 결정됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7531bae-d5de-44c0-bc78-78fed077e22a",
   "metadata": {
    "id": "e7531bae-d5de-44c0-bc78-78fed077e22a"
   },
   "source": [
    "- 여기에서 다음 토큰 생성에 대해 간략히 정리해 보겠습니다. 설명을 위해 매우 작은 어휘사전을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01a5ce39-3dc8-4c35-96bc-6410a1e42412",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "01a5ce39-3dc8-4c35-96bc-6410a1e42412",
    "outputId": "f6588dd8-5b3f-4dc7-9e13-473afd36c698"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "vocab = {\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "}\n",
    "\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "# 입력이 \"every effort moves you\"이고\n",
    "# LLM이 다음 토큰을 위해 아래와 같은 로짓을 반환했다고 가정해 보죠.\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "\n",
    "# 생성될 토큰은 다음과 같습니다.\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6400572f-b3c8-49e2-95bc-433e55c5b3a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6400572f-b3c8-49e2-95bc-433e55c5b3a1",
    "outputId": "282da416-9f62-4947-b299-7353de2a65fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 1. 재현성(Reproducibility) 설정\n",
    "# 난수 생성기의 시드(Seed)를 123으로 고정합니다.\n",
    "# 이렇게 하면 코드를 여러 번 실행해도 '무작위 뽑기'의 결과가 항상 똑같이 나옵니다.\n",
    "# (실험 결과를 일정하게 유지하고 싶을 때 필수적입니다.)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# 2. 확률 분포에 기반한 랜덤 샘플링 (핵심!)\n",
    "# probas: 모델이 예측한 다음 토큰들의 등장 확률 (예: \"사과\"=10%, \"바나나\"=80%, \"포도\"=10%)\n",
    "# torch.multinomial: 위 확률(가중치)을 반영하여 주사위를 굴립니다.\n",
    "#                    확률이 높을수록 뽑힐 가능성이 크지만, 낮은 확률의 토큰도 뽑힐 수 있습니다.\n",
    "# num_samples=1: 딱 1개만 뽑습니다.\n",
    "# .item(): 뽑힌 결과는 텐서(Tensor) 형태이므로, 이를 파이썬 정수(int) 값으로 변환합니다.\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "\n",
    "# 3. 결과 출력\n",
    "# inverse_vocab: {숫자 ID: \"단어\"} 형태로 된 사전(Dictionary)입니다.\n",
    "# 위에서 뽑은 숫자(ID)를 사람이 읽을 수 있는 실제 단어로 바꾸어 출력합니다.\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63d0a27-830b-42b5-9986-6d1a7de04dd9",
   "metadata": {
    "id": "c63d0a27-830b-42b5-9986-6d1a7de04dd9"
   },
   "source": [
    "- `torch.argmax`로 가장 가능성이 높은 토큰을 결정하는 대신에 `torch.multinomial(probas, num_samples=1)`를 사용해 소프트맥스 분포에서 샘플링하여 가장 가능성이 높은 토큰을 결정할 수 있습니다.\n",
    "- 설명을 위해 원래 소프트맥스 분포에서 1,000번 토큰을 샘플링해 보죠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b23b863e-252a-403c-b5b1-62bc0a42319f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b23b863e-252a-403c-b5b1-62bc0a42319f",
    "outputId": "ee53e519-d018-4b6a-e997-f66b684ed371"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "582 x forward\n",
      "2 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "343 x toward\n",
      "0 x you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123) # 재현가능성을 위한 랜덤 시드\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample), minlength=len(probas))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e7d9cf-a26d-4d9a-8664-4af1efa73832",
   "metadata": {
    "id": "32e7d9cf-a26d-4d9a-8664-4af1efa73832"
   },
   "source": [
    "- 온도 스케일링으로 분포와 선택 과정을 조절할 수 있습니다.\n",
    "- \"온도 스케일링\"은 로짓을 0보다 큰 숫자로 나누는 것을 의미합니다.\n",
    "- 1보다 큰 온도는 소프트맥스 함수를 적용한 후에 더 균등한 토큰 확률 분포를 만듭니다.\n",
    "- 1보다 작은 온도는 소프트맥스 함수를 적용한 후에 더 결정론적인 분포(더 날카롭거나 뾰족한 분포)를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0759e4c8-5362-467c-bec6-b0a19d1ba43d",
   "metadata": {
    "id": "0759e4c8-5362-467c-bec6-b0a19d1ba43d"
   },
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "\n",
    "# 온도 값\n",
    "temperatures = [1, 0.1, 5]  # 원본, 낮은 온도, 높은 온도\n",
    "\n",
    "# 스케일을 조정한 확률 계산\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e66e613-4aca-4296-a984-ddd0d80c6578",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "2e66e613-4aca-4296-a984-ddd0d80c6578",
    "outputId": "4ad8e021-e147-43cf-ccdc-fdcdad8429c5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAEiCAYAAAA21pHjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAPrRJREFUeJzt3QeUU9X2P/BN703pTZrSi4D0otJBEWwUBUTgiYCgCFKkSpUm8BhAaYJ0eYKKSn3SBKQXaSpFePQOAlLvf333f938kpAZZibJ5NzM97NWFjOZmeROuJN9zzn77J3AsixLiIiIyEgJQ30AREREFDkGaiIiIoMxUBMRERmMgZqIiMhgDNREREQGY6AmIiIyGAM1ERGRwRioiYiIDJZY4pkHDx7IqVOnJE2aNJIgQYJQHw4REcVDlmXJ9evXJXv27JIwYdRj5ngXqBGkc+XKFerDICIikhMnTkjOnDmjfCXiXaDGSNp+cdKmTRvqwyEionjo2rVrOmi0Y1JU4l2gtqe7EaQZqImIKJSiswTLZDIiIiKDhTRQr1u3Tl588UVdTMdVxZIlSx75M2vWrJHSpUtLsmTJpECBAvLll1/GybESERHFu0B948YNKVmypERERETr+48ePSoNGjSQ5557Tnbt2iXvv/++tG3bVpYvXx70YyUiIgqFkK5R16tXT2/RNXnyZMmbN6+MHj1aPy9cuLBs2LBBPvvsM6lTp04Qj5SI4nob5Z07d/iik2MlSZJEEiVKFJDHclQy2aZNm6RmzZoe9yFAY2Qdmdu3b+vNPdOOiMyFAI3ZMwRrIidLnz69ZM2a1e+aHY4K1GfOnJEsWbJ43IfPEXxv3bolKVKkeOhnhg0bJgMHDozDoyQif4pAnD59Wkci2LryqEIQRKaexzdv3pRz587p59myZYs/gTo2evXqJV27dn1o7xoRmefevXv6BocE05QpU4b6cIhizR44IlhnzpzZr2lwRwVqTCGcPXvW4z58jv3QvkbTgOxw3IiMMiBdFF+7KvHV/fv39d+kSZOG+lCI/GZfbN69e9evQO2oeaWKFSvK6tWrPe5buXKl3k9E4YN1+CkcJAhQP4mQBuq///5bt1nhBkggwcfHjx93TVu3bNnS9f3t27eXI0eOyEcffSQHDx6UiRMnysKFC+WDDz4I2e9AREQUTCEN1Nu2bZOnn35ab4C1ZHzcr18//RxJJXbQBmzN+uGHH3QUjf3X2KY1depUbs0iIqKwFdI16meffVaz4yLjq+oYfmbnzp1BPjIiMkmenj/E6fMdG94gYNOb/fv3lwEDBkg4yZMnj26LjWprrOk6d+4sv/zyi/z2229ak8Oe2TWRo5LJiIhMg5k/24IFC3RG8NChQ677UqdOLU6AQROS+RInThyne+ZDmTj49ttvy6+//ip79uwRkzkqmYyIyMTdKPYtXbp0OsJ2v2/+/Pk6YkuePLkUKlRIc2tsx44d0+9Hrk3VqlV198ozzzwjv//+u2zdulXKli2rgR4VHM+fP+/6ubfeeksaNWqkNSIyZcqkO1+Qw+NezQ0FY1BHAkuGeFwsFy5atMijbwKe+6effpIyZcro7hhUejx8+LC89NJLWqMCz43jWbVqlces5l9//aW5Qfh5e0YBswalSpXyeG3Gjh2ro2/v4x4yZIhuwStYsKCr7fDrr7+uBUIee+wxfX68NsE0fvx46dixo+TLl09Mx0BNRBQkc+bM0RE2AtOBAwdk6NCh0rdvX5k5c+ZD0+N9+vSRHTt26Ii2efPmmjQ7btw4Wb9+vfz555+u3B0bdsDgMRFw582bJ998841HcScE6VmzZmnp5X379mlgffPNN2Xt2rUej9OzZ08ZPny4PlaJEiU0ybd+/fr6+FhmrFu3rjZPsvOF8Dw5c+aUTz75RGcT3GcUogOPixkH5BotXbpUty6hwiT6MuN3xXQ0LhDwvFGVkU2dOnWUN1y4hAtOfRMRBQkCMJJeX375Zf0co9v9+/fL559/Lq1atXJ9X7du3VxJsV26dJFmzZppQKtcubLe16ZNm4dydjBlPH36dN2rW7RoUQ2c3bt3l0GDBmnww0UBRsL29lWMHDFixnNXr17d9Tj4uVq1ark+x4gWo28bHm/x4sXy3XffSadOnfTr2BOMwIoZg5hKlSqVJgHbU96zZ8/W0T/us0fnM2bM0NE1LkJq167t83EetaaMWYZwwUBNRBSk7oCYRkaQbdeunUf1NUyRu8NI1maXSS5evLjHfXY5ShuCqXv1NgRkjIYxjYx/UeHNPQADRqj2Lhsbptfd4WcxjY0dNhgt43hRotl9B44/8Hu5r0vv3r1bZwwQ+N39888/+vpFBm2O4wsGaiKiIEDAgylTpkj58uU9vuZdpQqdlmz2qNL7vpg0KbGfG8E2R44cHl/zrtSIEa47jO4xLT1q1CgNhljffvXVVx/ZzQx12b138WBk7837+XCsWCPHMoE3rL9H5lFJepjmx7R/OGCgJiIKAoyCkTCFIk1vvPFGwB8fI1H3ZkSbN2/W4IVeBpieRkDGKNh9mjs6sEaMpK/GjRu7Aql3YhdGxHa5V/egisZJCNb2xUZ0tjyVLl1as+VRDzsm09W7OPVNRET+QnIX9utiqhvJUWi5i0JPly9f9mgWFBsY4WJaHUloCKRYD8caMka2mEbGyBgJZBiJV6lSRa5evapBGMHQfX3c25NPPqkJY0ggQ8BF8pv3aB6Z3OvWrZOmTZvqBUHGjBk1GxyZ6SNGjNAR+LJlyzSj/FHBFxcxI0eO1ExvrJcjUQ1Z5TgGJNTlzJkzKFPfmG7HRQguLnDBYwf+IkWKGFdrnlnfRERB0rZtW02SQnIU1mYxukVSGJLK/FWjRg0NqtWqVZMmTZpIw4YNPQqrIAkMQRbZ39gehgsFTIU/6rnHjBkjGTJkkEqVKmmwRpIbRr3uEFBxcZA/f37X9DSeA1vPIiIidP18y5YterHwKFhnR9DPnTu3Jt3hcXABgjXqYCaEtW3bVtfrkVyH7XB2lcxTp06JaRJYUZUGC0Noc4mrW1xdhlNWIDkMu2f5hDdn1PxHMMG+Y/INU9NXrlyRJUuW8CVy6Pkck1jEETUREZHBGKiJiIgMxqxvIiKH8dWwiMIXR9REREQGY6AmIiIyGAM1ERGRwRioiYiIDMZATUREZDAGaiIiIoMxUBMR+QH1sKO6uZf1DBeo9T127FhxsuPHj0uDBg20hCkagqCXN1p6RmXIkCFaWhU/g37ZcYX7qInI2SVXg/J8V6P9rejZbEMXqH79+smhQ4ei3Y7RFKgmjY5YiRPHXVhAY5FQNMC4f/++BumsWbPKxo0b9f+wZcuW2lp06NChUR7va6+9pr2/p02bFmfHyxE1EZEf8GZv31C7GaNo9/vmz5+vjSZQ67lQoULauMKGxhb4/oULF0rVqlW1ZeUzzzyjTSK2bt0qZcuW1UBfr1497UzlXuu7UaNG2p0LTTFQK7p9+/YePaPR8QoNOVBnGo+LRhmLFi1yfX3NmjX63OhwhX7Q6IK1YcMGOXz4sHayQptOPDeOZ9WqVa6fQ5csdLdCZy571gAwc1CqVCmP1wajboy+vY8bI1O0AC1YsKDef+LECXn99dd1lIoWnXh+79aagbRixQrZv3+/zJ49W48Zry+amKChSFR9t/F64/dGg5W4xEBNRBQkc+bM0RE2AtOBAwd0tIaOVjNnzvT4PrSoRLvKHTt26Ii2efPm2uJx3Lhxsn79em3JiMdxt3r1an1MBNx58+ZpW0gEEhuC9KxZs2Ty5Mmyb98+DTBvvvmmrF271uNxevbsKcOHD9fHKlGihLZ+rF+/vj7+zp07tesWumhhqhjwPGg9iQ5aGIm6zyhEBx4XMw4rV66UpUuXyt27d7VDF1pz4ndFK05cIOB5owqaqVOnjvKGC5fIbNq0SYMtLkZsOAY0ysBrZRpOfRMRBQkC8OjRo7V9I2B0i5EcWiu694RGO0gECujSpYs0a9ZMA1rlypX1PrR99C4biinj6dOn63pp0aJFNXBinRUjQwQ/XBRgJIxpWsiXL5+OmPHcaLdpw8/VqlXL9TlGtBh92/B4ixcvlu+++077XePriRIl0sCKGYOYSpUqlbb+tKe8MarF6B/32aNztAXF6BoXIbVr1/b5OHb/6MhE1ZEKPajdgzTYn+NrpmGgJiIKghs3bug0MoJsu3btXPcjYQlT5O4wkvUOGO7Tq7jv3LlzHj+DYIogbUNAxmgY08j49+bNmx4BGDBCRc9ld5hed4efxTQ2eldjtIzjvXXrlmtE7S/8Xu7r0rt379YZAwR+7xaReP0iU6BAAYkvGKiJiIIAAQ+mTJki5cuX9/gaRqTukMRks0eV3vdh1BnT50awzZEjh8fXsBbtPcJ1h9E9pqVHjRqlwRDr26+++mqU09CQMGFCTUhzh5G9N+/nw7FijRzLBN6w/h6ZRyXpYZof0/6+YCZgy5YtHvedPXvW9TXTMFATEQUBRsFImDpy5Ii88cYbAX98jEQx0kUghc2bN2vwypUrl05PIyBjFOw+zR0dWCNG0lfjxo1dgdQ7sQsjYmROewdVTBsjWNsXG4+anobSpUtrtjy2SEU1XR3IqW/MPiBvALMUeF7AxQl+pkiRImIaBmoioiBBclfnzp11qhvJUbdv35Zt27bJ5cuXpWvXrn49Nka4mFZHEhoCKdbDsYaMkS2mkTEyRgIZRuJVqlSRq1evahBGMHJfH/f25JNPasIYEsgQcJH85j2aRyb3unXrpGnTpnpBkDFjRs0GR2b6iBEjdAS+bNkyzSh/VPDFRczIkSM10xvr5UhUQ1Y5jgEJdTlz5gz41DfWvRGQW7RooceLCwy8jh07dnTNOGDEjS1byBWwZyVw4XPp0iX9Fxcq9sUCjiWY2/BCnvWNdHj8p2PrAqaHvKcjvCHdHyn9uIrElSNORKxlEBGZpm3btpokheQorM1idIukMCSV+atGjRoaVKtVqyZNmjSRhg0behRXQRIYgiyyv7E9DBcKmAp/1HOPGTNGMmTIoIU9EKyR5IZRrzsEVFwc5M+f3zU9jefA1jO8p2P9HO/luFh4FKyzI+jnzp1bk+7wOLgAwft6TEbYMYGlB2Sc41+MrjFNjqCM38uGNX5kp7tP3yPzHmv8uCjCTAM+xg0XX8GUwPJeVIhDmO7Ai4N1BARpBOGvv/5aXxx7OsLd3Llz5e2339ZMR5xE2GuIKRpc1eHkig6k3+PqFleXwToJiPwq4BGDYhvhBm/OR48e1WCCi3fyDe97V65ckSVLlvAlcuj5HJNYFNIRNYIrsiFbt26t0xAI2Li6QiD2BRVksF0BewwxCsf0BbYxPGoUTkRE5FQhC9RYX9m+fbvUrFnz/w4mYUL9HJvRfcEoGj9jB2Ykafz444+6OZ+IiCgchSyZ7MKFC7oY72vT+cGDB33+DEbS+DkkRmDGHvv7UH2md+/ekT4Pkjdwc59uICJyMu/iJxTeQp5MFhOoUoNqO0hYQKk9ZAUiOQJJE5FBIgXWAewbEtCIiIicImQjaqTzI+PO3mRuw+eRbThHBiPS6ZFJCciiRPWff/3rX/Lxxx/r1Lm3Xr16eWyDwIiawZqIiJwiZCNqbJhHNRrsUbNhrx4+t2vTekO6vHcwtiv8RJa8jj1xyKhzvxERETlFSAueYKSLjfeoNVuuXDndnoURMrLAAVu3sNEc09eAPX3IFMe+NWznQn1YjLJxv3dJPiIionAQ0kCNTfqoZINN5KgMg76gqGZjJ5ih+ov7CBqVY1ApB/+ePHlSN9ojSKMUHBERUTgKacGTUGDBEzICC574xIInFE7+CYeCJ0RERBQ1BmoiIj9gOS6qm3v97XCBypDIKXKyBD7+r+bPny8mYvcsIjJe8ZnF4/T59rbaG+3vPX36tEf/AuTcoF+BLZhdlQIJq6AoQpU4ceI4rVCJHUChMmPGDG1WYkufPr2YiCNqIiI/oO6DfcOaI0Zm7vdhlIaOUFijLFSokBZssqEDFb5/4cKFUrVqVe0K+Mwzz2jDoa1bt+qOGAT6evXqaeKte1OORo0aaRtNJNVijRNVGhH43Le7YscM1kfxuOhotWjRIo8CUnhutKLEVllsZd2wYYMcPnxYW04iqRfPjeNZtWqV6+fQzhJtKNG50B6JAmYOkBDsDqNujL69jxsJwOjVjU6IcOLECXn99dc1UKKXNp7fuwd2MOD53P+vTG0Ew0BNRBQkc+bM0RE2AtOBAwe0siK2lM6cOdPj+9A2EbtZUHERI1qUS0Yv5nHjxsn69et1Kyoexx1qTuAxEXDnzZunlRoRuG0I0rNmzdJmR/v27dPAinaOa9eu9Xicnj17yvDhw/WxSpQooe0b0T8Bj79z504dcWJ3DXbhAJ4HPaLREhKzCe4zCtGBx8WMw8qVK7XVJNpIopUmemjjd0XPbFwg4HndLzy84XuiuuHC5VHQfxrFt7A9GM2gTM2t5tQ3EVGQIACPHj1a+ywDRrf79++Xzz//XGtI2NC3GcEKunTpol0BEdDQLRDQn9m7vjemjBFc0HGwaNGiGji7d++uJZUR/HBRgJGwXUAqX758OmLGc6Mvtg0/V6tWLdfnGNFi9G3D4y1evFi+++476dSpk34ddSsQWCOrIhmVVKlSaY9ue8p79uzZOvrHffboHFPSGO3iIqR27do+H2fXrl1RPs+jMqnxez///PP6+q1YsUI6dOigFymdO3cW0zBQExEFAYo3YRoZQRbtfG1oJoQpcncYydrsOhIokex+37lz5zx+BsEUQcaGgIxAg2lk/ItKju4BGDBCRcEod5hed4efxTQ2+ihgtIzjvXXrlmtE7S/8Xu7r0rt379YZAwR+761NeP0iU6BAAfEHZjZseE3w/zVy5EgGaiKi+AIBD6ZMmaKVFN15V1JMkiSJ62N7VOl9H0adMX1uBFtUd3SHtWjvEa47jO4xLT1q1CgNhljffvXVV6OchgYUp/KeOsbI3pv38+FYsUaOZQJvWH+PzKOS9DDNj2n/6ML/EWYP0G3R+zUKNY6oiYiCAKNgJEwdOXJE3njjjYA/PkaiGOkikMLmzZs1eKHpEKanEWwwCnaf5o4OrBEj6atx48auQOqd2IURMTLEvYMqKkwiWNsXG4+anobSpUtrtnzmzJlj1Ithl59T374eL0OGDMYFaWCgJiIKEiR3Yc0TU91IjsJobdu2bXL58mWPrn6xgREuptWRhIZAivVwrCFjZItpZIyMkUCGkXiVKlW0AhaCMAKY+/q4tyeffFITxpBAhoCLKWLv0TwyudetWydNmzbVwIaELGSDIzN9xIgROgJHOWhklD8qYOIiBlPOyPTGujES1ZBVjmNAQl3OnDkDPvX9/fffa6fGChUqaKY3ZhCwpo/XzETM+iYiChK05EWSFJKjsDaL0S2SwpBU5q8aNWpoUK1WrZr2TWjYsKFHcRVM4yLIIvsb28NwoYCp8Ec9NxofYWRZqVIlDdZIcsOo1x0CKi4O8ufP75qexnNg61lERISun2/ZsiVagQ/r7Aj6uXPn1qQ7PA4uQLBGHaxuh0mSJNHjxLo+tpQhwQ6/Ny52TMRa30ShwFrfPrHWd/RgavrKlSuyZMmSQJ6VFGCs9U1ERBQPcOqbiIjIYEwmIyJyGO/iJxTeYjWi/vnnnwN/JERERBSYQI3sQWT7DR48WKvgEBERkUGB+uTJk7pfD51YUD8W6fvo/vKoyjVERNFhanMEolCcx7EK1Njcjo30qOTy66+/ylNPPaUFzVGFB5v7UTGHiCim7NKavOincHDz5s2HysGGJJkMG+HRQeXxxx/XVmno5oJN79hIjjqr6OpCRBStN6TEibUABipc4c0NVbaInDiSRpBGIxV0AfOu7R5ngRrF1r/99lsNzCi/hg4sEyZM0PZs+CNDWbvXXntNW7oREUUHSlZmy5ZNjh49qmUkiZwMQTo2rUADEqjfe+89bVSOq4YWLVpobddixYp5dEdB5xVMhRMRxQQaPqA0Jqe/ycmSJEni90jar0CNUfK///1vrcsaWacRrGNzGxcRxQamvNEsgYhimUyGwuWY1vYO0mgwjuLq9lpTTNurERERUQAC9XPPPSeXLl166H60UcPXiIiIKISB2r0xuLuLFy/q+jQRERFJ3K9RY00aEKTRZs196vv+/fuyZ88e7WFKREREIQjU6dKlc42o06RJIylSpPDI1KxQoYK0a9cuQIdGREREMQrUM2bM0H/z5Mkj3bp14zQ3ERGRqVnfgVqLjoiI0MCPrRjly5eXLVu2RPn9V65ckY4dO2pRBEy9o3zpjz/+GJBjISIicuyIGqVCV69eLRkyZJCnn37aZzKZbceOHdF6zAULFkjXrl211CiC9NixY7XBx6FDhyRz5swPfT8KINSqVUu/hoYgOXLk0OpFqP5CREQUrwP1Sy+95Eoea9SoUUCefMyYMbqm3bp1a/0cAfuHH37QsqQ9e/Z86PtxP7aFbdy40VXkHKNxIiKicJXAClE/OYyOUXwfI2P3wN+qVSud3kYdcW/169eXxx57TH8OX8+UKZM0b95cevToEWmpttu3b+vNdu3aNcmVK5fu+U6bNm2QfjuiRxiQLoqvXeXLRxTmrl27pgna0YlFIWtNc+HCBd3SlSVLFo/78fmZM2d8/syRI0c0sOPnsC7dt29fGT16tAwePDjS5xk2bJi+GPYNQZqIiCjspr6xNh3VurQ7X1XLAuHBgwe6Pv3FF1/oCLpMmTJy8uRJGTlypCa4+dKrVy9dB/ceURMREYVVoEaiVyChaQeC7dmzZz3ux+eRtQVDprd3R5LChQvrCBxT6djL7Q3r6pE1DiEiIgqbQI2140BCUMWIGJnk9ho1Rsz4vFOnTj5/pnLlyjJ37lz9Pruh/O+//64B3FeQJiIicrpor1Fjytj946hu0YUp6SlTpsjMmTPlwIED8u6778qNGzdcWeAtW7bUqWsbvo5p9S5dumiARob40KFDdV81ERGRxPc16tOnT+saMfYt+1qvtpt1INkrOpo0aSLnz5+Xfv366fR1qVKlZNmyZa4Es+PHj7tGzoC15eXLl8sHH3wgJUqU0H3UCNrI+iYiIorX27PWrl2rU8/oM42Po2JyH+qYpMQT+SNPzx8i/dqx5M0j/0FuzyIKe9diEIuiPaJ2D74mB2IiIqJ425TD3eXLl2XatGm6tgxFihTRtWUUJCEiIqLAiFXBk3Xr1mnpzvHjx2vAxg0f582bV79GREREIRxRI8saiWCTJk1y7WlGAlmHDh30a3v37g3Q4REREcVvsRpR//nnn/Lhhx96FB7Bx9huha8RERFRCAM1Wl7aa9PucF/JkiUDcVxEREQUk6nvPXv2uD7u3Lmz7l/G6LlChQp63+bNmyUiIkKGDx/OF5aIiCiu91Gj8AiKmTzq22NS8CQUuI+a4gr3URNRnO6jPnr0aHS/lYiIiAIk2oH6iSeeCNRzEhERUbALnsD+/fu1HjdaTLpr2LChPw9LRERE/gTqI0eOSOPGjXW/tPu6td2ow+Q1aiIiorDfnoWMb1QhO3funKRMmVL27dunFcnKli0ra9asCfxREhERxVOxGlFv2rRJ/vvf/0rGjBk1Gxy3KlWqyLBhw3Tr1s6dOwN/pERERPFQrEbUmNpOkyaNfoxgferUKVfC2aFDhwJ7hERERPFYrEbUxYoVk927d+v0d/ny5WXEiBGSNGlS+eKLLyRfvnyBP0oiIqJ4KlaBuk+fPnLjxg39+JNPPpEXXnhBqlatKo8//rgsWLAg0MdIREQUb8UqUNepU8f1cYECBeTgwYNy6dIlyZAhgyvzm4iIiEK8jxpOnDih/+bKlSsAh0NERER+J5Pdu3dP+vbtq3VK8+TJozd8jCnxu3fvxuYhiYiIKFAj6vfee0+++eYbTSKrWLGia8vWgAED5OLFizJp0qTYPCwREREFIlDPnTtX5s+fL/Xq1XPdV6JECZ3+btasGQM1ERFRKKe+kyVLptPd3rBdC9u0iIiIKISBulOnTjJo0CC5ffu26z58PGTIEP0aERERxfHU98svv+zx+apVqyRnzpxSsmRJ/RwFUNBFq0aNGgE6NCIiIop2oEZWt7tXXnnF43NuzyIiIgphoJ4xY0YQnp6IiIiCVvDk/PnzriYcBQsWlEyZMvnzcERERBSIZDLU+X777bclW7ZsUq1aNb1lz55d2rRpIzdv3ozNQxIREVGgAnXXrl1l7dq18v3338uVK1f09u233+p9H374YYwfLyIiQrd7JU+eXLtxbdmyJVo/h73cqC3eqFGjWPwWREREYRqo//Of/8i0adO04EnatGn1Vr9+fZkyZYosWrQoRo+FblsI/P3795cdO3ZoFjmafpw7dy7Knzt27Jh069ZNu3YRERGFq1gFakxvZ8mS5aH7M2fOHOOp7zFjxki7du2kdevWUqRIEZk8ebKkTJlSpk+fHunP3L9/X9544w0ZOHAg+18TEVFYi1WgRn1vjID/+ecf1323bt3SwGnX/o4O7Lvevn271KxZ8/8OKGFC/Ry1wyODHti4KMCa+KOgEMu1a9c8bkRERGGd9T127FipW7fuQwVPsMa8fPnyaD/OhQsXdHTsPTrH5+hx7cuGDRt02n3Xrl3Reo5hw4bpBQQREVG8CdTFixeXP/74Q+bMmeMKqGjGgenoFClSSLBcv35dWrRooWvhGTNmjNbP9OrVS9fAbRhRszgLERGFbaBGv+lChQrJ0qVLdW3ZHwi2iRIlkrNnz3rcj8+zZs360PcfPnxYk8hefPFF130PHjzQfxMnTqx7uvPnz/9QAxHciIiI4sUadZIkSTzWpv2BTltlypSR1atXewRefO5rrRsXCHv37tVpb/vWsGFDee655/RjjpSJiCjcxGrqu2PHjvLpp5/K1KlTdSTrD0xLt2rVSsqWLSvlypXT9W8UVEEWOLRs2VJy5Miha81YAy9WrJjHz6dPn17/9b6fiIgoHMQqym7dulVHvStWrND16lSpUnl8/Ztvvon2YzVp0kRLkfbr10/OnDkjpUqVkmXLlrkSzI4fP66Z4ERERPFRrAI1RrHe3bP8gR7WkfWxXrNmTZQ/++WXXwbsOIiIiBwdqLF+PHLkSPn99991D/Tzzz8vAwYMCGqmNxERUXwWoznlIUOGSO/evSV16tS6bjx+/HhdryYiIiIDRtSzZs2SiRMnyjvvvKOfr1q1Sho0aKBJZVxHJiIKb3l6/uDz/mPDG8T5scQnMRpRI7ELzTdsKPWJ7lWnTp0KxrERERHFezEK1Pfu3dMtUt77qlEEhYiIiEI89W1Zlrz11lselb5Q/KR9+/YeW7Risj2LiIiIAhSoUZjE25tvvhmThyAiIqJgBeoZM2bE5NuJiIjITyz5RUREZDAGaiIiIoMxUBMRERmMgZqIiMhgDNREREQGY6AmIiIyGAM1ERGRwRioiYiIDMZATUREZDAGaiIiIoMxUBMRERmMgZqIiMhgDNREREQGY6AmIiIyGAM1ERGRwRioiYiIDMZATUREZLDEoT4AIvJUfGbxSF+Sva328uUiimc4oiYiIjIYAzUREZHBjAjUERERkidPHkmePLmUL19etmzZEun3TpkyRapWrSoZMmTQW82aNaP8fiIiIicL+Rr1ggULpGvXrjJ58mQN0mPHjpU6derIoUOHJHPmzA99/5o1a6RZs2ZSqVIlDeyffvqp1K5dW/bt2yc5cuQIye9ARES+MeciDEbUY8aMkXbt2knr1q2lSJEiGrBTpkwp06dP9/n9c+bMkQ4dOkipUqWkUKFCMnXqVHnw4IGsXr06zo+diIgorAP1nTt3ZPv27Tp97TqghAn1802bNkXrMW7evCl3796Vxx57LIhHSkREFA+nvi9cuCD379+XLFmyeNyPzw8ePBitx+jRo4dkz57dI9i7u337tt5s165d8/OoiYiI4tHUtz+GDx8u8+fPl8WLF+t6tS/Dhg2TdOnSuW65cuWK8+MkIiJyZKDOmDGjJEqUSM6ePetxPz7PmjVrlD87atQoDdQrVqyQEiVKRPp9vXr1kqtXr7puJ06cCNjxExERhXWgTpo0qZQpU8YjEcxODKtYsWKkPzdixAgZNGiQLFu2TMqWLRvlcyRLlkzSpk3rcSMiInKKkG/PwtasVq1aacAtV66cbs+6ceOGZoFDy5YtddsVprAB27H69esnc+fO1b3XZ86c0ftTp06tNyIionAS8kDdpEkTOX/+vAZfBF1su8JI2U4wO378uGaC2yZNmqTZ4q+++qrH4/Tv318GDBgQ58dPREQU1oEaOnXqpDdfUODE3bFjx+LoqIiIiELP0VnfRERE4Y6BmoiIyGAM1ERERAYzYo06PmKheiIiig6OqImIiAzGQE1ERGQwBmoiIiKDMVATEREZjIGaiIjIYAzUREREBmOgJiIiMhgDNRERkcEYqImIiAzGQE1ERGQwBmoiIiKDMVATEREZjE05iMhvbDJD4aT4zOKRfm1vq70S1ziiJiIiMhgDNRERkcE49U2OnQ4iIooPOKImIiIyGAM1ERGRwTj17ac8PX+I9GvHhjfw9+GJiCie44iaiIjIYAzUREREBuPUN4U1ZqpTOJ0bTjxm8h9H1ERERAZjoCYiIjIYAzUREZHBjAjUERERkidPHkmePLmUL19etmzZEuX3f/3111KoUCH9/uLFi8uPP/4YZ8dKREQUrwL1ggULpGvXrtK/f3/ZsWOHlCxZUurUqSPnzp3z+f0bN26UZs2aSZs2bWTnzp3SqFEjvf32229xfuxERERhH6jHjBkj7dq1k9atW0uRIkVk8uTJkjJlSpk+fbrP7x83bpzUrVtXunfvLoULF5ZBgwZJ6dKlZcKECXF+7ERERGG9PevOnTuyfft26dWrl+u+hAkTSs2aNWXTpk0+fwb3YwTuDiPwJUuWBP14iYjIhwHpIn9Z8ubmS+bkQH3hwgW5f/++ZMmSxeN+fH7w4EGfP3PmzBmf34/7fbl9+7bebFevXtV/r127FoDfQOTB7ZuRfi2q57h/636sfi4QivVfHunXfhtYx8hjjq1QHnOU50YCy9jXObLzg+dG6IX63IjsnOb5HHP2/5dlRf5e4GKF0MmTJ3GE1saNGz3u7969u1WuXDmfP5MkSRJr7ty5HvdFRERYmTNn9vn9/fv31+fgja8BzwGeAzwHeA6IYa/BiRMnHhkrQzqizpgxoyRKlEjOnj3rcT8+z5o1q8+fwf0x+X5Mq7tPlT948EAuXbokjz/+uCRIkEACCVdIuXLlkhMnTkjatGnFCXjMfJ15bvBvkO8bcQ8j6evXr0v27Nkf+b0hDdRJkyaVMmXKyOrVqzVz2w6k+LxTp04+f6ZixYr69ffff99138qVK/V+X5IlS6Y3d+nTp5dgQpB2SqC28Zj5OvPc4N8g3zfiVrp0Uaztm1TrG6PdVq1aSdmyZaVcuXIyduxYuXHjhmaBQ8uWLSVHjhwybNgw/bxLly5SvXp1GT16tDRo0EDmz58v27Ztky+++CLEvwkREVHghTxQN2nSRM6fPy/9+vXThLBSpUrJsmXLXAljx48f10xwW6VKlWTu3LnSp08f6d27tzz55JOa8V2sWLEQ/hZERERhGqgB09yRTXWvWbPmoftee+01vZkGU+wo3OI91W4yHjNfZ54b/Bvk+4bZEiCjLNQHQURERIZWJiMiIqLIMVATEREZjIGaiIjIYAzUREREBmOgjqV79+7JrFmzHqqSRkREFEjM+vYD2nEeOHBAnnjiCXEKFJdBL+9q1aqJk+TLl0+2bt2qpV/dXblyRducHjlyRELtu+++i/b3NmzYMKjHEp+h0c/evXv17zJDhgyhPhzHikmTD1MrMa5bty7KrzvlfdCIfdROhUpqu3btclSgRvcwtBHFMaP6GwI3Kr+Z7tixY/oG7A2d0U6ePCkmsMvg2lBL3n33o3tteV+/iwlmzpypNfhR9Q8++ugjrfqHXvHz5s0z8lxHOeHixYvrBSheV1Qu3Lhxo15IL126VJ599tlQH6IjodRydPshmHo+P+vj/94Jf4feGKj90KFDBy2BiiYcqFmeKlUqj6+XKFFCTIMqbqgE99VXX+mbMgq0IHDjTe6ll16SJEmSiEncR6nLly/3qI2LPzLUfc+TJ4+YAHXqbatWrZIePXrI0KFDXXXo0UsdFfVwn6lwbJMmTXIdb0REhHz22Wca8D744AP55ptvxDSLFi2SN998Uz/+/vvv5ejRo9omF+f4xx9/LL/88ouYCMe9cOFCrb54584dj6/t2LFDQu3nn3/2uFDu2bOnvPXWWx7nM95D7PLOJrp8+bLH53fv3pWdO3dK3759ZciQIeIYMWlLSZ4SJEjw0C1hwoSuf51g+/btVqdOnazkyZNbGTNmtN5//33r999/t0x+je1b0qRJraeeesr6/vvvLdMULVrUWr9+/UP3r1u3zipUqJBlqhQpUlh//fWXfvzRRx9ZLVq00I9/++03PT9MlCxZMlerwHbt2lldunTRj48cOWKlSZPGMtG4ceOs1KlT698ezuN33nnHqlmzppUuXTqrd+/elmmef/75h9oLw5w5c6zq1atbTrNmzRqrdOnSllMwmcwPuHL3vmGt1P7XdKdPn9bOY7ih3Wj9+vV1bQ/TnBhFmTJKxQ1TrpgJsD/HDdPehw4dkhdeeEFMc/jwYZ9d2jAjgNGJqVKnTi0XL17Uj1esWCG1atXSj5MnTy63bt0SE6EvwP79+3WGBX0C7GO+efOmntcmmjhxoi4p/Pvf/9YuglhiwN9h586ddXnKNBg9o3GSN9y3ZcsWcZosWbLoe4djhPpKgeLWnTt3rEWLFlkNGjSwkiRJYpUpU8aaNGmSdfXqVdf3fPPNN1b69OmNOmZc0Zs00n+UqlWrWrVq1bLOnDnjug8f165d26pWrZplqubNm+tIo02bNlbKlCmtCxcu6P3ffvutzhKYqH///joSxUxF7ty5rX/++UfvnzZtmlWhQgXL1JmLY8eO6ceZMmWydu3apR/jHH/ssccs02Dmqnv37g/dj/vwNVPt3r3b44bX+aefftJZgMqVK1tOwTVqP2EdbPLkyTqKxlUnRn5o1Zk3b15d8zVNtmzZdDTarFkzvRJGtzJvzz33XNB7dscE1s337NkjTjJt2jR5+eWXJXfu3JIrVy69D7kMdrc3U2FNGuvoONb//Oc/riz77du36zljogEDBmj3PBwzmvXYTXEwmsa6qomyZs0qly5d0vcLnCObN2+WkiVL6vuIie0XMMP2yiuvyE8//STly5fX+/D+8ccff+h5YqpSpUo9lNQJFSpUkOnTp4tTcHuWH5B0g/acyDpFYsJvv/2m24i+/PJLTbJwT8Yw6cICb2aYynQSJDLhDXj48OHiFHhzwHQmEpugcOHCmrgX3Uxairl//vnHEed227Zt9QIOyZy4OOrevbtUrlxZtm3bphd4uNAzzf/+9z99z8OWVPt8bt++vetC1ER//fWXx+domZwpUyZHnCPuGKj9gLVcZMliW06aNGlk9+7dGqgRsLEt4MKFC2ISZDymSJFCt5Q5rX/3e++9pwVmMCL1lWE/ZswYMYWTX2dYv369fP7555pn8fXXX+v2PVzgYZaoSpUqYhqsTePvEDNbKED0+++/698hMnuxIwA7Gkxj51kkTvz/JzXnz5+vW8pwfr/zzju6bm3S+Vy3bl19fXF8FPeYTOYHTFM9/fTTD92Pkd+NGzfENJhCxjSbU/YOusPFDwqb4IIIb8TYYmHfEBBN4uTXGdOYderU0QsNbBFCwh4gwcnUbWWYzcIs1ogRIzwCHC6Spk6dKibCyM4O0tC0aVMZP368XpCaFKSduvTkbu3atfLiiy9KgQIF9IZiQ7gYdZRQL5I7WeHCha0lS5box9hqcfjwYf14/Pjx1tNPP22ZaOrUqVb9+vWtixcvhvpQwppTX+dSpUpZM2fOfOic3rFjh5UlSxbLRPnz57dWrVr10DEfOHDAqKRId3nz5rXeeustV+Kb7fz58/o102DbZo8ePSyn+eqrr6zEiRNbr7/+um6Jww0fI5EWW8ucgslkfkCxk44dO+q6GNYjkVyB6k0oAGDqlfyECRPkzz//lOzZs2sii/cUsgmFFqKzVgY5c+YUUzn1dcaWFV9lFbGtDOVaTYTKdBgpecPUMqZtTYQtehhRV61aVYv6ILkMMAvjva5qSm8DJF+hkI/pS0/esy2YaUGOiw1b4HC8gwYNkubNm4sTMFD7mRCCKUJkyWLPJv7T8cY8btw4ncoykXeZS6fAm+7gwYNl9OjR8vfff+t9mAb/8MMPtfoUphJN4tTXGQEDFxje1d42bNig676m5opgKtO7vCkqf/lamjIBEgqx57tbt24a+LAT4JlnnhHTl54AS0/uTE6OPHLkiE57e8P0d+/evcUxQj2kDxc3btywzp49G+rDCFs9e/bU/aYTJ0507YmMiIjQ+0ys5ORUQ4cOtYoUKWJt3rxZq3qhutrs2bP1dcaSjomw/IR91MOHD9e93yNHjrTatm2rFb9WrFhhmQiV9ez3C5zb2FeNaVrstXdKVUMnyJ8/vzV58uSH7kftiAIFClhOwUDth5s3b2qAtqGAwWeffWYtX77cMtnly5etKVOm6BuEvYaKUqL/+9//LFNly5ZNi274epPOnj17SI4pHD148MAaPHiwlSpVKlepVpSX7dOnj2UylGZFCU5cUCDooZiFyX+HCMbuF/YI0nidW7duzUAdQBMnTtQLtvbt21uzZs3SG8q1ouysrwBuKm7P8kPt2rV1zyP2EmL9rmDBgpqxiW1ZWAN59913xTTI3sReXruUJdYkMaWJ6Xs0B8AWKBNh3yOO/amnnvK4H8ePogamlbfEWiOKRETWdAHFLkyG48UUOJYZMLWM0qIUOFiqOXPmjGTOnNl1HwomNW7cWEvlmrhjAHu8IzufTWzWYlu8eLEumbnv/8a+dRMLUkUq1FcKTvb4449rswLACLVEiRLW/fv3rYULFxrbeKFGjRquUoDuGbK//PKL9cQTT1imKleunPXee+89dD+aGpQvX94yTd++fXUWYNSoUTpSGjRokJblxDmDzFMKHLyuP//8c1i8pJj6RsMI08ybN08zpV944QUdoeJflA7FkgOy103VsmVLa+3atZbTMVAHqNPQa6+9Zg0YMEA/Pn78uH7NRGnTprX+/PPPhwI1pu0xHWQqvHlhOhZb4t5++2294WP8Dpj2NE2+fPmspUuX6sc4Rvs1R5Bu1qyZZaq///5bp7krVqyo63vYKuR+M1HDhg313M2ZM6fVrVs3a+fOnZbpBg4caK1evdrn64+vmaZ48eLWhAkTPN43sEyCbmX9+vWzTPXSSy/pBQbWo4cMGWKdPHnSciIGaj9PXrzxIjAjAG7cuFHv37Ztm7F7TrGGhz2x3oEaSTd4ozMZ/siQOPbyyy/r7eOPPzb2Dw9JTfZFXNasWTUHAPB641wxVdOmTXUmAC0ukW8xduxYj5upLl26ZH3++efabAHrv0iIwxvz0aNHLRPZbVpHjx7tcb+pyWQ4n+3XEk1D9uzZox/v379fz2+TnTt3Tl9nzHhiT3XdunV11hPNfpyCgdoPX3/9tV6t4Q8LiSzumbM4GUydJmzUqJGepAjU6NmLgIICLXYfX1M0btzY1dULRTi8i0OYDNOCyJwGJDYNGzZMP54/f75eLJkKU5kbNmywnAy9qUeMGKHLT4kSJbJMDdQ4F7AUgqnj27dvGx2oc+TI4QrOGKDYvakxODH5wtMbLpixXIblKPRXRyEXJ3TlY6D20+nTp3WEirVp26+//qpVkUx05coVvahAxSa8ieXKlUsvNtB6EdNuJsFxnTp1ymeWrOlQxQkjOsAbMq7kMf2GUZTJFZ7y5MmjoySnwgXo4sWLrVdeeUXfjE3dEWBvz8KSCJZwsNSAz00N1FiusUf/n3zyiV5sYgsc8lpwQe0Ep06d0i18BQsW1GU0rF8jZwd/m2PGjLFMxqzveFQty7uABbKokdWLQgbIBDdNiRIl9NjQdrN169ZaCzlt2rQ+v7dly5ZiMrQxtJsu+CrAYIrZs2fLt99+q93fUqZMKU6BTnVz587VWuUojoPdGG+88YY8//zzRhbkQAvO06dPa9b3tWvX5PXXX5d9+/Zp4wsU4zAt6xu7FFCBEQWd8Pqi2pd9PmPHSIYMGcREd+/e1cpvM2bMkBUrVuh7CgpVoTiV/V6CrPC3335bLl++LKZioI5H1bIAPXtNbkvn7pdfftHX8vDhw/pGgdfW15su7jN9u5PJUL3L/XXFtizMtqE6GRoymF76FN298P+PDk8IzrgQsntSO2V7Ft5L0C4XbSTxsWmB2qkyZsyoryd6qbdr1063cnrD1lr8DaDJkqlYQtQPCMboG4seyegla49U0cgeV5+oM2savPmiVeGbb74pr776qrFXwoDXFCNR+40NpQvd952aDN2z0Oq0evXq+m/+/PnFVE4td2rD3xt6rKdPn16cAiM81DKw4fzGjBECxrp168Q0mLHCzBbqwJt8LntDLQOcG1H1n8Z5Y3KQBo6o/YBpIHuqyh2mDjt06KDNAkyDtpCYIkT/WxRWwCgEQdvEUQimL9G+EFNUmIrF9CBqqzsBppDxhrtmzRodoWLUh6BtB2729Q0Opy1BOQWmi3E+u5/L9oUoz+XgY6COR9Wy3GFqE0HEe10PHXJMgSpv6CSULVs2jzU9p8Fxoyfu0qVLZcGCBUZPbW7dulWPr3z58h73//rrr/p/ULZsWTGNU5agMGL+17/+pe8b+DgyWIZAX2oTYfCBgI3zGTfMcuHv075AouBgoPYD3sxw8/6jwx8Z3vDsaVvTYd2xTZs2etFhUgBxejIZOqphKQQXREh2wmwGyhdiJIIpOROVK1dOPvroI10W8S4R+emnn2rANk2vXr10CWrgwIEPLUFhXdKUJai8efNqGc7HH39cP44qUKPrk4nscxrnM85rvHegxCzObQoeBmo/4IqyQYMGuh5ZsWJFV71eJGz9+OOP2mvWVLgCxmgaN7Sww/EjEQd1y02BrFL0/HZiMlmlSpU8AjOmCLG+Z3JOAKCmNy7YvFtaYg0PF07Xr18X0zhxCcp7dgtMzE63oSUkArN9TttT3044p8MBA7WfTp06JREREXLw4EH9HCcx3hzw5mGizz//XIMzropxrAjO2Krg3cvXCU0MTPbYY4/pMaNxC97QcPNeIjERRnuYorcvPN0vmnBRauIWFqcuQWEWADMrf/zxh36OtV5kfmM92DQ4lzNlyiQffPCBLpE54VwOJwzU8Qy2ZmGrAgJ0yZIlxSmwVo2uPbjQwLTg119/rUktX331lU4jIpPdtFHS3r17dRSCmRes62HNHSMRTOVjStZEODewpo7RqJ2VjO0ryAzHRRK6J5nGiUtQ/fr10w57OEb32bgJEyZoMPzkk0/EJLt379bzGOfz+vXrXeeyky5CnYyBOoZw5R5dmCo0DQIIRtNOCXg2JLy1aNFCLzBwrPv379fpWbyxYZkBN1PhNd++fbse65w5c4xOJsM0MaYzL168qFuFYNeuXZIlSxZZuXKlkXvwI1uCwoXdTz/9ZOQSFEanuLDAhZG7efPmafBGq1yTIXBjNsD08zlccB91DGEqDWtJ9rpSZPA9Jp68SAqyAx4SQW7fvq33X716VYYOHWpswENWL9YhkTSGrWU2JA/ha6bBa4vRB264MMLabvHixfVNGCMRU+GiDRejeAPGmzG2wyGRDwHFu/iJKfB6YpobxULsnsOYnjV5CQoVs3xl0JcpU0bu3bsnpsH7Hdan3c9pVFTDYMTk8zlccEQdiynY6DJx3RejJEytIeAhOQtvxhiZ4o+wXr16ug5sIpSzxCgaBVvcjxuzAsg6RYEZkyROnFhfa3vvNEap7gUuKLDw/48LjHPnzukIz513kpkJcMGGCx9Mf7vr1q2brqkj78UkSBjD1jcsl9lT3pipcFKRGSfjiDqG3IPvsGHDdEoQdWLdYS8yion06NFDTIORB4KGNwQRrEWaKmvWrFpsAYHaHa7svTOUQw0zKZi5wBuZEzNikdyE7Te+gh7WVk2zbNkyvfDEdL33TJepM1t2MhnqT1eoUEE/x9Y3TNfjd8FuB5t3MA9VAR+cz5Ftj6TgYqAOQAa1t6JFi0rTpk2NDNROCnjukHzVpUsXvQjCmy+y7bEOiRFI3759xSQoDIIqapiGdVqgnjJlirz77rtaIxnnivuWIXxsYqDG6BRlInFsuHB2AmyJRI0AwPZDwGuOG75mM2XLFnIAbKz+FgKhbt/lZMmSJdN+zt4OHz6sXzMRemUXKVJEeyWnSZPGWr9+vTV79mxtWzd+/HjLVA8ePLAGDx6s7enQIhA3tDHs06ePZaIyZcpYq1atspwmd+7c2grQSXAeo10kBQ/a+A4cOFB7T6MNJ27oXY6Wl+4tfik4GKj9gP7CX3311UP3z5o1y8qbN69lIqcFPG+3b9+29u3bpz2/r1+/bpnqp59+skqVKmV9//332gf36tWrHjeTgx4uNJ2kdevW1tSpU0N9GGGtZ8+eejE/ceJEa/fu3XqLiIjQ+3r37h3qwwt7TCbzA3qy4jZy5EjtewurV6/WEoyoM4zShqa6c+eOToEjQQTJWKhIRYHjXl/affoSF8cmr5uilOwzzzxjVIW66JS1xNQ3tjwhs947O71z584hO7Zw4fTqb07HNWo/dO/eXRNYcKIi8NlVkrA2bXKQBhQsQICm4EAylhMVKFBA1/xRJMQpQQ97j5GUhb89bB3yXlc38ZidBiV6CxUq9ND9uM+08r3hiCPqAMCoFIlD2HOKMoCmtYskii4nNotA0huCcc+ePY3plBVunFj9LZwwUBMFCba7YQuOXYQDuwGwlY/7qQNfVx3BIn/+/AF+ZAqHBkThgIGaKAjQzrBOnTo6y4LWkYBggmIWmKa1t+aYAHt2Bw0aJKlSpfLYv+trRI2ez6ZBAR+sT6PDEwUH9nejiI+vBkSopIYATsHDQE0UBBhhYL0X+5LxBgd4Q0NnJEwfo0mHKdAkZPHixVplCh9HFaj/+9//imkw7T1r1iytmoWSlt7r6iYUDHE61AZAsxbv7nXI0cF9piZHhgsGaqIgwEgaZVm9E3BQBhU1npGpTIHhxIsLp4mszSxKKiMp9caNGyE7tviAWd9EQYBSi5gu9A7UWNNDrXIKHKdm2DuBvRRiV6VDzX0bRtEoe4pGRRRcDNREQdCkSRPdkzxq1CipVKmS3vfLL7/olj7v1oZEpsKskHt/dWzrtOFjLDegjC8FF6e+iQIE3ZuKFSum04TYV4+gjCIRdttCrJ2ijvbw4cO5hY8cBa1Ox40bx6YcIcJATRSEhBs0OEGWN9aq7aYL2D7kPnVIRBQdnPomChBkTR89elQD9bFjx7RFJAIzKnwREcUWAzVRgLzyyitSvXp1yZYtmybfILsbo2xfTKzwRURmYqAmCpAvvvhCXn75ZW12gr296KHNDG8i8hfXqImClHyDusgM1ETkLwZqIiIig7HVDBERkcEYqImIiAzGQE1ERGQwBmoiIiKDMVATEREZjIGaiIjIYAzUREREBmOgJiIiEnP9PziNpZrNoOdfAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프 그리기\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i], bar_width, label=f'Temperature = {T}')\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"outputs/temperature-plot.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d750e989-842a-4cfa-a44b-cf44d6e49163",
   "metadata": {
    "id": "d750e989-842a-4cfa-a44b-cf44d6e49163"
   },
   "source": [
    "- 온도 0.1로 스케일을 조정하면 더 뾰족한 분포를 만들어, `torch.argmax`에 가까워져 항상 가장 가능성있는 토큰이 선택됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e4600713-c51e-4f53-bf58-040a6eb362b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e4600713-c51e-4f53-bf58-040a6eb362b8",
    "outputId": "54400e8d-6190-4791-e2e6-69614305e872"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "985 x forward\n",
      "0 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "15 x toward\n",
      "0 x you\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(scaled_probas[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526e93cb-8e2a-42a1-b1ba-4fd5fe64c26b",
   "metadata": {
    "id": "526e93cb-8e2a-42a1-b1ba-4fd5fe64c26b"
   },
   "source": [
    "- 온도 5로 스케일을 조정한 확률은 더 균등한 분포가 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9dfb48f0-bc3f-46a5-9844-33b6c9b0f4df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9dfb48f0-bc3f-46a5-9844-33b6c9b0f4df",
    "outputId": "42128234-557f-4737-982d-7b0b9f0bc94b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165 x closer\n",
      "75 x every\n",
      "42 x effort\n",
      "239 x forward\n",
      "71 x inches\n",
      "46 x moves\n",
      "32 x pizza\n",
      "227 x toward\n",
      "103 x you\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(scaled_probas[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c83f0c4-3774-4375-ad7f-96440ba5fef7",
   "metadata": {
    "id": "0c83f0c4-3774-4375-ad7f-96440ba5fef7"
   },
   "source": [
    "- LLM 입력이 \"every effort moves you\"일 경우 위와 같은 방법을 사용하면 \"every effort moves you pizza\"와 같이 3.2%의 확률(1,000번 중에 32번)로 이따금 말이 안되는 텍스트를 생성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e4873e-07e4-4abb-85df-bdaedcc1a6f7",
   "metadata": {
    "id": "c6e4873e-07e4-4abb-85df-bdaedcc1a6f7"
   },
   "source": [
    "### 5.3.2 탑-k 샘플링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4da95a-8bb2-4f69-a9b0-a643531db5df",
   "metadata": {
    "id": "6d4da95a-8bb2-4f69-a9b0-a643531db5df"
   },
   "source": [
    "- 높은 온도를 사용하여 출력의 다양성을 증가시키면서 말이 안되는 문장이 생성될 가능성을 낮추기 위해 가장 가능성있는 상위 k개 토큰으로 샘플링될 토큰을 제한할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae6fffd-2730-4abe-a2d3-781fc4836f17",
   "metadata": {
    "id": "7ae6fffd-2730-4abe-a2d3-781fc4836f17"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch05_compressed/15.webp\" width=700px>\n",
    "\n",
    "- (이 그림의 숫자는 간단하게 나타내려고 소숫점 두자리 이후를 자른 값입니다. 소프트맥스 열의 값은 모두 더해서 1.0이 되어야 합니다)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba12da5-6ff1-4008-91b8-d2d537cbc14c",
   "metadata": {
    "id": "0ba12da5-6ff1-4008-91b8-d2d537cbc14c"
   },
   "source": [
    "- 코드로는 다음과 같이 구현할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2a7f908a-e9ec-446a-b407-fb6dbf05c806",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2a7f908a-e9ec-446a-b407-fb6dbf05c806",
    "outputId": "4802b0c1-4c2e-4986-aec1-10b32cb251ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "탑-k 로짓: tensor([6.7500, 6.2800, 4.5100])\n",
      "탑-k 위치: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "\n",
    "print(\"탑-k 로짓:\", top_logits)\n",
    "print(\"탑-k 위치:\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "753865ed-79c5-48b1-b9f2-ccb132ff1d2f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "753865ed-79c5-48b1-b9f2-ccb132ff1d2f",
    "outputId": "b657970e-19ef-43cb-c8cf-daf61cc10531"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],\n",
    "    input=torch.tensor(float(\"-inf\")),\n",
    "    other=next_token_logits\n",
    ")\n",
    "\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "46d95dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "#위의 코드를 좀 더 효율적으로 구현\n",
    "#자세한 내용은 다음을 참고하세요: https://github.com/rasbt/LLMs-from-scratch/discussions/326\n",
    "new_logits = torch.full_like( # -inf 값을 담은 텐서를 만듭니다.\n",
    "    next_token_logits, -torch.inf\n",
    ")   \n",
    "new_logits[top_pos] = next_token_logits[top_pos] # -inf 텐서에 상위 k개 값을 복사합니다.\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4844f000-c329-4e7e-aa89-16a2c4ebee43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4844f000-c329-4e7e-aa89-16a2c4ebee43",
    "outputId": "33060826-7853-48dd-87af-da5f06c0018f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56056503-a15d-4315-a3ff-46647a4c7c45",
   "metadata": {
    "id": "56056503-a15d-4315-a3ff-46647a4c7c45"
   },
   "source": [
    "### 5.3.3 텍스트 생성 함수 수정하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34770423-473d-46f6-a5fa-6b2979564d26",
   "metadata": {
    "id": "34770423-473d-46f6-a5fa-6b2979564d26"
   },
   "source": [
    "- 이전 두 개의 절에서 온도 스케일링과 탑-k 샘플링을 소개했습니다.\n",
    "- 두 개념을 사용해 앞서 LLM으로 텍스트를 생성할 때 사용한 `generate_sample` 함수를 수정해 새로운 `generate` 함수를 만들어 보죠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e318891-bcc0-4d71-b147-33ce55febfa3",
   "metadata": {
    "id": "8e318891-bcc0-4d71-b147-33ce55febfa3"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "    \"\"\"\n",
    "    텍스트를 생성하는 함수입니다.\n",
    "    \n",
    "    Args:\n",
    "        model: 학습된 LLM 모델\n",
    "        idx: 현재까지의 문맥(토큰 인덱스들의 텐서) (Batch, Time)\n",
    "        max_new_tokens: 최대로 생성할 토큰 수\n",
    "        context_size: 모델이 한 번에 처리할 수 있는 최대 문맥 길이\n",
    "        temperature: 생성 다양성 조절 (0.0 = 결정적/안전함, 높을수록 창의적/무작위)\n",
    "        top_k: 확률이 높은 상위 k개 토큰만 후보로 남김 (이상한 단어 생성 방지)\n",
    "        eos_id: '문장 끝'을 알리는 토큰 ID (이게 나오면 생성을 멈춤)\n",
    "    \"\"\"\n",
    "\n",
    "    # 지정된 횟수(max_new_tokens)만큼 반복하며 한 글자씩 생성합니다.\n",
    "    for _ in range(max_new_tokens):\n",
    "        \n",
    "        # 1. 문맥 자르기 (Context Cropping)\n",
    "        # 입력 길이가 모델의 허용 범위(context_size)를 넘지 않도록, 가장 최근 토큰들만 남깁니다.\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        \n",
    "        # 2. 모델 예측 (Forward Pass)\n",
    "        # 기울기 계산을 꺼서 메모리를 아끼고 속도를 높입니다.\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        \n",
    "        # 3. 마지막 토큰의 예측값 추출\n",
    "        # 우리는 '다음 단어'만 궁금하므로, 시퀀스의 가장 마지막 타임 스텝의 로짓(Logits)만 가져옵니다.\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # 4. Top-k 샘플링 (필터링 단계)\n",
    "        # 확률이 너무 낮은 엉뚱한 단어들이 선택되는 것을 원천 차단합니다.\n",
    "        if top_k is not None:\n",
    "            # 상위 k개의 값(top_logits)만 구합니다.\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            # 상위 k개 중 가장 작은 값을 기준으로 삼습니다.\n",
    "            min_val = top_logits[:, -1]\n",
    "            # 기준보다 작은 값(순위 밖의 단어들)은 -infinity로 바꿉니다.\n",
    "            # (나중에 softmax를 통과하면 확률이 0이 되어 절대 뽑히지 않게 됩니다.)\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        # 5. 온도 스케일링 (Temperature Scaling) 적용 여부 확인\n",
    "        # temperature > 0: 확률에 기반해 '뽑기'를 합니다. (다양한 문장)\n",
    "        # temperature == 0: 가장 확률 높은 것만 무조건 고릅니다. (일관된 문장)\n",
    "        if temperature > 0.0:\n",
    "            # [핵심] 로짓을 온도로 나눕니다.\n",
    "            # 온도가 높으면(>1) 분포가 평평해져서 다양한 단어가 나올 확률이 오릅니다.\n",
    "            # 온도가 낮으면(<1) 분포가 뾰족해져서 확실한 단어만 나올 확률이 오릅니다.\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # (수치 안정성 팁): 로짓 값이 너무 크면 지수함수(exp) 계산 시 오버플로우가 날 수 있습니다.\n",
    "            # 최댓값을 빼주면 결과 확률은 같으면서 값의 크기는 줄어들어 안전합니다.\n",
    "            logits = logits - logits.max(dim=-1, keepdim=True).values\n",
    "\n",
    "            # 로짓을 확률(0~1 사이 값)로 변환합니다.\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # 확률 분포에 따라 랜덤하게 하나를 뽑습니다. (Weighted Random Sampling)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # 6. 그리디 샘플링 (Greedy Sampling)\n",
    "        # 온도 설정이 없으면(0.0), 무조건 가장 높은 점수를 받은 토큰을 선택합니다.\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        # 7. 조기 종료 (Early Stopping)\n",
    "        # 만약 뽑힌 토큰이 '문장 종료(EoS)' 토큰이라면 더 이상 생성하지 않고 루프를 깹니다.\n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "\n",
    "        # 8. 결과 누적\n",
    "        # 방금 생성한 토큰(idx_next)을 기존 문장(idx) 뒤에 이어 붙입니다.\n",
    "        # 이 새로운 문장이 다음 루프의 입력이 됩니다.\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aa2a0d7d-0457-42d1-ab9d-bd67683e7ed8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aa2a0d7d-0457-42d1-ab9d-bd67683e7ed8",
    "outputId": "14bcc0b4-d977-4067-ee25-96e12adef458"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출력 텍스트:\n",
      " Every effort moves you stand,\" was down surprise, one of his glory, my lies by by\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(inference_device),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print(\"출력 텍스트:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2002ca-f4c1-48af-9e0a-88bfc163ba0b",
   "metadata": {
    "id": "4e2002ca-f4c1-48af-9e0a-88bfc163ba0b"
   },
   "source": [
    "## 5.4 파이토치로 모델 로드하고 저장하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc52676-f026-4566-a226-2a90269f9d53",
   "metadata": {
    "id": "0fc52676-f026-4566-a226-2a90269f9d53"
   },
   "source": [
    "- LLM 훈련에는 계산 비용이 많이 듭니다. 따라서 LLM 가중치를 저장하고 로드하는 것이 중요합니다.\n",
    "\n",
    "<img src=\"images/llm_from_scratch/ch05_compressed/16.webp\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e4c7f9-592f-43d6-a00e-598fa01dfb82",
   "metadata": {
    "id": "10e4c7f9-592f-43d6-a00e-598fa01dfb82"
   },
   "source": [
    "- 파이토치에서는 `torch.save` 함수를 `.state_dict()` 메서드 결과에 적용해 소위 `state_dict`인 모델 가중치를 저장하는 것이 권장됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d67d869-ac04-4382-bcfb-c96d1ca80d47",
   "metadata": {
    "id": "3d67d869-ac04-4382-bcfb-c96d1ca80d47"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"outputs/model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e889e0-07bf-43e5-8f92-5c5c7aeaad9e",
   "metadata": {
    "id": "90e889e0-07bf-43e5-8f92-5c5c7aeaad9e"
   },
   "source": [
    "- 그다음 모델 가중치를 새로운 `GPTModel` 클래스 인스턴스에 로드할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d57d914-60a3-47f1-b499-5352f4c457cb",
   "metadata": {
    "id": "9d57d914-60a3-47f1-b499-5352f4c457cb"
   },
   "outputs": [],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "model.load_state_dict(torch.load(\"outputs/model.pth\", map_location=device, weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa81aec-9c72-4f46-8ae2-4a4fde3edbc1",
   "metadata": {
    "id": "caa81aec-9c72-4f46-8ae2-4a4fde3edbc1"
   },
   "source": [
    "- 일반적인 SGD 대신 Adam이나 AdamW와 같이 적응형 옵티마이저로 LLM을 훈련하는 것이 일반적입니다.\n",
    "- 이런 적응형 옵티마이저는 모델 가중치마다 추가적인 파라미터를 저장합니다. 나중에 사전 훈련을 계속하려면 이 파라미터도 저장하는 것이 맞습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bbd175bb-edf4-450e-a6de-d3e8913c6532",
   "metadata": {
    "id": "bbd175bb-edf4-450e-a6de-d3e8913c6532"
   },
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    },\n",
    "    \"outputs/model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0c7295-c822-43bf-9286-c45abc542868",
   "metadata": {
    "id": "8a0c7295-c822-43bf-9286-c45abc542868"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 1. 체크포인트 파일 로드\n",
    "# 저장된 파일(.pth)을 읽어와서 파이썬 딕셔너리 형태로 만듭니다.\n",
    "# weights_only=True: 보안을 위해 피클(pickle) 데이터 중 가중치 데이터만 로드하도록 제한합니다. (안전한 로딩)\n",
    "checkpoint = torch.load(\"outputs/model_and_optimizer.pth\", weights_only=True)\n",
    "\n",
    "# 2. 모델 구조(Skeleton) 재생성\n",
    "# 가중치를 담으려면, 가중치가 들어갈 '그릇(모델 구조)'이 먼저 메모리에 있어야 합니다.\n",
    "# [중요] 저장할 때 사용했던 설정(GPT_CONFIG_124M)과 똑같이 만들어야 에러가 안 납니다.\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "# 3. 모델 가중치(Weight) 복원\n",
    "# 체크포인트 딕셔너리에서 'model_state_dict' 키에 저장된 가중치들을 꺼내\n",
    "# 방금 만든 빈 모델(model)에 덮어씌웁니다.\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "# 4. 옵티마이저 초기화\n",
    "# 옵티마이저도 새로 생성해야 합니다. 이때 모델의 파라미터(model.parameters())를 연결해줍니다.\n",
    "# 주의: 여기서 설정한 lr(학습률) 등은 초기 설정값이며, 바로 아래 줄에서 덮어씌워질 수 있습니다.\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.1)\n",
    "\n",
    "# 5. 옵티마이저 상태(State) 복원 (학습 재개 시 필수!)\n",
    "# 옵티마이저는 단순히 학습률만 가지고 있는 게 아니라,\n",
    "# 이전 학습 과정에서의 '관성(Momentum)'이나 '스텝 수' 같은 내부 정보를 가지고 있습니다.\n",
    "# 이 정보를 복원해야 학습이 끊기지 않고 자연스럽게 이어집니다.\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "\n",
    "# 6. 학습 모드 설정\n",
    "# 불러온 직후에는 모델이 어떤 상태인지 모르므로, 다시 학습을 시작할 준비(train mode)를 합니다.\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4194350e-0409-4a63-8ffd-d3a896509032",
   "metadata": {
    "id": "4194350e-0409-4a63-8ffd-d3a896509032"
   },
   "source": [
    "## 5.5 오픈AI에서 사전 훈련된 가중치 로드하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83eb6c38-7278-40e0-bd9f-8a2b1feac3ec",
   "metadata": {
    "id": "83eb6c38-7278-40e0-bd9f-8a2b1feac3ec"
   },
   "source": [
    "- 앞서 하나의 단편 소설로 구성된 작은 데이터셋을 사용해 소규모 GPT-2 모델을 훈련했습니다.\n",
    "- 구텐베르크 프로젝트에 있는 전체 책으로 더 오래 모델을 훈련하고 싶다면 [../03_bonus_pretraining_on_gutenberg](../03_bonus_pretraining_on_gutenberg)을 참고하세요.\n",
    "- 다행히 오픈AI는 GPT-2 모델의 가중치를 공개적으로 제공하기 때문에 대규모 말뭉치에서 모델을 재훈련하기 위해 수만에서 수십만 달러를 쓸 필요가 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127ddbdb-3878-4669-9a39-d231fbdfb834",
   "metadata": {
    "id": "127ddbdb-3878-4669-9a39-d231fbdfb834",
    "jp-MarkdownHeadingCollapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미 파일이 존재합니다: models/gpt2\\gpt2-small-124M.pth\n",
      "출력 텍스트:\n",
      " Every effort moves you as far as the hand can go until the end of your turn unless something interrupts your control flow. As you may observe I\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import torch\n",
    "\n",
    "def load_gpt2_model(file_name, config):\n",
    "    \"\"\"\n",
    "    GPT-2 사전 학습된 가중치(Pre-trained Weights)를 다운로드하고,\n",
    "    초기화된 모델에 해당 가중치를 입혀서 반환하는 함수입니다.\n",
    "    \"\"\"\n",
    "    # 1. 저장 경로 설정\n",
    "    base_dir = \"models/gpt2\"\n",
    "    os.makedirs(base_dir, exist_ok=True)  # 폴더가 없으면 새로 만듭니다.\n",
    "    model_path = os.path.join(base_dir, file_name)\n",
    "    \n",
    "    # 다운로드 받을 원본 URL (HuggingFace 저장소)\n",
    "    url = f\"https://huggingface.co/rasbt/gpt2-from-scratch-pytorch/resolve/main/{file_name}\"\n",
    "\n",
    "    # 2. 파일 다운로드 (이미 파일이 있다면 건너뜀)\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"'{file_name}' 다운로드 중...\")\n",
    "        # 대용량 파일이므로 stream=True로 설정하여 조금씩 메모리에 올립니다.\n",
    "        with requests.get(url, stream=True) as r:\n",
    "            r.raise_for_status() # 404 등 에러 발생 시 예외 처리\n",
    "            with open(model_path, 'wb') as f:\n",
    "                # 8KB씩 조각(chunk)내어 파일에 씁니다.\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "        print(f\"다운로드 완료: {model_path}\")\n",
    "    else:\n",
    "        print(f\"이미 파일이 존재합니다: {model_path}\")\n",
    "\n",
    "    # 3. 모델 구조 생성 및 가중치 로드\n",
    "    model = GPTModel(config) # 껍데기(Architecture) 생성\n",
    "    \n",
    "    # 저장된 가중치 파일을 불러옵니다.\n",
    "    # map_location: 저장된 모델이 GPU용이라도, 현재 내 컴퓨터 환경(device)에 맞춰 로드합니다.\n",
    "    # (주의: 이 함수 밖에서 정의된 'device' 변수를 참조하고 있으므로, 호출 전에 device가 정의되어야 안전합니다.)\n",
    "    checkpoint = torch.load(model_path, map_location=device) \n",
    "    \n",
    "    # 불러온 가중치를 모델에 덮어씌웁니다.\n",
    "    model.load_state_dict(checkpoint)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# --- 설정(Configuration) 정의 ---\n",
    "\n",
    "# 1. 모든 GPT-2 모델이 공유하는 기본 설정\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,    # 어휘 사전 크기 (단어 개수)\n",
    "    \"context_length\": 1024, # 한 번에 처리 가능한 최대 문맥 길이\n",
    "    \"drop_rate\": 0.0,       # 드롭아웃 비율 (추론 시에는 보통 0)\n",
    "    \"qkv_bias\": True        # Attention 레이어의 편향(Bias) 사용 여부\n",
    "}\n",
    "\n",
    "# 2. 모델 크기별 달라지는 설정 (레이어 수, 임베딩 차원 등)\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "# 3. 사용할 모델 선택 및 설정 병합\n",
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "# BASE_CONFIG에 선택한 모델의 특정 설정(emb_dim 등)을 덮어씌워 최종 설정을 완성합니다.\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "# --- 메인 실행부 (사용 예시) ---\n",
    "\n",
    "# 1. 장치(Device) 자동 감지 로직\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\") # NVIDIA GPU\n",
    "else:\n",
    "    device = torch.device(\"cpu\") # 그 외에는 CPU\n",
    "\n",
    "print(f\"사용 장치: {device}\")\n",
    "\n",
    "# 2. 모델 로드 및 설정\n",
    "model_name = \"gpt2-small-124M.pth\"\n",
    "# 위에서 정의한 load_gpt2_model 함수 호출 (이때 device 변수가 함수 내부에서 사용됨)\n",
    "gpt = load_gpt2_model(model_name, BASE_CONFIG)\n",
    "\n",
    "gpt.to(device) # 모델을 해당 장치(GPU/CPU)로 이동\n",
    "gpt.eval()     # [중요] 평가 모드로 전환 (드롭아웃 비활성화 등)\n",
    "\n",
    "# 3. 텍스트 생성 테스트\n",
    "torch.manual_seed(123) # 결과 재현성을 위해 시드 고정\n",
    "\n",
    "# 입력 텍스트를 토큰 ID로 변환 후 장치로 이동\n",
    "start_context = \"Every effort moves you\"\n",
    "encoded_input = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=encoded_input,\n",
    "    max_new_tokens=25,  # 새로 생성할 토큰 개수\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    top_k=50,           # 상위 50개 확률 단어 중에서만 샘플링 (품질 유지)\n",
    "    temperature=1.5     # 창의성 높음 (1.0보다 크면 다양한 표현 시도)\n",
    ")\n",
    "\n",
    "# 4. 결과 출력\n",
    "print(\"출력 텍스트:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6252dbdb-0a12-4781-8942-0c78b7eaa781",
   "metadata": {},
   "source": [
    "- 모델별 차이점\n",
    "<img src=\"images/llm_from_scratch/ch05_compressed/17.webp\" width=700px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d079f98-a7c4-462e-8416-5a64f670861c",
   "metadata": {
    "id": "6d079f98-a7c4-462e-8416-5a64f670861c"
   },
   "source": [
    "- 모델이 일관성 있는 텍스트를 생성했기 때문에 가중치가 올바르게 로드되었다고 확신할 수 있습니다. 이 과정에서 조금만 잘못되어도 모델이 제대로 텍스트를 생성하지 못합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28493b9b-a1ae-4f31-87bc-c10ee4447f44",
   "metadata": {
    "id": "28493b9b-a1ae-4f31-87bc-c10ee4447f44"
   },
   "source": [
    "- 허깅 페이스 허브에서 가중치를 로드하는 방법은 [../02_alternative_weight_loading](../02_alternative_weight_loading)에 있는 노트북을 참고하세요.\n",
    "- GPT 구조와 (메타에서 개발한) Llama 구조를 비교해 보려면 보너스 콘텐츠 [../07_gpt_to_llama](../07_gpt_to_llama)를 참고하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a66474-230d-4180-a8ff-843e04f1f1c4",
   "metadata": {
    "id": "f2a66474-230d-4180-a8ff-843e04f1f1c4"
   },
   "source": [
    "## 요약"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7ed189-a633-458c-bf12-4f70b42684b8",
   "metadata": {
    "id": "fc7ed189-a633-458c-bf12-4f70b42684b8"
   },
   "source": [
    "- [./gpt_train.py](./gpt_train.py)는 훈련 스크립트 파일입니다.\n",
    "- [./gpt_generate.py](./gpt_generate.py)는 OpenAI에서 사전 훈련된 가중치를 로드하여 프롬프트를 기반으로 텍스트를 생성합니다.\n",
    "- 연습문제 솔루션은 [./exercise-solutions.ipynb](./exercise-solutions.ipynb)에 있습니다."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "llm-hands-on",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
