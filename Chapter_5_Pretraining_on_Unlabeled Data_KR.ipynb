{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11feef31",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/rickiepark/llm-from-scratch/blob/main/ch05/01_main-chapter-code/ch05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45398736-7e89-4263-89c8-92153baff553",
   "metadata": {
    "id": "45398736-7e89-4263-89c8-92153baff553"
   },
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<font size=\"2\">\n",
    "세바스찬 라시카(Sebastian Raschka)가 쓴 <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a>의 번역서 <br><<b><a href=\"<a href=\"http://tensorflow.blog/llm-from-scratch\">밑바닥부터 만들면서 배우는 LLM</a></b>>의 예제 코드입니다.<br>\n",
    "<br>코드 저장소: <a href=\"https://github.com/rickiepark/llm-from-scratch\">https://github.com/rickiepark/llm-from-scratch</a>\n",
    "</font>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<a href=\"http://tensorflow.blog/llm-from-scratch\"><img src=\"https://tensorflowkorea.wordpress.com/wp-content/uploads/2025/09/ebb091ebb094eb8ba5llm_ebb3b8ecb185_ec959eeba9b4.jpg\" width=\"100px\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dd524e-864c-4012-b0a2-ccfc56e80024",
   "metadata": {
    "id": "66dd524e-864c-4012-b0a2-ccfc56e80024"
   },
   "source": [
    "# 5장: 레이블이 없는 데이터를 활용한 사전 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92b989e9-da36-4159-b212-799184764dd9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "92b989e9-da36-4159-b212-799184764dd9",
    "outputId": "323b4987-fed4-4cbb-c5bd-3949099e9e71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib 버전: 3.10.8\n",
      "numpy 버전: 2.3.5\n",
      "tiktoken 버전: 0.12.0\n",
      "torch 버전: 2.9.1+cu126\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\",\n",
    "        \"numpy\",\n",
    "        \"tiktoken\",\n",
    "        \"torch\",\n",
    "        # \"tensorflow\" # OpenAI의 사전 훈련된 가중치를 위해서\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} 버전: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3bdf9e-2ff0-4a57-abab-ede2d955a237",
   "metadata": {
    "id": "0a3bdf9e-2ff0-4a57-abab-ede2d955a237"
   },
   "source": [
    "- 이 장에서 LLM을 사전 훈련하기 위해 훈련 루프를 구현하고 기본적인 모델 평가 방법을 알아 보겠습니다.\n",
    "- 이 장의 끝에서는 OpenAI의 사전 훈련된 가중치를 우리가 직접 구현한 모델에 로드해 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd27fcc-2886-47cb-b544-046c2c31f02a",
   "metadata": {
    "id": "efd27fcc-2886-47cb-b544-046c2c31f02a"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch05_compressed/01.webp\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d214765-7a73-42d5-95e9-302154b29db9",
   "metadata": {
    "id": "0d214765-7a73-42d5-95e9-302154b29db9"
   },
   "source": [
    "- 이 장에서 다루는 주제는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67711d4-8391-4fee-aeef-07ea53dd5841",
   "metadata": {
    "id": "f67711d4-8391-4fee-aeef-07ea53dd5841"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch05_compressed/02.webp\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d824183-145c-4865-89e1-1f0d0a338f19",
   "metadata": {
    "id": "0d824183-145c-4865-89e1-1f0d0a338f19"
   },
   "source": [
    "## 5.1 텍스트 생성 모델 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3350f8c-5181-4f9b-a789-4523105e98f2",
   "metadata": {
    "id": "a3350f8c-5181-4f9b-a789-4523105e98f2"
   },
   "source": [
    "- 이전 장에 코드를 사용하여 GPT 모델을 초기화하는 방법을 간략히 정리합니다.\n",
    "- 그다음 LLM을 위한 기본적인 평가 지표를 소개합니다.\n",
    "- 이 절의 마지막에서 이 평가 지표를 훈련 세트와 검증 세트에 적용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc1cf3f-82d8-46c7-9ecc-58979ce87cdd",
   "metadata": {
    "id": "bdc1cf3f-82d8-46c7-9ecc-58979ce87cdd"
   },
   "source": [
    "### 5.1.1 GPT를 사용해 텍스트 생성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3415fd-9f4a-4548-908e-9dfa56edc9bc",
   "metadata": {
    "id": "5b3415fd-9f4a-4548-908e-9dfa56edc9bc"
   },
   "source": [
    "- 이전 장의 코드를 사용하여 GPT 모델을 초기화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "oujnEbGCRVJe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oujnEbGCRVJe",
    "outputId": "3d1ff51c-cbc3-484d-f629-30c324508fb7"
   },
   "outputs": [],
   "source": [
    "# 깃허브에서 previous_chapters.py 파일을 다운로드합니다.\n",
    "# !wget https://bit.ly/3HlFmc8 -O previous_chapters.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86000d74-624a-48f0-86da-f41926cb9e04",
   "metadata": {
    "id": "86000d74-624a-48f0-86da-f41926cb9e04"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from previous_chapters import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # 어휘 사전 크기\n",
    "    \"context_length\": 256, # 짧은 문맥 길이 (원본 길이: 1024)\n",
    "    \"emb_dim\": 768,        # 임베딩 차원\n",
    "    \"n_heads\": 12,         # 어텐션 헤드 개수\n",
    "    \"n_layers\": 12,        # 층 개수\n",
    "    \"drop_rate\": 0.1,      # 드롭아웃 비율\n",
    "    \"qkv_bias\": False      # 쿼리-키-값 생성시 편향 사용 여부\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();  # 추론 시에는 드롭아웃을 비활성화합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c6cf0f-7458-48a2-97fd-aa5068d65e8c",
   "metadata": {
    "id": "09c6cf0f-7458-48a2-97fd-aa5068d65e8c"
   },
   "source": [
    "- 위에서 드롭아웃을 0.1로 지정했지만 요즘에는 드롭아웃을 사용하지 않고 LLM을 훈련하는 경우가 많습니다.\n",
    "- 최신 LLM은 (초기 GPT 모델과 달리) 쿼리, 키, 값 행렬을 위한 `nn.Linear` 층에서 편향 벡터를 사용하지 않습니다. 그래서 `\"qkv_bias\": False`로 지정합니다.\n",
    "- 모델 훈련에 필요한 계산 자원을 절감하기 위해 문맥 길이(`context_length`)를 256 토큰으로 줄입니다. 원본 1억 2,400만 파라미터의 GPT-2 모델은 1024개의 토큰을 사용했습니다.\n",
    "  - 대부분의 독자들은 이 코드 예제를 랩탑 컴퓨터에서 실행하기 때문입니다.\n",
    "  - 하지만 `context_length`를 1,024개 토큰으로 늘려서 실험해도 괜찮습니다(어떤 코드도 바꿀 필요가 없습니다)\n",
    "  - 나중에 `context_length`가 1,024인 모델을 사전 훈련된 가중치에서 로드하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f80895-be35-4bb5-81cb-f357ef7367fe",
   "metadata": {
    "id": "59f80895-be35-4bb5-81cb-f357ef7367fe"
   },
   "source": [
    "- 그 다음이 이전 장에서 만든 `generate_text_simple` 함수를 사용해 텍스트를 생성합니다.\n",
    "- 또한 두 개 유틸리티 함수 `text_to_token_ids`와 `token_ids_to_text`를 정의합니다. 이 장에서 토큰과 텍스트 표현 사이를 전환하는데 사용하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741881f3-cee0-49ad-b11d-b9df3b3ac234",
   "metadata": {
    "id": "741881f3-cee0-49ad-b11d-b9df3b3ac234"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch05_compressed/03.webp\" width=900px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e062b82-3540-48ce-8eb4-009686d0d16c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5e062b82-3540-48ce-8eb4-009686d0d16c",
    "outputId": "dad3e6ea-4617-417d-97ac-dfc14447e520"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출력 텍스트:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from previous_chapters import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # 배치 차원을 추가합니다.\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # 배치 차원을 삭제합니다\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"출력 텍스트:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d3249b-b2a0-44c4-b589-ae4b403b8305",
   "metadata": {
    "id": "e4d3249b-b2a0-44c4-b589-ae4b403b8305"
   },
   "source": [
    "- 위해서 볼 수 있듯이 모델이 아직 훈련되지 않았기 때문에 좋은 텍스트를 생성하지 못합니다.\n",
    "- 훈련 과정에서 어떤 것이 좋은 텍스트인지 어떻게 정량적으로 측정할 수 있을까요?\n",
    "- 다음 절에서 훈련 과정을 모니터링할 수 있도록 생성된 출력의 손실을 계산하는 지표를 소개합니다.\n",
    "- LLM 미세 튜닝을 다루는 다음 장에서 모델의 품질을 측정하는 또 다른 방법을 소개하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3d7ea2-637f-4490-bc76-e361fc81ae98",
   "metadata": {
    "id": "0f3d7ea2-637f-4490-bc76-e361fc81ae98"
   },
   "source": [
    "### 5.1.2 텍스트 생성 손실 계산하기: 크로스 엔트로피와 혼잡도"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1ba8aa-fb03-4d25-957f-fe8778762440",
   "metadata": {
    "id": "9e1ba8aa-fb03-4d25-957f-fe8778762440"
   },
   "source": [
    "- 두 개의 훈련 샘플(행)에 대한 토큰 ID를 담고 있는 `inputs` 텐서가 있다고 가정해보죠.\n",
    "- `inputs`에 해당하는 `targets`은 모델이 생성 해야할 토큰 ID를 담고 있습니다.\n",
    "- 2장에서 데이터 로더를 구현할 때 설명했듯이 `targets`은 `inputs`에서 한 토큰씩 앞으로 이동한 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b5402f8-ec0c-4a44-9892-18a97779ee4f",
   "metadata": {
    "id": "6b5402f8-ec0c-4a44-9892-18a97779ee4f"
   },
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dc0645-ac2c-4973-9b40-6da40515bede",
   "metadata": {
    "id": "33dc0645-ac2c-4973-9b40-6da40515bede"
   },
   "source": [
    "- `inputs`을 모델에 주입하면 각각 세 개의 토큰으로 구성된 두 개의 입력 샘플에 대한 로짓 벡터를 얻습니다.\n",
    "- 각각의 토큰는 어휘 사전 크기에 해당하는 50,257차원의 벡터입니다.\n",
    "- 소프트맥스 함수를 적용하여 로짓 텐서을 확률 점수를 담고 있는 동일 차원의 텐서로 바꿀 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7b6ec51-6f8c-49bd-a349-95ba38b46fb6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e7b6ec51-6f8c-49bd-a349-95ba38b46fb6",
    "outputId": "2fb80348-8746-4509-bb8e-3f5292ac5846"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():# Gradient(기울기)계산을 비활성화, 추론이나 평가시 사용\n",
    "    logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1) # 어휘 사전의 각 토큰에 대한 확률\n",
    "print(probas.shape) # 크기: (batch_size, num_tokens, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c36a382-b5e2-4de6-9e65-0b69b685013b",
   "metadata": {
    "id": "5c36a382-b5e2-4de6-9e65-0b69b685013b"
   },
   "source": [
    "- 매우 작은 어휘 사전을 사용하는 아래 그림에서 확률 점수를 텍스트로 바꾸는 방법을 보여 줍니다. 이 장의 끝에서 이에 대해 논의하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384d86a9-0013-476c-bb6b-274fd5f20b29",
   "metadata": {
    "id": "384d86a9-0013-476c-bb6b-274fd5f20b29"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch05_compressed/04.webp\" width=900px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8480efd-d419-4954-9ecc-2876055334bd",
   "metadata": {
    "id": "e8480efd-d419-4954-9ecc-2876055334bd"
   },
   "source": [
    "- 이전 장에서 설명했듯이 `argmax` 함수를 적용하여 확률 점수를 토큰 ID 바꿀 수 있습니다.\n",
    "- 앞의 소프트맥스 함수는 각 토큰에 대해서 50,257 차원의 벡터를 생성합니다. `argmax` 함수는 이 벡터에서 가장 높은 확률을 가진 위치를 반환합니다. 이것이 주어진 토큰에 대한 예측 토큰의 아이디입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b84c9f-dd08-482e-b903-a86fe44e1144",
   "metadata": {
    "id": "f3b84c9f-dd08-482e-b903-a86fe44e1144"
   },
   "source": [
    "- 배치에는 각각 세 개 토큰으로 구성된 두 개의 입력 샘플이 있으므로 2x3 크기의 예측 토큰을 얻습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34ebd76a-16ec-4c17-8958-8a135735cc1c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34ebd76a-16ec-4c17-8958-8a135735cc1c",
    "outputId": "b5f6d08c-71a6-4858-a543-b97545ffb7d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토큰 ID:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"토큰 ID:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee4072c-21ed-4df7-8721-dd2535362573",
   "metadata": {
    "id": "cee4072c-21ed-4df7-8721-dd2535362573"
   },
   "source": [
    "- 이 토큰을 디코딩하면 모델이 예측해야 할 토큰, 즉 타겟 토큰과 매우 다른 것을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c990ead6-53cd-49a7-a6d1-14d8c1518249",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c990ead6-53cd-49a7-a6d1-14d8c1518249",
    "outputId": "290fbe6c-aa20-4011-b7eb-b4ea1d292d44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫 번째 샘플의 타깃:  effort moves you\n",
      "첫 번째 샘플의 타깃:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"첫 번째 샘플의 타깃: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"첫 번째 샘플의 타깃: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53eb8a7-070e-46d6-930c-314ba55a6ff2",
   "metadata": {
    "id": "a53eb8a7-070e-46d6-930c-314ba55a6ff2"
   },
   "source": [
    "- 이는 모델이 아직 훈련되지 않았기 때문입니다.\n",
    "- 모델을 훈련하려면 정답 예측(타깃)에서 얼만큼 떨어져 있는지 알아야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad90592f-0d5d-4ec8-9ff5-e7675beab10e",
   "metadata": {
    "id": "ad90592f-0d5d-4ec8-9ff5-e7675beab10e"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch05_compressed/06.webp\" width=900px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7251bf5-a079-4782-901d-68c9225d3157",
   "metadata": {
    "id": "c7251bf5-a079-4782-901d-68c9225d3157"
   },
   "source": [
    "- 타겟 인덱스에 해당하는 토큰 확률은 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54aef09c-d6e3-4238-8653-b3a1b0a1077a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "54aef09c-d6e3-4238-8653-b3a1b0a1077a",
    "outputId": "51ada8d3-ead5-4c95-da8c-a79a9a12d45f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트 1: tensor([7.4540e-05, 3.1061e-05, 1.1563e-05])\n",
      "텍스트 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]] # [2, 3, 50257]\n",
    "print(\"텍스트 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"텍스트 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e89a19-73c2-4e49-93b4-861f699f1cbf",
   "metadata": {
    "id": "a0e89a19-73c2-4e49-93b4-861f699f1cbf"
   },
   "source": [
    "- 확률이 1에 가까워지도록 이 값들을 최대화하는 것이 목표입니다.\n",
    "- 수학적 최적화에서는 확률 점수 자체를 최대화하는 것보다 확률 점수의 로그를 최대화하는 것이 쉽습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31402a67-a16e-4aeb-977e-70abb9c9949b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "31402a67-a16e-4aeb-977e-70abb9c9949b",
    "outputId": "9633daea-c621-40f9-eb65-d1fa2f7ee7b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "# 토큰 확률의 로그를 계산합니다.\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4261441-a511-4633-9c4c-67998af31b84",
   "metadata": {
    "id": "c4261441-a511-4633-9c4c-67998af31b84"
   },
   "source": [
    "- 그 다음 로그 확률의 평균을 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b003797-161b-4d98-81dc-e68320e09fec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9b003797-161b-4d98-81dc-e68320e09fec",
    "outputId": "f3a0d3df-c21b-48d3-d743-118e8b6459b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "# 각 토큰에 대한 평균 확률을 계산합니다.\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d51994-ad17-4ba3-a6ec-f588b4b13585",
   "metadata": {
    "id": "36d51994-ad17-4ba3-a6ec-f588b4b13585"
   },
   "source": [
    "- 모델 가중치를 최적화하여 평균 로그 확률을 가능한 크게 만드는 것이 목표입니다.\n",
    "- 로그 때문에 가장 큰 가능한 값은 0이며, 현재는 0에서 부터 멀리 떨어져 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de388a1-8a0a-4c94-8894-9041dc6ad514",
   "metadata": {
    "id": "3de388a1-8a0a-4c94-8894-9041dc6ad514"
   },
   "source": [
    "- 딥러닝 에서는 평균 로그 확률을 최대화하는 것 대신에 음의 평균 로그 확률을 최소화하는 것이 일반적입니다. 이 예제의 경우 -10.7722를 최대화하여 0에 가깝게 만드는 것 대신에 10.7722을 최소화하여 0에 가깝게 만듭니다.\n",
    "- -10.7722의 음수 값, 즉 10.7722을 딥러닝에서는 크로스 엔트로피 손실이라고 부릅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "176ddf35-1c5f-4d7c-bf17-70f3e7069bd4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "176ddf35-1c5f-4d7c-bf17-70f3e7069bd4",
    "outputId": "f4232ec9-3c65-4f2f-85db-aaf3875750bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eeb868-abd8-4028-82db-107546bf7c2c",
   "metadata": {
    "id": "84eeb868-abd8-4028-82db-107546bf7c2c"
   },
   "source": [
    "- 파이토치는 이전 단계를 수행하는 `cross_entropy` 함수를 제공합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd24b7f-b760-47ad-bc84-86d13794aa54",
   "metadata": {
    "id": "5bd24b7f-b760-47ad-bc84-86d13794aa54"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch05_compressed/07.webp\" width=600px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aaf9dd-3ee6-42bf-a63f-6e93dbfb989d",
   "metadata": {
    "id": "e8aaf9dd-3ee6-42bf-a63f-6e93dbfb989d"
   },
   "source": [
    "- `cross_entropy` 함수를 적용하기 전에 로짓과 타깃의 크기를 확인해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "695d6f64-5084-4c23-aea4-105c9e38cfe4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "695d6f64-5084-4c23-aea4-105c9e38cfe4",
    "outputId": "1e90e870-badc-40e3-bd42-d4355cea8dac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로짓 크기: torch.Size([2, 3, 50257])\n",
      "타깃 크기: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# 로짓의 크기는 (batch_size, num_tokens, vocab_size)입니다.\n",
    "print(\"로짓 크기:\", logits.shape)\n",
    "\n",
    "# 타깃의 크기는 (batch_size, num_tokens)입니다.\n",
    "print(\"타깃 크기:\", targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3d65f0-6566-4865-93e4-0c0bcb10cd06",
   "metadata": {
    "id": "1d3d65f0-6566-4865-93e4-0c0bcb10cd06"
   },
   "source": [
    "- 파이토치의 `cross_entropy` 함수를 위해 배치 차원을 기준으로 합쳐서 텐서를 펼쳐야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e17e027-ab9f-4fb5-ac9b-a009b831c122",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0e17e027-ab9f-4fb5-ac9b-a009b831c122",
    "outputId": "52a46bbb-bdd8-42af-c5c3-903a37ee80b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "펼친 로짓: torch.Size([6, 50257])\n",
      "펼친 타깃: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\"펼친 로짓:\", logits_flat.shape)\n",
    "print(\"펼친 타깃:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4921a57f-3a79-473e-a863-6d63b495010f",
   "metadata": {
    "id": "4921a57f-3a79-473e-a863-6d63b495010f"
   },
   "source": [
    "- 타깃은 토큰 ID이며, 최대화해야 할 로짓 텐서의 인덱스를 나타냅니다.\n",
    "- 파이토치의 `cross_entropy` 함수는 최대화할 토큰 인덱스에 대해 자동으로 소프트맥스와 로그 확률 계산을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62d0816e-b29a-4c8f-a9a5-a167562de978",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62d0816e-b29a-4c8f-a9a5-a167562de978",
    "outputId": "3ee41d42-6315-4eab-fc49-6e22af1f02f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f15ce17-fd7b-4d8e-99da-b237523a7a80",
   "metadata": {
    "id": "0f15ce17-fd7b-4d8e-99da-b237523a7a80"
   },
   "source": [
    "- 크로스 엔트로피 손실에 관련된 개념은 LLM의 혼잡도입니다.\n",
    "- 혼잡도는 크로스 엔트로피 손실에 지수 함수를 적용한 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "168952a1-b964-4aa7-8e49-966fa26add54",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "168952a1-b964-4aa7-8e49-966fa26add54",
    "outputId": "9822b33e-c224-4816-aafb-e4991ab847bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48725.8203)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ae26dd-d77e-41fd-b924-6bd103dd4ee7",
   "metadata": {
    "id": "71ae26dd-d77e-41fd-b924-6bd103dd4ee7"
   },
   "source": [
    "- 혼잡도는 모델이 각 단계에서 불확실해하는 실제 어휘사전 크기를 나타내기 때문에 원시 손실 값보다 이해하기 더 쉽습니다(이 예에서는 48,725개 단어 또는 토큰).\n",
    "- 다른 말로 하면, 혼잡도는 모델이 예측한 확률 분포가 데이터셋에 있는 단어의 실제 분포와 얼마나 잘 맞는지를 측정합니다.\n",
    "- 손실과 비슷하게 낮은 혼잡도는 모델 예측이 실제 분포에 가깝다는 것을 나타냅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec6c217-e429-40c7-ad71-5d0a9da8e487",
   "metadata": {
    "id": "2ec6c217-e429-40c7-ad71-5d0a9da8e487"
   },
   "source": [
    "### 5.1.3 훈련 세트와 검증 세트의 손실 계산하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530da89e-2448-436c-8f1b-28e8a31ef85c",
   "metadata": {
    "id": "530da89e-2448-436c-8f1b-28e8a31ef85c"
   },
   "source": [
    "- LLM 훈련을 위해 비교적 작은 데이터셋을 사용합니다(사실 단편 소설 하나를 사용합니다).\n",
    "- 이유는 다음과 같습니다.\n",
    "  - 적절한 GPU가 없는 랩탑 컴퓨터에서 몇 분 안에 코드 예제가 실행되어야 합니다.\n",
    "  - 교육 목적을 위해 훈련이 비교적 빨리 끝나야 합니다(몇 주가 아니라 몇 분 만에).\n",
    "  - 사용 권리를 위반하지 않으며 깃허브 저장소에 저장할 수 있는 크기의 공개된 텍스트를 사용해야 합니다.\n",
    "- 예를 들어, Llama 2 7B는 2조 개의 토큰에서 훈련하기 위해 A100 GPU에서 184,320 GPU 시간이 필요합니다.\n",
    "  - 이 글을 쓰는 시점에, AWS의 8xA100 클라우드 서버의 시간당 가격은 약 \\$30입니다.\n",
    "  - 따라서 대략 계산하면 이 LLM을 훈련하는데 184,320 / 8 * \\$30 =  \\$690,000이 듭니다.\n",
    "- 아래에서는 2장에서 다루었던 데이터셋을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "654fde37-b2a9-4a20-a8d3-0206c056e2ff",
   "metadata": {
    "id": "654fde37-b2a9-4a20-a8d3-0206c056e2ff"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "file_path = \"datas/the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    response = requests.get(url, timeout=30)\n",
    "    response.raise_for_status()\n",
    "    text_data = response.text\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()\n",
    "\n",
    "# 책에서는 다음 코드를 사용했지만 VPN을 사용하는 경우 urllib가 문제를 일으킬 수 있습니다.\n",
    "# 따라서 더 안정적인 `requests` 패키지를 사용합니다.\n",
    "\n",
    "# import os\n",
    "# import urllib.request\n",
    "\n",
    "# file_path = \"the-verdict.txt\"\n",
    "# url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "# if not os.path.exists(file_path):\n",
    "#     with urllib.request.urlopen(url) as response:\n",
    "#         text_data = response.read().decode('utf-8')\n",
    "#     with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "#         file.write(text_data)\n",
    "# else:\n",
    "#     with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "#         text_data = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379330f1-80f4-4e34-8724-41d892b04cee",
   "metadata": {
    "id": "379330f1-80f4-4e34-8724-41d892b04cee"
   },
   "source": [
    "- 다운로드한 텍스트를 확인하기 위해 처음과 끝에서 100 개의 문자를 출력하여 보죠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6kgJbe4ehI4q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6kgJbe4ehI4q",
    "outputId": "b08c7968-afe4-4e88-b111-f09daecca3cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "# 처음 99개 문자\n",
    "print(text_data[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "j2XPde_ThM_e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j2XPde_ThM_e",
    "outputId": "5197ff45-c5d2-4c5b-e135-3261bd1b5790"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n"
     ]
    }
   ],
   "source": [
    "# 마지막 99개 문자\n",
    "print(text_data[-99:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b46a952-d50a-4837-af09-4095698f7fd1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6b46a952-d50a-4837-af09-4095698f7fd1",
    "outputId": "786c8b83-cf2f-4918-a666-d5093c1f330d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문자: 20479\n",
      "토큰: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"문자:\", total_characters)\n",
    "print(\"토큰:\", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8830cb9-90f6-4e7c-8620-beeabc2d39f7",
   "metadata": {
    "id": "a8830cb9-90f6-4e7c-8620-beeabc2d39f7"
   },
   "source": [
    "이 텍스트의 토큰이 5,145개 뿐이라 LLM을 훈련하기에 너무 적어 보일 수 있습니다. 하지만 이는 교육적인 목적을 위해서입니다(나중에 사전 훈련된 가중치를 로드하겠습니다)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedcad87-a0e8-4b9d-ac43-4e927ccbb50f",
   "metadata": {
    "id": "bedcad87-a0e8-4b9d-ac43-4e927ccbb50f"
   },
   "source": [
    "- 그 다음 데이터셋을 훈련 세트와 검증 세트로 나누고 2장의 데이터 로더를 사용해 LLM 훈련을 위한 배치를 준비합니다.\n",
    "- 시각화때문에 아래 그림은 `max_length=6`라고 가정하지만, 훈련 데이터 로더에서 `max_length`는 LLM이 지원하는 문맥 길이와 같습니다.\n",
    "- 아래 그림은 간단하게 나타내려고 입력 토큰만 보여줍니다.\n",
    "  - LLM을 텍스트에 있는 다음 단어를 예측하도록 훈련하기 때문에 타깃은 한 토큰씩 이동한 것외에는 입력과 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bdaa07-ba96-4ac1-9d71-b3cc153910d9",
   "metadata": {
    "id": "46bdaa07-ba96-4ac1-9d71-b3cc153910d9"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch05_compressed/09.webp\" width=900px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0959c855-f860-4358-8b98-bc654f047578",
   "metadata": {
    "id": "0959c855-f860-4358-8b98-bc654f047578"
   },
   "outputs": [],
   "source": [
    "from previous_chapters import create_dataloader_v1\n",
    "\n",
    "# 훈련 세트 비율\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f37b3eb0-854e-4895-9898-fa7d1e67566e",
   "metadata": {
    "id": "f37b3eb0-854e-4895-9898-fa7d1e67566e"
   },
   "outputs": [],
   "source": [
    "# 유효성 검사\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"훈련 데이터 로더에 토큰이 충분하지 않습니다. \"\n",
    "          \"`GPT_CONFIG_124M['context_length']`를 낮추거나 \"\n",
    "          \"`training_ratio`를 증가시키세요.\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"훈련 데이터 로더에 토큰이 충분하지 않습니다. \"\n",
    "          \"`GPT_CONFIG_124M['context_length']`를 낮추거나 \"\n",
    "          \"`training_ratio`를 증가시키세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ac3296-a4d1-4303-9ac5-376518960c33",
   "metadata": {
    "id": "e7ac3296-a4d1-4303-9ac5-376518960c33"
   },
   "source": [
    "- 컴퓨팅 자원을 절감하고 데이터셋이 매우 작기 때문에 비교적 작은 배치 크기를 사용합니다.\n",
    "- 예를 들어 Llama 2 7B는 배치 크기 1024에서 훈련되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e0514d-b990-4dc0-9afb-7721993284a0",
   "metadata": {
    "id": "a8e0514d-b990-4dc0-9afb-7721993284a0"
   },
   "source": [
    "- 데이터가 올바르게 로드되었는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca0116d0-d229-472c-9fbf-ebc229331c3e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ca0116d0-d229-472c-9fbf-ebc229331c3e",
    "outputId": "16bde066-4c1e-41b3-d375-06b94b2c3c89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 로더:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "검증 데이터 로더:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"훈련 데이터 로더:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\n검증 데이터 로더:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b9b1a4-863d-456f-a8dd-c07fb5c024ed",
   "metadata": {
    "id": "f7b9b1a4-863d-456f-a8dd-c07fb5c024ed"
   },
   "source": [
    "- 토큰 크기가 예상 범위 안에 있는지 추가로 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb860488-5453-41d7-9870-23b723f742a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eb860488-5453-41d7-9870-23b723f742a0",
    "outputId": "adf4ea59-6c5a-4fd0-c8f5-0807894858e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 토큰 수: 4608\n",
      "검증 토큰 수: 512\n",
      "모든 토큰 수: 5120\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"훈련 토큰 수:\", train_tokens)\n",
    "print(\"검증 토큰 수:\", val_tokens)\n",
    "print(\"모든 토큰 수:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3085e8-665e-48eb-bb41-cdde61537e06",
   "metadata": {
    "id": "5c3085e8-665e-48eb-bb41-cdde61537e06"
   },
   "source": [
    "- 주어진 배치에서 크로스 엔트로피 손실을 계산 하는 유틸리티 함수를 작성 합니다\n",
    "- 또한 데이터 로더에서 사용자가 지정한 배치 개수 만큼 추출하여 손실을 계산하는 두 번째 유틸리티 함수를 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b9de31e-4096-47b3-976d-b6d2fdce04bc",
   "metadata": {
    "id": "7b9de31e-4096-47b3-976d-b6d2fdce04bc"
   },
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # num_batches가 데이터 로더에 있는 배치 개수보다 크면\n",
    "        # 배치 횟수를 데이터 로더에 있는 총 배치 개수로 맞춥니다.\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0691332-84d0-48b3-b462-a885ddeb4fca",
   "metadata": {
    "id": "f0691332-84d0-48b3-b462-a885ddeb4fca"
   },
   "source": [
    "- CUDA를 지원하는 GPU를 가지고 있다면 어떤 코드도 변경할 필요 없이 GPU 에서 LLM을 훈련할 수 있습니다.\n",
    "- `device` 설정을 통해 데이터를 LLM 모델과 동일한 장치에 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56f5b0c9-1065-4d67-98b9-010e42fc1e2a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "56f5b0c9-1065-4d67-98b9-010e42fc1e2a",
    "outputId": "95e16aa8-0f0a-4440-814b-3ab398bb1737"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device.\n",
      "훈련 손실: 10.987583266364204\n",
      "검증 손실: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    # 파이토치 2.9 이상에서는 mps 결과가 안정적입니다.\n",
    "    major, minor = map(int, torch.__version__.split(\".\")[:2])\n",
    "    if (major, minor) >= (2, 9):\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using {device} device.\")\n",
    "\n",
    "\n",
    "model.to(device) # nn.Module 클래스의 경우 model = model.to(device)로 할당할 필요가 없습니다.\n",
    "\n",
    "torch.manual_seed(123) # 데이터 로더에서 셔플링이 일어나므로 재현가능성을 위해 설정합니다.\n",
    "\n",
    "with torch.no_grad(): # 모델을 아직 훈련하지 않으므로 효율성을 위해 그레이디언트 추적을 끕니다.\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"훈련 손실:\", train_loss)\n",
    "print(\"검증 손실:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43875e95-190f-4b17-8f9a-35034ba649ec",
   "metadata": {
    "id": "43875e95-190f-4b17-8f9a-35034ba649ec"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch05_compressed/10.webp\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9339f8d-00cb-4206-af67-58c32bd72055",
   "metadata": {
    "id": "b9339f8d-00cb-4206-af67-58c32bd72055"
   },
   "source": [
    "## 5.2 LLM 훈련하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652a4cf4-e98f-46d9-bdec-60e7ccb8d6bd",
   "metadata": {
    "id": "652a4cf4-e98f-46d9-bdec-60e7ccb8d6bd"
   },
   "source": [
    "- 이 절에서는 LLM 훈련을 위한 코드를 구현합니다.\n",
    "- 여기서는 간단한 훈련 함수를 만듭니다(이 훈련 함수를 학습률 워밍업, 코사인 어닐링, 그레이디언트 클리핑 같은 고급 기법으로 확장하고 싶다면 [부록 D](../../appendix-D/01_main-chapter-code)를 참고하세요).\n",
    "\n",
    "<img src=\"images/llm_from_scratch/ch05_compressed/11.webp\" width=600px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "Mtp4gY0ZO-qq",
   "metadata": {
    "id": "Mtp4gY0ZO-qq"
   },
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # 손실과 지금까지 처리한 토큰 수를 추적하기 위해 리스트를 초기화합니다.\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # 메인 훈련 루프를 시작합니다.\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # 모델을 훈련 모드로 설정합니다.\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # 이전 배치 반복에서 얻은 손실의 그레이디언트를 초기화합니다.\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # 손실의 그레이디언트를 계산합니다.\n",
    "            optimizer.step() # 손실의 그레이디언트를 사용하여 모델 가중치를 업데이트합니다.\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # 추가적인 평가 단계\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"에포크 {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"훈련 손실 {train_loss:.3f}, 검증 손실 {val_loss:.3f}\")\n",
    "\n",
    "        # 각 에포크 후에 샘플 텍스트를 출력합니다.\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # 간결한 출력 포맷을 위해\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a301b333-b9d4-4eeb-a212-3a9874e3ac47",
   "metadata": {
    "id": "a301b333-b9d4-4eeb-a212-3a9874e3ac47"
   },
   "source": [
    "- 위에 정의한 훈련 함수로 LLM을 훈련해 보죠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3422000b-7aa2-485b-92df-99372cd22311",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3422000b-7aa2-485b-92df-99372cd22311",
    "outputId": "c561513b-e8a8-4d9e-9fb8-d2cf513558c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크 1 (Step 000000): 훈련 손실 9.820, 검증 손실 9.932\n",
      "에포크 1 (Step 000005): 훈련 손실 8.065, 검증 손실 8.341\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "에포크 2 (Step 000010): 훈련 손실 6.621, 검증 손실 7.052\n",
      "에포크 2 (Step 000015): 훈련 손실 6.047, 검증 손실 6.601\n",
      "Every effort moves you, and,, and,,,,,,, and,.                                   \n",
      "에포크 3 (Step 000020): 훈련 손실 5.582, 검증 손실 6.480\n",
      "에포크 3 (Step 000025): 훈련 손실 5.524, 검증 손실 6.402\n",
      "Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and\n",
      "에포크 4 (Step 000030): 훈련 손실 5.110, 검증 손실 6.354\n",
      "에포크 4 (Step 000035): 훈련 손실 4.987, 검증 손실 6.386\n",
      "Every effort moves you, and a, and a, and a-- the picture. Gisburn, and a was, and a. I had been. of the of the of the of the of the of the of the of the of the. I had a\n",
      "에포크 5 (Step 000040): 훈련 손실 4.369, 검증 손실 6.264\n",
      "Every effort moves you, one of the picture--as of the picture--as of the of the of the picture--as of the fact of the picture of the picture of the picture of the picture.   \"I had been the of the picture of the\n",
      "에포크 6 (Step 000045): 훈련 손실 3.978, 검증 손실 6.204\n",
      "에포크 6 (Step 000050): 훈련 손실 3.479, 검증 손실 6.194\n",
      "Every effort moves you know the                                                \n",
      "에포크 7 (Step 000055): 훈련 손실 3.510, 검증 손실 6.213\n",
      "에포크 7 (Step 000060): 훈련 손실 2.728, 검증 손실 6.146\n",
      "Every effort moves you know he was not that I felt--I looked, and I felt to have to have to see a little to me to have to see a little of his pictures--I looked.             \n",
      "에포크 8 (Step 000065): 훈련 손실 2.255, 검증 손실 6.148\n",
      "에포크 8 (Step 000070): 훈련 손실 1.922, 검증 손실 6.216\n",
      "Every effort moves you know,\" was not that the picture.  \"I had the last word.           \"I turned back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "에포크 9 (Step 000075): 훈련 손실 1.547, 검증 손실 6.220\n",
      "에포크 9 (Step 000080): 훈련 손실 1.216, 검증 손실 6.279\n",
      "Every effort moves you know,\" was not that my hostess was \"interesting\": on that I had not till I felt to me to me to have to see a smile behind his pictures with a little.   \"I had been the bull--and by his\n",
      "에포크 10 (Step 000085): 훈련 손실 0.922, 검증 손실 6.320\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "# 노트:\n",
    "# 실행 시간을 계산하고 싶다면 다음 주석을 해제하세요.\n",
    "# import time\n",
    "# start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Note:\n",
    "# 실행 시간을 계산하고 싶다면 다음 주석을 해제하세요.\n",
    "# end_time = time.time()\n",
    "# execution_time_minutes = (end_time - start_time) / 60\n",
    "# print(f\"훈련 소요 시간: {execution_time_minutes:.2f}분.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8b86f0-b07d-40d7-b9d3-a9218917f204",
   "metadata": {
    "id": "2e8b86f0-b07d-40d7-b9d3-a9218917f204"
   },
   "source": [
    "- 여러분의 결과와 손실 값이 조금 다를 수 있습니다. 대체적으로 비슷하다면 (훈련 손실은 1이하이고 검증 손실은 7이하이면) 걱정할 필요가 없습니다.\n",
    "- GPU 하드웨어와 CUDA 버전 또는 파이토치의 신버전에서 바뀐 변화 때문에 차이가 발생할 수 있습니다.\n",
    "- CPU에서 이 예제를 실행하더라도 작은 차이를 볼 수 있습니다. 이런 차이를 만드는 원인 중 하나는 파이토치가 컴파일된 운영체제에 따라 `nn.Dropout`의 동작 방식이 다르기 때문입니다. 자세한 내용은 파이토치 [깃허브 이슈](https://github.com/pytorch/pytorch/issues/121595)를 참고하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0WSRu2i0iHJE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "0WSRu2i0iHJE",
    "outputId": "843a9009-b1b2-4d60-a0e9-26b75ee0836c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # 에포크에 대한 훈련 손실과 검증 손실의 그래프를 그립니다.\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # 처리한 토큰 수에 대한 두 번째 x 축을 만듭니다.\n",
    "    ax2 = ax1.twiny()  # y 축을 공유하는 두 번째 x 축을 만듭니다.\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # 눈금을 정렬하기 위해 투명한 그래프를 만듭니다.\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(\"outputs/loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc83ded-5f80-4e1c-bf4d-ccb59999d995",
   "metadata": {
    "id": "8bc83ded-5f80-4e1c-bf4d-ccb59999d995"
   },
   "source": [
    "- 위 결과를 보면 모델이 처음에는 이해할 수 없는 단어를 생성하지만 마지막으로 갈수록 문법적으로 어느 정도 정확한 문장을 생성합니다.\n",
    "- 하지만 훈련 세트 손실과 검증 세트 손실을 보면 모델이 과대적합되기 시작합니다.\n",
    "- 마지막 부분의 몇 문장을 확인하면 훈련 세트에 있는 내용이라는 것을 알 수 있습니다. 모델이 단순히 훈련 데이터를 암기한 것입니다.\n",
    "- 매우 작은 훈련 세트를 사용하고 모델을 여러 에포크에서 훈련하고 있기 때문에 과대적합이 일어납니다.\n",
    "  - 여기서는 교육적인 목적을 위해 LLM을 훈련합니다. 모델이 일관된 텍스트를 생성하는 방법을 학습할 수 있는지 확인하는 것이 주요 목적입니다.\n",
    "  - 대량의 고가 하드웨어에서 몇 주 또는 몇 달 동안 이런 모델을 훈련하는 대신에 나중에 사전 훈련된 가중치를 로드하여 사용하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb380c42-b31c-4ee1-b8b9-244094537272",
   "metadata": {
    "id": "eb380c42-b31c-4ee1-b8b9-244094537272"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch05_compressed/13.webp\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5cdf2f-09a5-4eb0-a20a-d7aac5c14c2c",
   "metadata": {
    "id": "6d5cdf2f-09a5-4eb0-a20a-d7aac5c14c2c"
   },
   "source": [
    "- 더 큰 훈련 데이터셋에서 오래 모델을 훈련하고 싶다면 [../03_bonus_pretraining_on_gutenberg](../03_bonus_pretraining_on_gutenberg)을 참고하세요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699f45fc-bf78-42f2-bd24-2355db41b28f",
   "metadata": {
    "id": "699f45fc-bf78-42f2-bd24-2355db41b28f"
   },
   "source": [
    "## 5.3 무작위성을 제어하기 위한 디코딩 전략"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be9086e-2c27-41da-97d0-49137d0ba3c7",
   "metadata": {
    "id": "6be9086e-2c27-41da-97d0-49137d0ba3c7"
   },
   "source": [
    "- 위에서 구현한 GPT 모델처럼 작은 LLM의 추론 비용은 비교적 저렴합니다. 따라서 훈련에 GPU를 사용했더라도 추론에서는 GPU를 사용할 필요가 없습니다.\n",
    "- 이전 장에서 만든 `generate_text_simple` 함수를 사용해 한 번에 하나의 단어(또는 토큰)씩 새로운 텍스트를 생성할 수 있습니다.\n",
    "- 5.1.2절에서 설명했듯이 생성된 다음 토큰은 어휘사전의 모든 토큰 중에서 확률 점수가 가장 높은 토큰입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2734cee0-f6f9-42d5-b71c-fa7e0ef28b6d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2734cee0-f6f9-42d5-b71c-fa7e0ef28b6d",
    "outputId": "a04a6ae7-7be6-4f72-bc2d-4930d0a0fac4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출력 텍스트:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NEW: 이후 코드의 결과를 책과 일치하도록 만들기 위해 CPU를 사용합니다.\n",
    "inference_device = torch.device(\"cpu\")\n",
    "\n",
    "model.to(inference_device)\n",
    "model.eval()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(inference_device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"출력 텍스트:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25dbe31-bb7c-4893-b25b-47d0492d4aa4",
   "metadata": {
    "id": "d25dbe31-bb7c-4893-b25b-47d0492d4aa4"
   },
   "source": [
    "- `generate_text_simple` 함수를 여러번 실행하더라도 LLM은 항상 동일한 출력을 생성합니다.\n",
    "- `generate_text_simple`를 수정하기 위해 두 가지 디코딩 전략을 소개합니다. *온도 스케일링*과 *탑-k* 샘플링입니다.\n",
    "- 이를 사용해 모델이 생성된 텍스트의 무작위성과 다양성을 조절할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb6f380-a798-4fd9-825c-17b7cd29a994",
   "metadata": {
    "id": "4bb6f380-a798-4fd9-825c-17b7cd29a994"
   },
   "source": [
    "### 5.3.1 온도 스케일링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f4f53c-0612-43d3-aa82-52447eac50fa",
   "metadata": {
    "id": "a7f4f53c-0612-43d3-aa82-52447eac50fa"
   },
   "source": [
    "- 이전에는 `torch.argmax`를 사용해 항상 가장 높은 확률을 가진 토큰을 다음 토큰으로 샘플링했습니다.\n",
    "- 다양성을 추가하기 위해 확률 분포에서 샘플링하도록 `torch.multinomial(probs, num_samples=1)`을 사용해 토큰을 샘플링할 수 있습니다.\n",
    "- 여기서 각 인덱스 선택 가능성은 입력 텐서에 있는 확률에 따라 결정됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7531bae-d5de-44c0-bc78-78fed077e22a",
   "metadata": {
    "id": "e7531bae-d5de-44c0-bc78-78fed077e22a"
   },
   "source": [
    "- 여기에서 다음 토큰 생성에 대해 간략히 정리해 보겠습니다. 설명을 위해 매우 작은 어휘사전을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01a5ce39-3dc8-4c35-96bc-6410a1e42412",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "01a5ce39-3dc8-4c35-96bc-6410a1e42412",
    "outputId": "f6588dd8-5b3f-4dc7-9e13-473afd36c698"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "vocab = {\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "}\n",
    "\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "# 입력이 \"every effort moves you\"이고\n",
    "# LLM이 다음 토큰을 위해 아래와 같은 로짓을 반환했다고 가정해 보죠.\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "\n",
    "# 생성될 토큰은 다음과 같습니다.\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6400572f-b3c8-49e2-95bc-433e55c5b3a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6400572f-b3c8-49e2-95bc-433e55c5b3a1",
    "outputId": "282da416-9f62-4947-b299-7353de2a65fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63d0a27-830b-42b5-9986-6d1a7de04dd9",
   "metadata": {
    "id": "c63d0a27-830b-42b5-9986-6d1a7de04dd9"
   },
   "source": [
    "- `torch.argmax`로 가장 가능성이 높은 토큰을 결정하는 대신에 `torch.multinomial(probas, num_samples=1)`를 사용해 소프트맥스 분포에서 샘플링하여 가장 가능성이 높은 토큰을 결정할 수 있습니다.\n",
    "- 설명을 위해 원래 소프트맥스 분포에서 1,000번 토큰을 샘플링해 보죠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b23b863e-252a-403c-b5b1-62bc0a42319f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b23b863e-252a-403c-b5b1-62bc0a42319f",
    "outputId": "ee53e519-d018-4b6a-e997-f66b684ed371"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "582 x forward\n",
      "2 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "343 x toward\n",
      "0 x you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123) # 재현가능성을 위한 랜덤 시드\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample), minlength=len(probas))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e7d9cf-a26d-4d9a-8664-4af1efa73832",
   "metadata": {
    "id": "32e7d9cf-a26d-4d9a-8664-4af1efa73832"
   },
   "source": [
    "- 온도 스케일링으로 분포와 선택 과정을 조절할 수 있습니다.\n",
    "- \"온도 스케일링\"은 로짓을 0보다 큰 숫자로 나누는 것을 의미합니다.\n",
    "- 1보다 큰 온도는 소프트맥스 함수를 적용한 후에 더 균등한 토큰 확률 분포를 만듭니다.\n",
    "- 1보다 작은 온도는 소프트맥스 함수를 적용한 후에 더 결정론적인 분포(더 날카롭거나 뾰족한 분포)를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0759e4c8-5362-467c-bec6-b0a19d1ba43d",
   "metadata": {
    "id": "0759e4c8-5362-467c-bec6-b0a19d1ba43d"
   },
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "\n",
    "# 온도 값\n",
    "temperatures = [1, 0.1, 5]  # 원본, 낮은 온도, 높은 온도\n",
    "\n",
    "# 스케일을 조정한 확률 계산\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2e66e613-4aca-4296-a984-ddd0d80c6578",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "2e66e613-4aca-4296-a984-ddd0d80c6578",
    "outputId": "4ad8e021-e147-43cf-ccdc-fdcdad8429c5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프 그리기\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i], bar_width, label=f'Temperature = {T}')\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"outputs/temperature-plot.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d750e989-842a-4cfa-a44b-cf44d6e49163",
   "metadata": {
    "id": "d750e989-842a-4cfa-a44b-cf44d6e49163"
   },
   "source": [
    "- 온도 0.1로 스케일을 조정하면 더 뾰족한 분포를 만들어, `torch.argmax`에 가까워져 항상 가장 가능성있는 토큰이 선택됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e4600713-c51e-4f53-bf58-040a6eb362b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e4600713-c51e-4f53-bf58-040a6eb362b8",
    "outputId": "54400e8d-6190-4791-e2e6-69614305e872"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "985 x forward\n",
      "0 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "15 x toward\n",
      "0 x you\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(scaled_probas[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526e93cb-8e2a-42a1-b1ba-4fd5fe64c26b",
   "metadata": {
    "id": "526e93cb-8e2a-42a1-b1ba-4fd5fe64c26b"
   },
   "source": [
    "- 온도 5로 스케일을 조정한 확률은 더 균등한 분포가 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9dfb48f0-bc3f-46a5-9844-33b6c9b0f4df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9dfb48f0-bc3f-46a5-9844-33b6c9b0f4df",
    "outputId": "42128234-557f-4737-982d-7b0b9f0bc94b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165 x closer\n",
      "75 x every\n",
      "42 x effort\n",
      "239 x forward\n",
      "71 x inches\n",
      "46 x moves\n",
      "32 x pizza\n",
      "227 x toward\n",
      "103 x you\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(scaled_probas[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c83f0c4-3774-4375-ad7f-96440ba5fef7",
   "metadata": {
    "id": "0c83f0c4-3774-4375-ad7f-96440ba5fef7"
   },
   "source": [
    "- LLM 입력이 \"every effort moves you\"일 경우 위와 같은 방법을 사용하면 \"every effort moves you pizza\"와 같이 3.2%의 확률(1,000번 중에 32번)로 이따금 말이 안되는 텍스트를 생성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e4873e-07e4-4abb-85df-bdaedcc1a6f7",
   "metadata": {
    "id": "c6e4873e-07e4-4abb-85df-bdaedcc1a6f7"
   },
   "source": [
    "### 5.3.2 탑-k 샘플링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4da95a-8bb2-4f69-a9b0-a643531db5df",
   "metadata": {
    "id": "6d4da95a-8bb2-4f69-a9b0-a643531db5df"
   },
   "source": [
    "- 높은 온도를 사용하여 출력의 다양성을 증가시키면서 말이 안되는 문장이 생성될 가능성을 낮추기 위해 가장 가능성있는 상위 k개 토큰으로 샘플링될 토큰을 제한할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae6fffd-2730-4abe-a2d3-781fc4836f17",
   "metadata": {
    "id": "7ae6fffd-2730-4abe-a2d3-781fc4836f17"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch05_compressed/15.webp\" width=700px>\n",
    "\n",
    "- (이 그림의 숫자는 간단하게 나타내려고 소숫점 두자리 이후를 자른 값입니다. 소프트맥스 열의 값은 모두 더해서 1.0이 되어야 합니다)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba12da5-6ff1-4008-91b8-d2d537cbc14c",
   "metadata": {
    "id": "0ba12da5-6ff1-4008-91b8-d2d537cbc14c"
   },
   "source": [
    "- 코드로는 다음과 같이 구현할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2a7f908a-e9ec-446a-b407-fb6dbf05c806",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2a7f908a-e9ec-446a-b407-fb6dbf05c806",
    "outputId": "4802b0c1-4c2e-4986-aec1-10b32cb251ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "탑-k 로짓: tensor([6.7500, 6.2800, 4.5100])\n",
      "탑-k 위치: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "\n",
    "print(\"탑-k 로짓:\", top_logits)\n",
    "print(\"탑-k 위치:\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "753865ed-79c5-48b1-b9f2-ccb132ff1d2f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "753865ed-79c5-48b1-b9f2-ccb132ff1d2f",
    "outputId": "b657970e-19ef-43cb-c8cf-daf61cc10531"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],\n",
    "    input=torch.tensor(float(\"-inf\")),\n",
    "    other=next_token_logits\n",
    ")\n",
    "\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa6fa49-6e99-459d-a517-d7d0f51c4f00",
   "metadata": {
    "id": "dfa6fa49-6e99-459d-a517-d7d0f51c4f00"
   },
   "source": [
    "> 노트:  \n",
    ">\n",
    ">  이전 코드를 조금 더 효율적으로 구현하는 방법은 다음과 같습니다.\n",
    ">\n",
    "> ```python\n",
    "> new_logits = torch.full_like( # -inf 값을 담은 텐서를 만듭니다.\n",
    ">    next_token_logits, -torch.inf\n",
    ">)   \n",
    "> new_logits[top_pos] = next_token_logits[top_pos] # -inf 텐서에 상위 k개 값을 복사합니다.\n",
    "> ```\n",
    "> <br>\n",
    "> 자세한 내용은 다음을 참고하세요: https://github.com/rasbt/LLMs-from-scratch/discussions/326\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4844f000-c329-4e7e-aa89-16a2c4ebee43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4844f000-c329-4e7e-aa89-16a2c4ebee43",
    "outputId": "33060826-7853-48dd-87af-da5f06c0018f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56056503-a15d-4315-a3ff-46647a4c7c45",
   "metadata": {
    "id": "56056503-a15d-4315-a3ff-46647a4c7c45"
   },
   "source": [
    "### 5.3.3 텍스트 생성 함수 수정하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34770423-473d-46f6-a5fa-6b2979564d26",
   "metadata": {
    "id": "34770423-473d-46f6-a5fa-6b2979564d26"
   },
   "source": [
    "- 이전 두 개의 절에서 온도 스케일링과 탑-k 샘플링을 소개했습니다.\n",
    "- 두 개념을 사용해 앞서 LLM으로 텍스트를 생성할 때 사용한 `generate_sample` 함수를 수정해 새로운 `generate` 함수를 만들어 보죠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8e318891-bcc0-4d71-b147-33ce55febfa3",
   "metadata": {
    "id": "8e318891-bcc0-4d71-b147-33ce55febfa3"
   },
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    # for 루프는 이전과 동일합니다. 로짓을 받아 마지막 타임 스텝만 사용합니다.\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # 탑-k 샘플링으로 로짓을 필터링합니다.\n",
    "        if top_k is not None:\n",
    "            # 탑-k 값만 유지합니다.\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        # 온도 스케일링을 적용합니다.\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # (책에 없음): mps 장치에서 동일한 결과를 얻기 위해 수치 안정성을 위한 팁\n",
    "            # 소프트맥스 전에 행의 최댓값을 뺍니다.\n",
    "            logits = logits - logits.max(dim=-1, keepdim=True).values\n",
    "\n",
    "            # 소프트맥스 함수를 적용하여 확률을 얻습니다.\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # 분포에서 샘플링합니다.\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # 온도 스케일링을 사용하지 않는 경우 이전처럼 그리디 샘플링을 사용해 다음 토큰을 선택합니다.\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # eos_id가 지정되어 있고 EoS 토큰을 만나면 생성을 중단합니다.\n",
    "            break\n",
    "\n",
    "        # 이전과 동일하게 샘플링된 인덱스를 현재 시퀀스 뒤에 추가합니다.\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aa2a0d7d-0457-42d1-ab9d-bd67683e7ed8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aa2a0d7d-0457-42d1-ab9d-bd67683e7ed8",
    "outputId": "14bcc0b4-d977-4067-ee25-96e12adef458"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출력 텍스트:\n",
      " Every effort moves you stand,\" was down surprise, one of his glory, my lies by by\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(inference_device),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print(\"출력 텍스트:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2002ca-f4c1-48af-9e0a-88bfc163ba0b",
   "metadata": {
    "id": "4e2002ca-f4c1-48af-9e0a-88bfc163ba0b"
   },
   "source": [
    "## 5.4 파이토치로 모델 로드하고 저장하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc52676-f026-4566-a226-2a90269f9d53",
   "metadata": {
    "id": "0fc52676-f026-4566-a226-2a90269f9d53"
   },
   "source": [
    "- LLM 훈련에는 계산 비용이 많이 듭니다. 따라서 LLM 가중치를 저장하고 로드하는 것이 중요합니다.\n",
    "\n",
    "<img src=\"images/llm_from_scratch/ch05_compressed/16.webp\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e4c7f9-592f-43d6-a00e-598fa01dfb82",
   "metadata": {
    "id": "10e4c7f9-592f-43d6-a00e-598fa01dfb82"
   },
   "source": [
    "- 파이토치에서는 `torch.save` 함수를 `.state_dict()` 메서드 결과에 적용해 소위 `state_dict`인 모델 가중치를 저장하는 것이 권장됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d67d869-ac04-4382-bcfb-c96d1ca80d47",
   "metadata": {
    "id": "3d67d869-ac04-4382-bcfb-c96d1ca80d47"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"outputs/model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e889e0-07bf-43e5-8f92-5c5c7aeaad9e",
   "metadata": {
    "id": "90e889e0-07bf-43e5-8f92-5c5c7aeaad9e"
   },
   "source": [
    "- 그다음 모델 가중치를 새로운 `GPTModel` 클래스 인스턴스에 로드할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9d57d914-60a3-47f1-b499-5352f4c457cb",
   "metadata": {
    "id": "9d57d914-60a3-47f1-b499-5352f4c457cb"
   },
   "outputs": [],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    # 파이토치 2.9 이상에서는 mps 결과가 안정적입니다.\n",
    "    major, minor = map(int, torch.__version__.split(\".\")[:2])\n",
    "    if (major, minor) >= (2, 9):\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "model.load_state_dict(torch.load(\"outputs/model.pth\", map_location=device, weights_only=True))\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa81aec-9c72-4f46-8ae2-4a4fde3edbc1",
   "metadata": {
    "id": "caa81aec-9c72-4f46-8ae2-4a4fde3edbc1"
   },
   "source": [
    "- 일반적인 SGD 대신 Adam이나 AdamW와 같이 적응형 옵티마이저로 LLM을 훈련하는 것이 일반적입니다.\n",
    "- 이런 적응형 옵티마이저는 모델 가중치마다 추가적인 파라미터를 저장합니다. 나중에 사전 훈련을 계속하려면 이 파라미터도 저장하는 것이 맞습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bbd175bb-edf4-450e-a6de-d3e8913c6532",
   "metadata": {
    "id": "bbd175bb-edf4-450e-a6de-d3e8913c6532"
   },
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    },\n",
    "    \"outputs/model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0c7295-c822-43bf-9286-c45abc542868",
   "metadata": {
    "id": "8a0c7295-c822-43bf-9286-c45abc542868"
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"outputs/model_and_optimizer.pth\", weights_only=True)\n",
    "\n",
    "##모델 weight 로딩\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "## 옵티마이저가 모델 파라미터를 참조\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4194350e-0409-4a63-8ffd-d3a896509032",
   "metadata": {
    "id": "4194350e-0409-4a63-8ffd-d3a896509032"
   },
   "source": [
    "## 5.5 오픈AI에서 사전 훈련된 가중치 로드하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83eb6c38-7278-40e0-bd9f-8a2b1feac3ec",
   "metadata": {
    "id": "83eb6c38-7278-40e0-bd9f-8a2b1feac3ec"
   },
   "source": [
    "- 앞서 하나의 단편 소설로 구성된 작은 데이터셋을 사용해 소규모 GPT-2 모델을 훈련했습니다.\n",
    "- 구텐베르크 프로젝트에 있는 전체 책으로 더 오래 모델을 훈련하고 싶다면 [../03_bonus_pretraining_on_gutenberg](../03_bonus_pretraining_on_gutenberg)을 참고하세요.\n",
    "- 다행히 오픈AI는 GPT-2 모델의 가중치를 공개적으로 제공하기 때문에 대규모 말뭉치에서 모델을 재훈련하기 위해 수만에서 수십만 달러를 쓸 필요가 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "127ddbdb-3878-4669-9a39-d231fbdfb834",
   "metadata": {
    "id": "127ddbdb-3878-4669-9a39-d231fbdfb834",
    "jp-MarkdownHeadingCollapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미 파일이 존재합니다: models/gpt2\\gpt2-small-124M.pth\n",
      "출력 텍스트:\n",
      " Every effort moves you as far as the hand can go until the end of your turn unless something interrupts your control flow. As you may observe I\n"
     ]
    }
   ],
   "source": [
    "def load_gpt2_model(file_name, config):\n",
    "    \"\"\"\n",
    "    GPT2 가중치를 다운로드하고 모델에 로드하는 함수\n",
    "    \"\"\"\n",
    "    # 1. 경로 설정\n",
    "    base_dir = \"models/gpt2\"\n",
    "    os.makedirs(base_dir, exist_ok=True)  # 폴더가 없으면 생성\n",
    "    model_path = os.path.join(base_dir, file_name)\n",
    "    \n",
    "    url = f\"https://huggingface.co/rasbt/gpt2-from-scratch-pytorch/resolve/main/{file_name}\"\n",
    "\n",
    "    # 2. 파일 다운로드 (파일이 없을 때만 실행)\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"'{file_name}' 다운로드 중...\")\n",
    "        with requests.get(url, stream=True) as r:\n",
    "            r.raise_for_status()\n",
    "            with open(model_path, 'wb') as f:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "        print(f\"다운로드 완료: {model_path}\")\n",
    "    else:\n",
    "        print(f\"이미 파일이 존재합니다: {model_path}\")\n",
    "\n",
    "    # 3. 모델 초기화 및 가중치 로드\n",
    "    model = GPTModel(config)\n",
    "    # map_location을 통해 CPU/GPU 환경 대응\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    # model.to(device)\n",
    "    # model.eval() # 평가 모드 전환\n",
    "    \n",
    "    return model\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"drop_rate\": 0.0,       # Dropout rate\n",
    "    \"qkv_bias\": True        # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "# --- 사용 예시 ---\n",
    "model_name = \"gpt2-small-124M.pth\"\n",
    "gpt = load_gpt2_model(model_name, BASE_CONFIG)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    # 파이토치 2.9 이상에서는 mps 결과가 안정적입니다.\n",
    "    major, minor = map(int, torch.__version__.split(\".\")[:2])\n",
    "    if (major, minor) >= (2, 9):\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "gpt.to(device)\n",
    "gpt.eval()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "\n",
    "print(\"출력 텍스트:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6252dbdb-0a12-4781-8942-0c78b7eaa781",
   "metadata": {},
   "source": [
    "- 모델별 차이점\n",
    "<img src=\"images/llm_from_scratch/ch05_compressed/17.webp\" width=700px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d079f98-a7c4-462e-8416-5a64f670861c",
   "metadata": {
    "id": "6d079f98-a7c4-462e-8416-5a64f670861c"
   },
   "source": [
    "- 모델이 일관성 있는 텍스트를 생성했기 때문에 가중치가 올바르게 로드되었다고 확신할 수 있습니다. 이 과정에서 조금만 잘못되어도 모델이 제대로 텍스트를 생성하지 못합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28493b9b-a1ae-4f31-87bc-c10ee4447f44",
   "metadata": {
    "id": "28493b9b-a1ae-4f31-87bc-c10ee4447f44"
   },
   "source": [
    "- 허깅 페이스 허브에서 가중치를 로드하는 방법은 [../02_alternative_weight_loading](../02_alternative_weight_loading)에 있는 노트북을 참고하세요.\n",
    "- GPT 구조와 (메타에서 개발한) Llama 구조를 비교해 보려면 보너스 콘텐츠 [../07_gpt_to_llama](../07_gpt_to_llama)를 참고하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a66474-230d-4180-a8ff-843e04f1f1c4",
   "metadata": {
    "id": "f2a66474-230d-4180-a8ff-843e04f1f1c4"
   },
   "source": [
    "## 요약"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7ed189-a633-458c-bf12-4f70b42684b8",
   "metadata": {
    "id": "fc7ed189-a633-458c-bf12-4f70b42684b8"
   },
   "source": [
    "- [./gpt_train.py](./gpt_train.py)는 훈련 스크립트 파일입니다.\n",
    "- [./gpt_generate.py](./gpt_generate.py)는 OpenAI에서 사전 훈련된 가중치를 로드하여 프롬프트를 기반으로 텍스트를 생성합니다.\n",
    "- 연습문제 솔루션은 [./exercise-solutions.ipynb](./exercise-solutions.ipynb)에 있습니다."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
