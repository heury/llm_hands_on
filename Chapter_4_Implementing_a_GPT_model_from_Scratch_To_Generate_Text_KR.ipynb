{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa4dab80",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/rickiepark/llm-from-scratch/blob/main/ch04/01_main-chapter-code/ch04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f4321d-d32a-4a90-bfc7-e923f316b2f8",
   "metadata": {
    "id": "08f4321d-d32a-4a90-bfc7-e923f316b2f8"
   },
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<font size=\"2\">\n",
    "세바스찬 라시카(Sebastian Raschka)가 쓴 <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a>의 번역서 <br><<b><a href=\"<a href=\"http://tensorflow.blog/llm-from-scratch\">밑바닥부터 만들면서 배우는 LLM</a></b>>의 예제 코드입니다.<br>\n",
    "<br>코드 저장소: <a href=\"https://github.com/rickiepark/llm-from-scratch\">https://github.com/rickiepark/llm-from-scratch</a>\n",
    "</font>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<a href=\"http://tensorflow.blog/llm-from-scratch\"><img src=\"https://tensorflowkorea.wordpress.com/wp-content/uploads/2025/09/ebb091ebb094eb8ba5llm_ebb3b8ecb185_ec959eeba9b4.jpg\" width=\"100px\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9295b2-182b-490b-8325-83a67c4a001d",
   "metadata": {
    "id": "ce9295b2-182b-490b-8325-83a67c4a001d"
   },
   "source": [
    "# 4장: 밑바닥부터 GPT 모델 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9eac223-a125-40f7-bacc-bd0d890450c7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f9eac223-a125-40f7-bacc-bd0d890450c7",
    "outputId": "fa31d4bb-ced7-4ce4-f829-5511df4756aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "맷플롯립 버전: 3.10.8\n",
      "파이토치 버전: 2.9.1+cu126\n",
      "tiktoken 버전: 0.12.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "print(\"맷플롯립 버전:\", version(\"matplotlib\"))\n",
    "print(\"파이토치 버전:\", version(\"torch\"))\n",
    "print(\"tiktoken 버전:\", version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7da97ed-e02f-4d7f-b68e-a0eba3716e02",
   "metadata": {
    "id": "e7da97ed-e02f-4d7f-b68e-a0eba3716e02"
   },
   "source": [
    "- 이 장에서 GPT와 유사한 LLM 구조를 구현합니다. 다음 장에서는 이 LLM 훈련하는데 초점을 맞추겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4f11e0-4434-4979-9dee-e1207df0eb01",
   "metadata": {
    "id": "7d4f11e0-4434-4979-9dee-e1207df0eb01"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch04_compressed/01.webp\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fe99ab-0bcf-4778-a6b5-6db81fb826ef",
   "metadata": {
    "id": "53fe99ab-0bcf-4778-a6b5-6db81fb826ef"
   },
   "source": [
    "## 4.1 구조 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad72d1ff-d82d-4e33-a88e-3c1a8831797b",
   "metadata": {
    "id": "ad72d1ff-d82d-4e33-a88e-3c1a8831797b"
   },
   "source": [
    "- 1장은 GPT와 Llama 같은 모델을 소개했습니다. 이런 모델은 원본 트랜스포머 구조의 디코더 부분을 기반으로 순차적으로 단어를 생성합니다.\n",
    "- 따라서 이런 LLM을 종종 디코더 기반 LLM이라 부릅니다.\n",
    "- 전통적인 딥러닝 모델과 비교하면 LLM은 규모가 큽니다. 이는 코드의 양이 아니라 방대한 파라미터 개수 때문입니다.\n",
    "- 앞으로 보겠지만 LLM 구조의 많은 구성 요소가 반복적입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5213e9-bd1c-437e-aee8-f5e8fb717251",
   "metadata": {
    "id": "5c5213e9-bd1c-437e-aee8-f5e8fb717251"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch04_compressed/02.webp\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d43f5e2-fb51-434a-b9be-abeef6b98d99",
   "metadata": {
    "id": "0d43f5e2-fb51-434a-b9be-abeef6b98d99"
   },
   "source": [
    "- 이전 장에서 설명의 편의를 위해 토큰 입력과 출력의 임베딩 차원을 작게 했습니다.\n",
    "- 이 장에서는 작은 GPT-2 모델와 같은 임베딩 크기를 사용합니다.\n",
    "- 구체적으로 Radford et al.'s [Language Models are Unsupervised Multitask Learners](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)에 나온 가장 작은 GPT-2 모델 구조(1억 2,400만 파라미터)를 구현하겠습니다(처음에는 1억 1,700만 파라미터라고 보고되었지만 나중에 모델 저장소에 수정된 값으로 공개되었습니다).\n",
    "- 여기서 구현한 모델은 3억 4,500만 파라미터, 7억 6,200만 파라미터, 15억 4,200만 파라미터를 가진 모델과 호환됩니다. 5장에서 이 구현에 사전 훈련된 가중치를 로드하는 방법을 알아 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21baa14d-24b8-4820-8191-a2808f7fbabc",
   "metadata": {
    "id": "21baa14d-24b8-4820-8191-a2808f7fbabc"
   },
   "source": [
    "- 1억 2,400만 파라미터 GPT-2 모델의 설정은 다음과 같습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ed66875-1f24-445d-add6-006aae3c5707",
   "metadata": {
    "id": "5ed66875-1f24-445d-add6-006aae3c5707"
   },
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # 어휘사전 크기\n",
    "    \"context_length\": 1024, # 문맥 길이\n",
    "    \"emb_dim\": 768,         # 임베딩 차원\n",
    "    \"n_heads\": 12,          # 어텐션 헤드 개수\n",
    "    \"n_layers\": 12,         # 층 개수\n",
    "    \"drop_rate\": 0.1,       # 드롭아웃 비율\n",
    "    \"qkv_bias\": False       # 쿼리, 키, 값을 만들 때 편향 포함 여부\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12fcd28-d210-4c57-8be6-06cfcd5d73a4",
   "metadata": {
    "id": "c12fcd28-d210-4c57-8be6-06cfcd5d73a4"
   },
   "source": [
    "- `\"vocab_size\"`는 BPE 토크나이저(2장 참조)에서 사용할 50,257 토큰으로 구성된 어휘 사전 크기를 나타냅니다.\n",
    "- `\"context_length\"`는 위치 임베딩(2장 참조)으로 모델이 다룰 수 있는 입력 토큰의 최대 개수입니다.\n",
    "- `\"emb_dim\"`은 임베딩 크기를 나타내며, 각 토큰을 768 차원의 벡터로 변환합니다.\n",
    "- `\"n_heads\"`는 멀티 헤드 어텐션 메커니즘(3장 참조)에 있는 어텐션 헤드의 개수입니다.\n",
    "- `\"n_layers\"`에는 모델에 있는 (이 장에서 소개할) 트랜스포머 블록의 개수를 지정합니다.\n",
    "- `\"drop_rate\"`는 과대적합을 막기 위한 드롭아웃 메커니즘(3장 참조)의 강도를 지정합니다(0.1은 은닉 유닛의 10%를 랜덤하게 제외한다는 의미입니다).\n",
    "- `\"qkv_bias\"`는 멀티 헤드 어텐션의 Linear 층에서 쿼리, 키, 값을 계산할 때 편향 유닛을 도입할지 여부를 결정합니다. 현대적인 LLM의 구성 방식을 따라서 처음에는 이 값을 비활성화하지만 오픈AI의 사전 훈련된 GPT-2 가중치를 모델로 로드할 때 이를 다시 살펴 보겠습니다(5장 참조)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adce779-857b-4418-9501-12a7f3818d88",
   "metadata": {
    "id": "4adce779-857b-4418-9501-12a7f3818d88"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch04_compressed/03.webp\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619c2eed-f8ea-4ff5-92c3-feda0f29b227",
   "metadata": {
    "id": "619c2eed-f8ea-4ff5-92c3-feda0f29b227"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DummyGPTModel(nn.Module):\n",
    "    \"\"\"\n",
    "    GPT 모델의 전체 구조를 정의하는 클래스입니다.\n",
    "    실제 연산(Attention 등)은 제외하고, 데이터의 흐름과 입출력 차원을 맞추는 구조만 구현되어 있습니다.\n",
    "    \"\"\"\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 1. 토큰 임베딩 (Token Embedding)\n",
    "        # 입력된 단어 ID(정수)를 벡터(실수)로 변환합니다.\n",
    "        # 크기: [vocab_size, emb_dim] (예: 50257개 단어, 768차원)\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        \n",
    "        # 2. 위치 임베딩 (Position Embedding)\n",
    "        # Transformer는 순서 정보가 없으므로, 단어의 위치 정보를 벡터로 학습하여 더해줍니다.\n",
    "        # 크기: [context_length, emb_dim] (예: 최대 1024개 위치, 768차원)\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        \n",
    "        # 3. 드롭아웃 (Dropout)\n",
    "        # 과적합(Overfitting)을 방지하기 위해 임베딩 값의 일부를 무작위로 0으로 만듭니다.\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        # 4. 트랜스포머 블록 (Transformer Blocks)\n",
    "        # 실제 GPT의 핵심 연산(Self-Attention + Feed Forward)이 일어나는 층을 여러 개 쌓습니다.\n",
    "        # 여기서는 더미(Dummy) 블록을 사용하여 구조만 잡았습니다.\n",
    "        # * (Asterisk)는 리스트의 요소를 풀어서(unpacking) 인자로 전달합니다.\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "\n",
    "        # 5. 최종 정규화 (Final LayerNorm)\n",
    "        # 블록들을 통과한 후, 데이터 분포를 안정화하기 위한 정규화 층입니다.\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
    "        \n",
    "        # 6. 출력 헤드 (Output Head)\n",
    "        # 최종 벡터를 다시 단어 집합 크기(vocab_size)로 변환하여,\n",
    "        # 다음에 올 단어의 확률(Logits)을 계산합니다.\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        # in_idx: 입력 데이터 (배치 크기, 시퀀스 길이) -> 예: [Batch, Seq_Len]\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        \n",
    "        # A. 토큰 임베딩 변환\n",
    "        # 입력: [Batch, Seq_Len] -> 출력: [Batch, Seq_Len, Emb_Dim]\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        \n",
    "        # B. 위치 임베딩 생성\n",
    "        # 0부터 seq_len-1까지의 숫자를 생성하여 위치 벡터로 변환합니다.\n",
    "        # device=in_idx.device는 입력 데이터와 같은 장치(CPU/GPU)를 쓰기 위함입니다.\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        \n",
    "        # C. 임베딩 합산 (Input Embedding)\n",
    "        # 토큰 정보와 위치 정보를 더해줍니다. (브로드캐스팅에 의해 배치 내 모든 샘플에 동일하게 더해짐)\n",
    "        x = tok_embeds + pos_embeds\n",
    "        \n",
    "        # D. 드롭아웃 적용\n",
    "        x = self.drop_emb(x)\n",
    "        \n",
    "        # E. 트랜스포머 블록 통과\n",
    "        # 여러 층의 블록을 순차적으로 통과하며 특징을 추출합니다.\n",
    "        x = self.trf_blocks(x)\n",
    "        \n",
    "        # F. 최종 정규화\n",
    "        x = self.final_norm(x)\n",
    "        \n",
    "        # G. 다음 단어 예측 (Logits 산출)\n",
    "        # 출력: [Batch, Seq_Len, Vocab_Size]\n",
    "        logits = self.out_head(x)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    실제로는 Multi-Head Attention과 FeedForward Network가 들어가는 곳입니다.\n",
    "    구조 파악을 위해 입력을 그대로 반환하는 더미 클래스로 대체되었습니다.\n",
    "    \"\"\"\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        # 실제 구현에서는 여기에 Attention, MLP, LayerNorm 등이 정의됩니다.\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 아무런 연산도 수행하지 않고 입력을 그대로 다음 층으로 넘깁니다.\n",
    "        return x\n",
    "\n",
    "\n",
    "class DummyLayerNorm(nn.Module):\n",
    "    \"\"\"\n",
    "    Layer Normalization을 흉내 내는 더미 클래스입니다.\n",
    "    실제로는 평균과 분산을 이용해 데이터를 정규화합니다.\n",
    "    \"\"\"\n",
    "    def __init__(self, normalized_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "        # 실제 LayerNorm과 인터페이스(파라미터 입력 방식)를 맞추기 위한 초기화입니다.\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 아무런 연산도 수행하지 않고 입력을 그대로 반환합니다.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9665e8ab-20ca-4100-b9b9-50d9bdee33be",
   "metadata": {
    "id": "9665e8ab-20ca-4100-b9b9-50d9bdee33be"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch04_compressed/04.webp\" width=\"650px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794b6b6c-d36f-411e-a7db-8ac566a87fee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "794b6b6c-d36f-411e-a7db-8ac566a87fee",
    "outputId": "d72d0378-137a-45ba-c0bd-835e753b32ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import torch  # PyTorch 라이브러리 (텐서 연산을 위해 필요)\n",
    "import tiktoken  # OpenAI의 BPE 토크나이저 라이브러리\n",
    "\n",
    "# 1. 토크나이저 초기화\n",
    "# GPT-2 모델이 사용하는 인코딩 방식('gpt2')을 로드합니다.\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "# 데이터를 모을 빈 리스트 생성\n",
    "batch = []\n",
    "\n",
    "# 2. 예제 데이터 준비\n",
    "# 처리할 문장 두 개를 정의합니다.\n",
    "# 주의: torch.stack을 사용하려면 두 문장의 토큰 길이가 같아야 합니다.\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "\n",
    "# 3. 인코딩 및 텐서 변환\n",
    "# 과정: 텍스트 -> 토큰 ID 리스트(encode) -> 파이토치 텐서(tensor) -> 리스트에 추가(append)\n",
    "# txt1을 토큰화하여 텐서로 변환 후 batch 리스트에 담습니다.\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "\n",
    "# txt2도 동일하게 처리하여 batch 리스트에 담습니다.\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "\n",
    "# 4. 배치 생성 (Stacking)\n",
    "# 현재 batch는 [tensor([..]), tensor([..])] 형태의 리스트입니다.\n",
    "# 이를 하나의 큰 텐서(행렬)로 합칩니다. dim=0은 세로 방향(행)으로 쌓겠다는 의미입니다.\n",
    "# 결과 Shape 예상: [2, 4] (2개의 문장, 각 문장은 4개의 토큰)\n",
    "batch = torch.stack(batch, dim=0)\n",
    "\n",
    "# 결과 출력\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009238cd-0160-4834-979c-309710986bb0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "009238cd-0160-4834-979c-309710986bb0",
    "outputId": "81c71a9d-d518-4df6-fbfd-0411eb788b91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출력 크기: torch.Size([2, 4, 50257])\n",
      "tensor([[[-1.2034,  0.3201, -0.7130,  ..., -1.5548, -0.2390, -0.4667],\n",
      "         [-0.1192,  0.4539, -0.4432,  ...,  0.2392,  1.3469,  1.2430],\n",
      "         [ 0.5307,  1.6720, -0.4695,  ...,  1.1966,  0.0111,  0.5835],\n",
      "         [ 0.0139,  1.6754, -0.3388,  ...,  1.1586, -0.0435, -1.0400]],\n",
      "\n",
      "        [[-1.0908,  0.1798, -0.9484,  ..., -1.6047,  0.2439, -0.4530],\n",
      "         [-0.7860,  0.5581, -0.0610,  ...,  0.4835, -0.0077,  1.6621],\n",
      "         [ 0.3567,  1.2698, -0.6398,  ..., -0.0162, -0.1296,  0.3717],\n",
      "         [-0.2407, -0.7349, -0.5102,  ...,  2.0057, -0.3694,  0.1814]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 1. 랜덤 시드 고정\n",
    "# 실행할 때마다 결과가 달라지지 않도록 난수 생성기의 초기값을 '123'으로 고정합니다.\n",
    "# (디버깅이나 학습용 예제에서 결과를 재현하기 위해 필수적입니다.)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# 2. 모델 인스턴스 생성\n",
    "# GPT-2(124M 버전)의 설정값(GPT_CONFIG_124M)을 사용하여 모델을 만듭니다.\n",
    "# 'Dummy'라는 이름에서 알 수 있듯이, 아직 학습되지 않은(랜덤 가중치를 가진) 껍데기 모델일 가능성이 높습니다.\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "# 3. 순전파 (Forward Pass) 실행\n",
    "# 앞서 만든 데이터(batch)를 모델에 통과시켜 예측값을 계산합니다.\n",
    "# 반환된 'logits'는 확률로 변환되기 전의 원시 점수(Score)입니다.\n",
    "logits = model(batch)\n",
    "\n",
    "# 4. 결과 확인\n",
    "# 출력 텐서의 형태(Shape)를 확인합니다.\n",
    "# 예상 형태: [배치 크기, 문장 길이, 단어 사전 크기] -> 예: [2, 4, 50257]\n",
    "print(\"출력 크기:\", logits.shape)\n",
    "\n",
    "# 실제 계산된 텐서 값들을 출력합니다.\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8332a00-98da-4eb4-b882-922776a89917",
   "metadata": {
    "id": "f8332a00-98da-4eb4-b882-922776a89917"
   },
   "source": [
    "## 4.2 층 정규화로 활성화 정규화하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066cfb81-d59b-4d95-afe3-e43cf095f292",
   "metadata": {
    "id": "066cfb81-d59b-4d95-afe3-e43cf095f292"
   },
   "source": [
    "- LayerNorm([Ba et al. 2016](https://arxiv.org/abs/1607.06450))이라고도 불리는 층 정규화는 신경망 층의 활성화를 평균이 0이고 분산이 1이 되도록 조정합니다.\n",
    "- 이를 통해 훈련을 안정화하고 가중치 수렴 속도를 높일 수 있습니다.\n",
    "- 나중에 구현하겠지만 층 정규화는 트랜스포머 블록의 멀티 헤드 어텐션 모듈 전후에 적용됩니다. 또한 최종 출력 층 전에도 적용됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314ac47a-69cc-4597-beeb-65bed3b5910f",
   "metadata": {
    "id": "314ac47a-69cc-4597-beeb-65bed3b5910f"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch04_compressed/05.webp\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab49940-6b35-4397-a80e-df8d092770a7",
   "metadata": {
    "id": "5ab49940-6b35-4397-a80e-df8d092770a7"
   },
   "source": [
    "- 작은 입력 샘플을 간단한 신경망 층에 통과시켜 층 정규화의 작동 방식을 알아 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e1b463-dc3f-44ac-9cdb-9d5b6f64eb9d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "79e1b463-dc3f-44ac-9cdb-9d5b6f64eb9d",
    "outputId": "9b869c41-3167-443d-a9d0-03965a10d01a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 1. 랜덤 시드 고정\n",
    "# 매번 실행할 때마다 같은 랜덤 값이 나오도록 설정하여 결과를 재현할 수 있게 합니다.\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# 2. 입력 데이터(Batch) 생성\n",
    "# 형태(Shape): [2, 5] -> (배치 크기=2, 입력 특징의 개수=5)\n",
    "# 예: 5가지 속성을 가진 데이터 샘플이 2개 있다는 의미입니다.\n",
    "batch_example = torch.randn(2, 5) \n",
    "\n",
    "# 3. 신경망 층(Layer) 정의\n",
    "# nn.Sequential은 여러 모듈을 순서대로 묶어주는 컨테이너입니다.\n",
    "layer = nn.Sequential(\n",
    "    # (1) 선형 변환 (Linear Layer): \n",
    "    # 입력 차원 5개를 받아 -> 6개의 차원으로 확장/변환합니다.\n",
    "    # 내부 연산: Output = Input x Weight + Bias\n",
    "    nn.Linear(5, 6), \n",
    "    \n",
    "    # (2) 활성화 함수 (ReLU):\n",
    "    # 선형 변환된 값에서 음수는 0으로 만들고, 양수는 그대로 둡니다.\n",
    "    # 비선형성을 추가하여 모델이 복잡한 패턴을 학습할 수 있게 돕습니다.\n",
    "    nn.ReLU()\n",
    ")\n",
    "\n",
    "# 4. 순전파 (Forward Pass)\n",
    "# 데이터를 층에 통과시킵니다.\n",
    "# 입력 [2, 5] -> Linear 거침 -> [2, 6] -> ReLU 거침 -> 최종 [2, 6]\n",
    "out = layer(batch_example)\n",
    "\n",
    "# 5. 결과 출력\n",
    "# 결과 형태는 [2, 6]이 됩니다. (2개의 샘플, 각 샘플당 6개의 특징값)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fccc29e-71fc-4c16-898c-6137c6ea5d2e",
   "metadata": {
    "id": "8fccc29e-71fc-4c16-898c-6137c6ea5d2e"
   },
   "source": [
    "- 두 개의 입력에 대해 각각 평균과 분산을 계산해 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9888f79e-8e69-44aa-8a19-cd34292adbf5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9888f79e-8e69-44aa-8a19-cd34292adbf5",
    "outputId": "4ee025db-a9b4-4892-8bfd-7335760f5b14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균:\n",
      " tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>)\n",
      "분산:\n",
      " tensor([[0.0231],\n",
      "        [0.0398]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 1. 평균(Mean) 계산\n",
    "# dim=-1: 가장 마지막 차원(여기서는 6개의 특성 값)을 기준으로 평균을 냅니다.\n",
    "#         즉, \"각 샘플(행)마다\" 가지고 있는 6개 숫자의 평균을 구합니다.\n",
    "# keepdim=True: 계산 후 차원을 없애지 않고 유지합니다.\n",
    "#               입력 [2, 6] -> 결과 [2, 1] (이 옵션이 없으면 [2]가 됨)\n",
    "mean = out.mean(dim=-1, keepdim=True)\n",
    "\n",
    "# 2. 분산(Variance) 계산\n",
    "# 데이터가 평균으로부터 얼마나 퍼져있는지(변동성)를 계산합니다.\n",
    "# 옵션은 평균 계산과 동일하게 마지막 차원을 기준으로 차원을 유지하며 계산합니다.\n",
    "var = out.var(dim=-1, keepdim=True)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"평균:\\n\", mean)\n",
    "print(\"분산:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052eda3e-b395-48c4-acd4-eb8083bab958",
   "metadata": {
    "id": "052eda3e-b395-48c4-acd4-eb8083bab958"
   },
   "source": [
    "- 정규화는 두 입력(행)에 대해 독립적으로 적용됩니다. dim=-1을 사용하면 행 차원이 아니라 마지막 차원(이 경우 특성 차원)을 따라 계산이 수행됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570db83a-205c-4f6f-b219-1f6195dde1a7",
   "metadata": {
    "id": "570db83a-205c-4f6f-b219-1f6195dde1a7"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch04_compressed/06.webp\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8ecbc7-eb14-4fa1-b5d0-7e1ff9694f99",
   "metadata": {
    "id": "9f8ecbc7-eb14-4fa1-b5d0-7e1ff9694f99"
   },
   "source": [
    "- 평균을 빼고, 분산의 제곱근(표준편차)으로 나누면 입력을 열(특성) 차원을 따라 평균이 0이고 분산이 1이 되도록 만듭니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1d1bb9-3341-4c9a-bc2a-d2489bf89cda",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9a1d1bb9-3341-4c9a-bc2a-d2489bf89cda",
    "outputId": "e9dded6c-f611-4ea7-9638-12b758c2fae3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화된 층 출력:\n",
      " tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
      "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "평균:\n",
      " tensor([[9.9341e-09],\n",
      "        [5.9605e-08]], grad_fn=<MeanBackward1>)\n",
      "분산:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 1. 정규화 (Normalization) 수행\n",
    "# 공식: (입력값 - 평균) / 표준편차\n",
    "# torch.sqrt(var)는 분산의 제곱근이므로 '표준편차'가 됩니다.\n",
    "# 이 과정을 거치면 데이터의 중심이 0으로 이동하고, 퍼짐 정도가 1로 맞춰집니다.\n",
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "\n",
    "print(\"정규화된 층 출력:\\n\", out_norm)\n",
    "\n",
    "# 2. 결과 검증 (Verification)\n",
    "# 정규화가 제대로 되었다면,\n",
    "# 다시 구한 평균은 0에 매우 가깝고, 분산은 1에 매우 가까워야 합니다.\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "\n",
    "# 3. 검증 결과 출력\n",
    "# e-08 등의 표현이 나온다면 0에 아주 가까운 숫자라는 뜻입니다. (부동소수점 오차 감안)\n",
    "print(\"평균 (0에 가까워야 함):\\n\", mean)\n",
    "print(\"분산 (1에 가까워야 함):\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac62b90c-7156-4979-9a79-ce1fb92969c1",
   "metadata": {
    "id": "ac62b90c-7156-4979-9a79-ce1fb92969c1"
   },
   "source": [
    "- 각 입력의 평균은 0이고 분산은 1입니다. 결과를 보기 쉽도록 파이토치의 과학적 표기법을 끌 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e06c34b-c68a-4b36-afbe-b30eda4eca39",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3e06c34b-c68a-4b36-afbe-b30eda4eca39",
    "outputId": "17558a93-8dbf-4e25-8dfd-0b07418eb79c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균:\n",
      " tensor([[0.0000],\n",
      "        [0.0000]], grad_fn=<MeanBackward1>)\n",
      "분산:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "print(\"평균:\\n\", mean)\n",
    "print(\"분산:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944fb958-d4ed-43cc-858d-00052bb6b31a",
   "metadata": {
    "id": "944fb958-d4ed-43cc-858d-00052bb6b31a"
   },
   "source": [
    "- 위에서 각 입력의 특성을 정규화했습니다.\n",
    "- 이제 동일한 아이디어를 사용해 `LayerNorm` 클래스를 구현해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3333a305-aa3d-460a-bcce-b80662d464d9",
   "metadata": {
    "id": "3333a305-aa3d-460a-bcce-b80662d464d9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        # 1. 엡실론 (Epsilon) 정의\n",
    "        # 분산이 0이 되어 나눗셈 에러(Division by Zero)가 발생하는 것을 막기 위한 아주 작은 수입니다.\n",
    "        self.eps = 1e-5\n",
    "        \n",
    "        # 2. 학습 가능한 파라미터 (Scale & Shift)\n",
    "        # 단순히 정규화만 하면 모델의 표현력이 제한될 수 있습니다.\n",
    "        # 모델이 필요에 따라 데이터의 분포를 다시 조정할 수 있도록 '가중치'를 줍니다.\n",
    "        \n",
    "        # Scale (Gamma): 1로 초기화 (곱해도 값 변화 없음)\n",
    "        # nn.Parameter로 감싸야 역전파(Backprop) 때 학습(업데이트)이 됩니다.\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        \n",
    "        # Shift (Beta): 0으로 초기화 (더해도 값 변화 없음)\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 3. 통계량 계산\n",
    "        # 입력 데이터(x)의 마지막 차원(특성)을 기준으로 평균을 구합니다.\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        \n",
    "        # 분산을 구합니다.\n",
    "        # unbiased=False: 표본 분산(n-1로 나눔)이 아닌 모분산(n으로 나눔) 공식을 사용합니다.\n",
    "        # (딥러닝에서는 보통 n으로 나누는 방식을 선호합니다)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False) \n",
    "        \n",
    "        # 4. 정규화 (Normalization)\n",
    "        # (입력 - 평균) / sqrt(분산 + 엡실론)\n",
    "        # 데이터의 평균을 0, 분산을 1로 맞춥니다.\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        \n",
    "        # 5. 아핀 변환 (Affine Transformation)\n",
    "        # 정규화된 값에 학습된 스케일을 곱하고 시프트를 더해 최종 출력을 만듭니다.\n",
    "        # 이를 통해 모델은 정규화된 상태를 유지할지, 원래 데이터 특성을 살릴지 스스로 학습합니다.\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56c3908-7544-4808-b8cb-5d0a55bcca72",
   "metadata": {
    "id": "e56c3908-7544-4808-b8cb-5d0a55bcca72"
   },
   "source": [
    "**스케일 조정과 이동**\n",
    "\n",
    "- 평균을 빼고, 분산으로 나누어 정규화하는 것 이외에 두 개의 훈련 가능한 파라미터 `scale`과 `shift`를 추가했습니다.\n",
    "- 초기 `scale`(1)과 `shift`(0)은 아무런 영향을 미치지 못합니다. 하지만 `scale`과 `shift`가 훈련 가능한 파라미터이기 때문에 훈련 과정에서 두 파라미터를 조정하는 것이 훈련 작업에서 모델의 성능을 향상시킨다고 판단하는 경우 LLM이 자동으로 조정합니다.\n",
    "- 이를 통해 모델은 처리하는 데이터에 가잘 잘 맞는 스케일 조정과 이동을 학습할 수 있습니다.\n",
    "- 분산의 제곱근을 계산할 때 작은 값(`eps`)를 더합니다. 이는 분산이 0일 경우 0 나눗셈 오류를 방지하기 위해서입니다.\n",
    "\n",
    "**편향된 분산**\n",
    "- 위 분산 계산에서 `unbiased=False`는 $\\frac{\\sum_i (x_i - \\bar{x})^2}{n}$ 식으로 분산을 계산한다는 의미입니다. `n`은 샘플 크기입니다(여기서는 특성 또는 열 개수). 이 공식은 (분모가 `n-1`인) 베셀 보정(Bessel's correction)을 사용하지 않습니다. 따라서 편향된 분산을 추정합니다.\n",
    "- LLM에서 임베딩 차원 `n`은 매우 크므로 `n`과 `n-1`을 사용하는 차이는 무시할 수 있습니다.\n",
    "- 하지만 GPT-2가 정규화 층에 편향된 분산을 사용했으므로 나중에 사전 훈련된 가중치를 로드할 때 호환성을 위해 동일한 방식을 적용했습니다.\n",
    "- 이제 `LayerNorm`을 실제로 테스트해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23b1000a-e613-4b43-bd90-e54deed8d292",
   "metadata": {
    "id": "23b1000a-e613-4b43-bd90-e54deed8d292"
   },
   "outputs": [],
   "source": [
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln = ln(batch_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94c12de2-1cab-46e0-a099-e2e470353bff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "94c12de2-1cab-46e0-a099-e2e470353bff",
    "outputId": "b49dc597-2e56-4caf-b18e-527caabe3232"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균:\n",
      " tensor([[-0.0000],\n",
      "        [ 0.0000]], grad_fn=<MeanBackward1>)\n",
      "분산:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
    "\n",
    "print(\"평균:\\n\", mean)\n",
    "print(\"분산:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e136cfc4-7c89-492e-b120-758c272bca8c",
   "metadata": {
    "id": "e136cfc4-7c89-492e-b120-758c272bca8c"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch04_compressed/07.webp\" width=\"700px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11190e7d-8c29-4115-824a-e03702f9dd54",
   "metadata": {
    "id": "11190e7d-8c29-4115-824a-e03702f9dd54"
   },
   "source": [
    "## 4.3 GELU 활성화 함수를 사용하는 피드 포워드 네트워크 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0585dfb-f21e-40e5-973f-2f63ad5cb169",
   "metadata": {
    "id": "b0585dfb-f21e-40e5-973f-2f63ad5cb169"
   },
   "source": [
    "- 이 절에서 LLM의 트랜스포머 블록에서 사용되는 작은 신경망 모듈을 구현합니다.\n",
    "- 딥러닝에서는 ReLU(Rectified Linear Unit) 활성화 함수가 간단하며 다양한 신경망 구조에서 효과적이기 때문에 널리 사용됩니다.\n",
    "- LLM에서는 전통적인 ReLU 외에도 다양한 종류의 활성화 함수가 사용됩니다. 대표적인 두 개의 함수는 GELU(Gaussian Error Linear Unit)와 SwiGLU(Swish-Gated Linear Unit)입니다.\n",
    "- GELU와 SwiGLU는 각각 가우스 오차 함수와 시그모이드 GLU(gated linear unit)을 사용한 더 복잡하고 부드러운 활성화 함수입니다. 간단한 ReLU와 달리 딥러닝 모델의 성능을 향상시킵니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d482ce7-e493-4bfc-a820-3ea99f564ebc",
   "metadata": {
    "id": "7d482ce7-e493-4bfc-a820-3ea99f564ebc"
   },
   "source": [
    "- GELU 활성화 함수([Hendrycks and Gimpel 2016](https://arxiv.org/abs/1606.08415))는 여러 방법으로 구현할 수 있습니다. 정확한 정의는 GELU(x) = x⋅𝛷(x)입니다. 여기서 𝛷(x)는 표준 가우스 누적 분포 함수(가우스 오차 함수)입니다.\n",
    "- 실제로는 계산하기 쉬운 근사식으로 구현합니다: $\\text{GELU}(x) \\approx 0.5 \\cdot x \\cdot \\left(1 + \\tanh\\left[\\sqrt{\\frac{2}{\\pi}} \\cdot \\left(x + 0.044715 \\cdot x^3\\right)\\right]\\right)\n",
    "$ (원본 GPT-2 모델도 커브 피팅(curve fitting)으로 찾은 이 근사식을 사용했습니다)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84694b7-95f3-4323-b6d6-0a73df278e82",
   "metadata": {
    "id": "f84694b7-95f3-4323-b6d6-0a73df278e82"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # GELU는 학습해야 할 가중치(Parameter)가 없는 수학적 함수입니다.\n",
    "        # 따라서 초기화 함수(__init__)에서는 별다른 설정이 필요 없습니다.\n",
    "\n",
    "    def forward(self, x):\n",
    "        # GELU의 'tanh 근사 공식' 구현\n",
    "        # 원래 공식은 정규분포의 누적분포함수(CDF)를 사용하지만 계산 비용이 비쌉니다.\n",
    "        # 따라서 아래와 같이 tanh를 사용한 근사식을 주로 사용합니다.\n",
    "        # 식: 0.5 * x * (1 + tanh( sqrt(2/pi) * (x + 0.044715 * x^3) ))\n",
    "        \n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            # sqrt(2/pi)는 약 0.7978 정도 되는 상수입니다.\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * # 0.044715는 근사 오차를 최소화하기 위해 수학적으로 유도된 계수입니다.\n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc5487d2-2576-4118-80a7-56c4caac2e71",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "fc5487d2-2576-4118-80a7-56c4caac2e71",
    "outputId": "31c14496-f8b6-42b4-9e61-9a7312cb04b8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "\n",
    "# 샘플 데이터\n",
    "x = torch.linspace(-3, 3, 100)\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
    "    plt.subplot(1, 2, i)\n",
    "    plt.plot(x, y)\n",
    "    plt.title(f\"{label} activation function\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(f\"{label}(x)\")\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd01662-14cb-43fd-bffd-2d702813de2d",
   "metadata": {
    "id": "1cd01662-14cb-43fd-bffd-2d702813de2d"
   },
   "source": [
    "- 여기서 보듯이 ReLU는 양수는 그대로 출력하고 음수는 모두 0을 출력하는 구간별 선형 함수(piecewise linear function)입니다.\n",
    "- GELU는 부드러운 비선형 함수로, ReLU와 비슷하지만 모든 음수 값의 그레이디언트를 0으로 만들지 않습니다(대략 x = -0.75에서는 그레이디언트가 0이 됩니다).\n",
    "- 그다음 LLM의 트랜스포머 블록에 사용할 작은 신경망 모듈인 `FeedForward`를 구현해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9275c879-b148-4579-a107-86827ca14d4d",
   "metadata": {
    "id": "9275c879-b148-4579-a107-86827ca14d4d"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        \n",
    "        # nn.Sequential: 여러 층(Layer)을 순서대로 묶어서 실행하는 컨테이너입니다.\n",
    "        self.layers = nn.Sequential(\n",
    "            \n",
    "            # 1. 확장 단계 (Expansion)\n",
    "            # 입력 차원(emb_dim)을 4배로 뻥튀기합니다.\n",
    "            # 예: 768 -> 3072 (GPT-2 small 기준)\n",
    "            # 이유: 차원을 넓혀서 더 풍부하고 복잡한 특징을 학습하기 위함입니다.\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            \n",
    "            # 2. 활성화 함수 (GELU)\n",
    "            # 앞서 구현한 GELU 함수를 사용하여 비선형성을 추가합니다.\n",
    "            # 0보다 작은 값을 부드럽게 처리하여 학습 안정성을 높입니다.\n",
    "            GELU(),\n",
    "            \n",
    "            # 3. 압축/복원 단계 (Projection)\n",
    "            # 4배로 늘어났던 차원을 다시 원래 크기(emb_dim)로 줄입니다.\n",
    "            # 예: 3072 -> 768\n",
    "            # 이유: 다음 레이어나 블록으로 데이터를 넘겨주기 위해 입출력 크기를 맞춰야 합니다.\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 정의된 순서대로(Linear -> GELU -> Linear) 데이터를 통과시킵니다.\n",
    "        # 입력 x와 출력의 형태(Shape)는 동일하게 유지됩니다. (배치, 시퀀스, 임베딩 차원)\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c4976e2-0261-418e-b042-c5be98c2ccaf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7c4976e2-0261-418e-b042-c5be98c2ccaf",
    "outputId": "d609a4c9-2a11-4609-f748-2baead3b6bb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "print(GPT_CONFIG_124M[\"emb_dim\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcaacfa-3cfc-4c9e-b668-b71a2753145a",
   "metadata": {
    "id": "fdcaacfa-3cfc-4c9e-b668-b71a2753145a"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch04_compressed/09.webp\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "928e7f7c-d0b1-499f-8d07-4cadb428a6f9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "928e7f7c-d0b1-499f-8d07-4cadb428a6f9",
    "outputId": "a204a71c-277c-477b-c25a-2d6478971272"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "\n",
    "# 입력 크기: [batch_size, num_token, emb_size]\n",
    "x = torch.rand(2, 3, 768)\n",
    "out = ffn(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d779e0",
   "metadata": {},
   "source": [
    "입력에서 필요한 정보를 추출할 때 좀 더 잘 추출하기 위해 뻥튀기를 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8756c5-6b04-443b-93d0-e555a316c377",
   "metadata": {
    "id": "8f8756c5-6b04-443b-93d0-e555a316c377"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch04_compressed/10.webp\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5da2a50-04f4-4388-af23-ad32e405a972",
   "metadata": {
    "id": "e5da2a50-04f4-4388-af23-ad32e405a972"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch04_compressed/11.webp\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffcb905-53c7-4886-87d2-4464c5fecf89",
   "metadata": {
    "id": "4ffcb905-53c7-4886-87d2-4464c5fecf89"
   },
   "source": [
    "## 4.4 숏컷 연결 추가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffae416c-821e-4bfa-a741-8af4ba5db00e",
   "metadata": {
    "id": "ffae416c-821e-4bfa-a741-8af4ba5db00e"
   },
   "source": [
    "- 스킵 연결(skip connection)이나 잔차 연결(residual connection)이라고도 부르는 숏컷 연결(shortcut connection) 이면의 개념을 알아 보죠.\n",
    "- 원래 숏컷 연결은 컴퓨터 비전 분야의 심층 신경망(구체적으로 잔차 신경망(residual network))에서 그레이디언트 소실 문제를 완화하기 위해 제안되었습니다.\n",
    "- 숏컷 연결이 그레이디언트가 한 개 이상의 층을 건너 뛰어 네트워크에 흐를 수 있도록 짧은 다른 경로를 만든다는 것을 보여줍니다.\n",
    "- 이런 경로는 한 층의 출력을 이후 층의 출력에 더하여 만들어집니다.\n",
    "- 작은 샘플 네트워크로 이 아이디어를 설명해 보죠:\n",
    "\n",
    "<img src=\"images/llm_from_scratch/ch04_compressed/12.webp\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cfd241-a32e-4601-8790-784b82f2f23e",
   "metadata": {
    "id": "14cfd241-a32e-4601-8790-784b82f2f23e"
   },
   "source": [
    "- 코드로 구현하면 다음과 같습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05473938-799c-49fd-86d4-8ed65f94fee6",
   "metadata": {
    "id": "05473938-799c-49fd-86d4-8ed65f94fee6"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        \n",
    "        # 1. 층(Layer) 생성\n",
    "        # nn.ModuleList를 사용하여 5개의 층을 리스트 형태로 관리합니다.\n",
    "        # 각 층은 [선형 변환 -> GELU 활성화 함수]로 구성됩니다.\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU())\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 2. 순전파 (Forward Pass)\n",
    "        for layer in self.layers:\n",
    "            # 현재 층을 통과시켜 출력을 계산합니다. (F(x))\n",
    "            layer_output = layer(x)\n",
    "            \n",
    "            # 3. 스킵 연결 (Skip Connection / Residual Connection) 적용 로직\n",
    "            # 조건 1: use_shortcut이 True여야 함 (사용자가 원할 때)\n",
    "            # 조건 2: 입력(x)과 출력(layer_output)의 차원(Shape)이 같아야 더할 수 있음\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                # [핵심] 입력값 x를 출력값에 그대로 더해줍니다. (x + F(x))\n",
    "                # 이렇게 하면 역전파 때 그레이디언트가 이 '지름길'을 타고\n",
    "                # 입력 쪽으로 막힘없이 흐를 수 있습니다.\n",
    "                x = x + layer_output\n",
    "            else:\n",
    "                # 스킵 연결을 안 쓰거나 차원이 다르면, 그냥 층의 출력만 다음으로 넘깁니다.\n",
    "                x = layer_output\n",
    "        return x\n",
    "\n",
    "\n",
    "def print_gradients(model, x):\n",
    "    # 1. 정방향 계산\n",
    "    output = model(x)\n",
    "    target = torch.tensor([[0.]]) # 임의의 정답지 (Loss 계산용)\n",
    "\n",
    "    # 2. 손실(Loss) 계산\n",
    "    # 모델의 출력과 목표값(0) 사이의 오차를 계산합니다. (MSE)\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)\n",
    "\n",
    "    # 3. 역전파 (Backpropagation)\n",
    "    # 오차를 줄이기 위해 각 가중치를 얼마나 수정해야 할지(기울기) 계산합니다.\n",
    "    # 이때 미분값이 뒤에서부터 앞으로 흘러옵니다.\n",
    "    loss.backward()\n",
    "\n",
    "    # 4. 그레이디언트(기울기) 확인\n",
    "    # 각 층의 가중치(weight)들이 가진 기울기의 크기를 출력합니다.\n",
    "    # 층이 깊어질수록 이 값이 0에 가까워지는지(소실 문제) 확인하는 것이 목적입니다.\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            # param.grad: 계산된 기울기\n",
    "            # abs().mean(): 기울기들의 절댓값 평균 (방향 무시하고 크기만 봄)\n",
    "            print(f\"{name}의 평균 그레이디언트는 {param.grad.abs().mean().item()}입니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39bf277-b3db-4bb1-84ce-7a20caff1011",
   "metadata": {
    "id": "b39bf277-b3db-4bb1-84ce-7a20caff1011"
   },
   "source": [
    "- 숏컷 연결이 **없을** 때 그레디언트 값을 출력해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c75f43cc-6923-4018-b980-26023086572c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c75f43cc-6923-4018-b980-26023086572c",
    "outputId": "d98c2d1b-6c4c-48f2-8bb6-a6d19ffe69c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight의 평균 그레이디언트는 0.00020173590746708214입니다.\n",
      "layers.1.0.weight의 평균 그레이디언트는 0.0001201116101583466입니다.\n",
      "layers.2.0.weight의 평균 그레이디언트는 0.0007152042235247791입니다.\n",
      "layers.3.0.weight의 평균 그레이디언트는 0.0013988739810883999입니다.\n",
      "layers.4.0.weight의 평균 그레이디언트는 0.00504964729771018입니다.\n"
     ]
    }
   ],
   "source": [
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(\n",
    "    layer_sizes, use_shortcut=False\n",
    ")\n",
    "print_gradients(model_without_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837fd5d4-7345-4663-97f5-38f19dfde621",
   "metadata": {
    "id": "837fd5d4-7345-4663-97f5-38f19dfde621"
   },
   "source": [
    "- 그다음 숏컷 연결이 **있을** 때 그레이디언트 값을 출력합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11b7c0c2-f9dd-4dd5-b096-a05c48c5f6d6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "11b7c0c2-f9dd-4dd5-b096-a05c48c5f6d6",
    "outputId": "18441ec2-fc0f-463b-94a0-0b26ba0e3d63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight의 평균 그레이디언트는 0.22169791162014008입니다.\n",
      "layers.1.0.weight의 평균 그레이디언트는 0.20694102346897125입니다.\n",
      "layers.2.0.weight의 평균 그레이디언트는 0.32896995544433594입니다.\n",
      "layers.3.0.weight의 평균 그레이디언트는 0.2665732204914093입니다.\n",
      "layers.4.0.weight의 평균 그레이디언트는 1.3258541822433472입니다.\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(\n",
    "    layer_sizes, use_shortcut=True\n",
    ")\n",
    "print_gradients(model_with_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ff783a-46f0-49c5-a7a9-26a525764b6e",
   "metadata": {
    "id": "79ff783a-46f0-49c5-a7a9-26a525764b6e"
   },
   "source": [
    "- 위 출력에서 볼 수 있듯이 숏컷 연결이 앞쪽 층(`layer.0` 층)의 그레이디언트 소실 문제를 막습습니다.\n",
    "- 숏컷 연결의 개념을 사용해 트랜스포머 블록을 구현하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae578ca-e564-42cf-8635-a2267047cdff",
   "metadata": {
    "id": "cae578ca-e564-42cf-8635-a2267047cdff"
   },
   "source": [
    "## 4.5 어텐션과 선형 층을 트랜스포머 블록에 연결하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3daac6f-6545-4258-8f2d-f45a7394f429",
   "metadata": {
    "id": "a3daac6f-6545-4258-8f2d-f45a7394f429"
   },
   "source": [
    "- 이 절에서 이전에 배운 개념을 소위 트랜스포머 블록에 결합합니다.\n",
    "- 트랜스포머 블록은 이전 층에서 다룬 코잘 멀티 헤드 어텐션 모듈과 앞서 다룬 피드 포워드 신경망을 결합합니다.\n",
    "- 또한 트랜스포머 블록은 드롭아웃과 숏컷 연결을 사용합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1e8176-e5e3-4152-b1aa-0bbd7891dfd9",
   "metadata": {
    "id": "0e1e8176-e5e3-4152-b1aa-0bbd7891dfd9"
   },
   "outputs": [],
   "source": [
    "from previous_chapters import MultiHeadAttention\n",
    "import torch.nn as nn\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 1. 멀티 헤드 어텐션 (Multi-Head Attention)\n",
    "        # 문맥을 파악하는 핵심 부품입니다.\n",
    "        # \"단어들 사이의 관계\"를 계산하여 문맥 정보를 수집합니다.\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"]\n",
    "        )\n",
    "        \n",
    "        # 2. 피드 포워드 신경망 (FeedForward)\n",
    "        # 수집된 문맥 정보를 바탕으로 각 토큰(단어)의 정보를 개별적으로 가공/확장합니다.\n",
    "        self.ff = FeedForward(cfg)\n",
    "        \n",
    "        # 3. 레이어 정규화 (LayerNorm)\n",
    "        # 학습을 안정적으로 만들기 위해 데이터 분포를 정리합니다.\n",
    "        # 어텐션 앞(norm1)과 피드포워드 앞(norm2)에 각각 하나씩 배치됩니다.\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        \n",
    "        # 4. 드롭아웃 (Dropout)\n",
    "        # 과적합(Overfitting)을 방지하기 위해 숏컷 연결 직전에 사용합니다.\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # === [파트 1] 어텐션 블록 (Attention Block) ===\n",
    "        \n",
    "        # A. 숏컷(Shortcut) 저장\n",
    "        # \"변형되기 전의 원본 데이터\"를 따로 빼둡니다. (잔차 연결용)\n",
    "        shortcut = x\n",
    "        \n",
    "        # B. 정규화 (Pre-LayerNorm)\n",
    "        # 어텐션에 들어가기 '전에' 정규화를 먼저 합니다. (GPT-2 방식)\n",
    "        x = self.norm1(x)\n",
    "        \n",
    "        # C. 어텐션 수행\n",
    "        # 자기 자신을 포함한 주변 단어들의 정보를 모읍니다.\n",
    "        # 크기 유지: [batch_size, num_tokens, emb_size]\n",
    "        x = self.att(x)\n",
    "        \n",
    "        # D. 드롭아웃 적용\n",
    "        x = self.drop_shortcut(x)\n",
    "        \n",
    "        # E. 잔차 연결 (Residual Connection)\n",
    "        # \"학습된 변화량(x)\"에 \"원본(shortcut)\"을 더합니다.\n",
    "        # 이는 정보가 손실되지 않고 깊은 층까지 흐르게 도와줍니다.\n",
    "        x = x + shortcut \n",
    "\n",
    "        # === [파트 2] 피드 포워드 블록 (Feed Forward Block) ===\n",
    "        \n",
    "        # A. 숏컷 저장 (현재 상태를 다시 원본으로 취급)\n",
    "        shortcut = x\n",
    "        \n",
    "        # B. 정규화\n",
    "        x = self.norm2(x)\n",
    "        \n",
    "        # C. 피드 포워드 수행\n",
    "        # 정보를 확장했다가 압축하며 특징을 학습합니다.\n",
    "        x = self.ff(x)\n",
    "        \n",
    "        # D. 드롭아웃\n",
    "        x = self.drop_shortcut(x)\n",
    "        \n",
    "        # E. 잔차 연결\n",
    "        x = x + shortcut \n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b64d16-94a6-4d13-8c85-9494c50478a9",
   "metadata": {
    "id": "36b64d16-94a6-4d13-8c85-9494c50478a9"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch04_compressed/13.webp\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d2d375-87bd-4153-9040-63a1e6a2b7cb",
   "metadata": {
    "id": "54d2d375-87bd-4153-9040-63a1e6a2b7cb"
   },
   "source": [
    "- 두 개의 입력 샘플이 있다고 가정해 보죠. 각 샘플은 여섯 개의 토큰으로 구성되고 각 토큰은 768차원의 임베딩 벡터입니다. 트랜스포머 블록이 셀프 어텐션과 피드 포워드 신경망을 적용하여 동일 크기의 출력을 반환합니다.\n",
    "- 이 출력을 이전 장에서 이야기한 문맥 벡터의 증강된 버전으로 생각할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3fb45a63-b1f3-4b08-b525-dafbc8228405",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3fb45a63-b1f3-4b08-b525-dafbc8228405",
    "outputId": "8da8edb1-a5ba-4286-a862-92e46b5200e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 크기: torch.Size([2, 4, 768])\n",
      "출력 크기: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "x = torch.rand(2, 4, 768)  # 크기: [batch_size, num_tokens, emb_dim]\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "\n",
    "print(\"입력 크기:\", x.shape)\n",
    "print(\"출력 크기:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9e4ee4-cf23-4583-b1fd-317abb4fcd13",
   "metadata": {
    "id": "8f9e4ee4-cf23-4583-b1fd-317abb4fcd13"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch04_compressed/14.webp\" width=\"700px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46618527-15ac-4c32-ad85-6cfea83e006e",
   "metadata": {
    "id": "46618527-15ac-4c32-ad85-6cfea83e006e"
   },
   "source": [
    "## 4.6 GPT 모델 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec7d03d-9ff3-4ca3-ad67-01b67c2f5457",
   "metadata": {
    "id": "dec7d03d-9ff3-4ca3-ad67-01b67c2f5457"
   },
   "source": [
    "- 트랜스포머 블록을 이 장의 서두에서 만들었던 GPT 구조에 연결해 보죠.\n",
    "- 트랜스포머 블록은 여러 번 반복됩니다. 1억 2,400만 파라미터의 GPT-2 모델의 경우 12번 반복합니다:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7b362d-f8c5-48d2-8ebd-722480ac5073",
   "metadata": {
    "id": "9b7b362d-f8c5-48d2-8ebd-722480ac5073"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch04_compressed/15.webp\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324e4b5d-ed89-4fdf-9a52-67deee0593bc",
   "metadata": {
    "id": "324e4b5d-ed89-4fdf-9a52-67deee0593bc"
   },
   "source": [
    "- 이를 코드로 구현하면 다음과 같습니다. 여기서 `cfg[\"n_layers\"] = 12`입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61de39c-d03c-4a32-8b57-f49ac3834857",
   "metadata": {
    "id": "c61de39c-d03c-4a32-8b57-f49ac3834857"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 1. 토큰 임베딩 (Token Embedding)\n",
    "        # 입력된 단어 ID를 벡터(숫자들의 리스트)로 변환합니다.\n",
    "        # 예: \"Apple\"(ID: 52) -> [0.1, -0.5, ...]\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        \n",
    "        # 2. 위치 임베딩 (Positional Embedding)\n",
    "        # GPT는 순차적으로 글을 읽는 것이 아니라 한 번에 보므로, 단어의 순서 정보를 따로 알려줘야 합니다.\n",
    "        # \"첫 번째 단어\", \"두 번째 단어\"에 해당하는 고유한 벡터를 학습합니다.\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        \n",
    "        # 3. 임베딩 드롭아웃\n",
    "        # 임베딩 단계에서 과적합을 방지하기 위해 사용합니다.\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        # 4. 트랜스포머 블록 쌓기 (The \"Brain\")\n",
    "        # 앞서 만든 TransformerBlock을 설정한 층수(n_layers)만큼 반복해서 쌓습니다.\n",
    "        # * (asterisk)는 리스트의 요소들을 풀어서 nn.Sequential에 개별 인자로 넣어줍니다.\n",
    "        # (마치 블록을 12층, 24층 높이로 쌓아 올리는 것과 같습니다.)\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "\n",
    "        # 5. 최종 정규화 (Final Normalization)\n",
    "        # 모든 블록을 통과한 후, 출력값을 안정적으로 만들기 위해 마지막으로 한 번 더 정규화합니다.\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        \n",
    "        # 6. 출력 헤드 (Output Head)\n",
    "        # 모델이 이해한 벡터(emb_dim)를 다시 전체 단어장 크기(vocab_size)로 변환합니다.\n",
    "        # 이 결과값이 각 단어가 \"다음 단어일 확률 점수(Logits)\"가 됩니다.\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        # in_idx: 입력 텍스트의 토큰 ID들 [batch_size, seq_len]\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        \n",
    "        # A. 임베딩 계산\n",
    "        # 토큰 자체의 의미 벡터 생성\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        \n",
    "        # 위치 정보 벡터 생성 (0, 1, 2, ... seq_len-1)\n",
    "        # device=in_idx.device를 써야 GPU/CPU 에러가 나지 않습니다.\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        \n",
    "        # B. 정보 결합\n",
    "        # [단어의 의미] + [단어의 위치]를 더해서 모델에게 전달합니다.\n",
    "        # 파이토치의 브로드캐스팅 기능으로 pos_embeds가 배치의 모든 문장에 똑같이 더해집니다.\n",
    "        x = tok_embeds + pos_embeds  # 크기: [batch_size, num_tokens, emb_size]\n",
    "        \n",
    "        # C. 드롭아웃 적용\n",
    "        x = self.drop_emb(x)\n",
    "        \n",
    "        # D. 트랜스포머 블록 통과 (Deep Processing)\n",
    "        # 데이터가 깊은 신경망 층을 통과하며 고차원적인 특징을 학습합니다.\n",
    "        x = self.trf_blocks(x)\n",
    "        \n",
    "        # E. 최종 정규화\n",
    "        x = self.final_norm(x)\n",
    "        \n",
    "        # F. 다음 단어 예측 (Logits 생성)\n",
    "        # [batch_size, seq_len, vocab_size] 크기의 텐서가 나옵니다.\n",
    "        logits = self.out_head(x)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2750270f-c45d-4410-8767-a6adbd05d5c3",
   "metadata": {
    "id": "2750270f-c45d-4410-8767-a6adbd05d5c3"
   },
   "source": [
    "- 1억 2,400만 파라미터 모델의 설정을 사용해 랜덤한 초기 가중치로 GPT 모델을 만들었습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef94fd9c-4e9d-470d-8f8e-dd23d1bb1f64",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ef94fd9c-4e9d-470d-8f8e-dd23d1bb1f64",
    "outputId": "a85a7c67-46a8-49cd-b4c5-d709c4dfedea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 배치:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "\n",
      "출력 크기: torch.Size([2, 4, 50257])\n",
      "tensor([[[ 0.3613,  0.4222, -0.0711,  ...,  0.3483,  0.4661, -0.2838],\n",
      "         [-0.1792, -0.5660, -0.9485,  ...,  0.0477,  0.5181, -0.3168],\n",
      "         [ 0.7120,  0.0332,  0.1085,  ...,  0.1018, -0.4327, -0.2553],\n",
      "         [-1.0076,  0.3418, -0.1190,  ...,  0.7195,  0.4023,  0.0532]],\n",
      "\n",
      "        [[-0.2564,  0.0900,  0.0335,  ...,  0.2659,  0.4454, -0.6806],\n",
      "         [ 0.1230,  0.3653, -0.2074,  ...,  0.7705,  0.2710,  0.2246],\n",
      "         [ 1.0558,  1.0318, -0.2800,  ...,  0.6936,  0.3205, -0.3178],\n",
      "         [-0.1565,  0.3926,  0.3288,  ...,  1.2630, -0.1858,  0.0388]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "out = model(batch)\n",
    "print(\"입력 배치:\\n\", batch)\n",
    "print(\"\\n출력 크기:\", out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d616e7a-568b-4921-af29-bd3f4683cd2e",
   "metadata": {
    "id": "6d616e7a-568b-4921-af29-bd3f4683cd2e"
   },
   "source": [
    "- 이 모델을 다음 장에서 훈련해보겠습니다.\n",
    "- 크기를 간단히 계산해 보죠. 1억 2,400만 파라미터를 가지고 있는지 다음처럼 확인할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84fb8be4-9d3b-402b-b3da-86b663aac33a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "84fb8be4-9d3b-402b-b3da-86b663aac33a",
    "outputId": "22a8b7b0-d55f-4b30-ded9-b53b450ebf22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 파라미터 개수: 163,009,536\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"총 파라미터 개수: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67d13dd-dd01-4ba6-a2ad-31ca8a9fd660",
   "metadata": {
    "id": "b67d13dd-dd01-4ba6-a2ad-31ca8a9fd660"
   },
   "source": [
    "- 위에서 보듯이 이 모델의 파라미터 개수는 1억 2,400만개가 아니라 1억 6,300만개입니다. 왜일까요?\n",
    "- 원본 GPT-2 논문에서 연구자들은 가중치 묶기(weight tying)를 적용했습니다. 토큰 임베딩 층(`tok_emb`)의 가중치를 출력 층에 재사용한다는 의미이며, `self.out_head.weight = self.tok_emb.weight`처럼 설정합니다.\n",
    "- 토큰 임베딩 층은 50,257차원의 원-핫 인코딩된 입력 토큰을 768차원의 임베딩 표현에 투영합니다.\n",
    "- 출력 층은 768차원의 임베딩을 단어로 변환하기 위해 50,257차원의 표현으로 다시 투영합니다(다음 절에서 자세히 설명합니다).\n",
    "- 따라서 가중치 행렬의 크기를 보면 알 수 있듯이 임베딩 층과 출력 층의 파라미터 개수가 같습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3b43233-e9b8-4f5a-b72b-a263ec686982",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e3b43233-e9b8-4f5a-b72b-a263ec686982",
    "outputId": "65739d1f-5e94-4702-9082-86bb6cbeae68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토큰 임베딩 층의 가중치 크기: torch.Size([50257, 768])\n",
      "출력 층의 가중치 크기: torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"토큰 임베딩 층의 가중치 크기:\", model.tok_emb.weight.shape)\n",
    "print(\"출력 층의 가중치 크기:\", model.out_head.weight.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02259f6-6f79-4c89-a866-4ebeae1c3289",
   "metadata": {
    "id": "f02259f6-6f79-4c89-a866-4ebeae1c3289"
   },
   "source": [
    "- 원본 GPT-2 논문에서 연구자들은 토큰 임베딩 행렬을 출력 행렬로 재사용했습니다.\n",
    "- 결과적으로 출력 층의 파라미터 개수를 빼면 1억 2,400만 파라미터의 모델이 됩니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95a22e02-50d3-48b3-a4e0-d9863343c164",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "95a22e02-50d3-48b3-a4e0-d9863343c164",
    "outputId": "7d3597ac-495c-4c33-cc84-13574661a730"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가중치 묶기를 고려한 훈련 가능한 파라미터 개수: 124,412,160\n"
     ]
    }
   ],
   "source": [
    "total_params_gpt2 =  total_params - sum(p.numel() for p in model.out_head.parameters())\n",
    "print(f\"가중치 묶기를 고려한 훈련 가능한 파라미터 개수: {total_params_gpt2:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b03f80-b94c-46e7-9d42-d0df399ff3db",
   "metadata": {
    "id": "40b03f80-b94c-46e7-9d42-d0df399ff3db"
   },
   "source": [
    "- 실제로는 가중치 묶기가 없는 모델이 훈련하기 쉽기 때문에 여기서는 구현하지 않습니다.\n",
    "- 하지만 5장에서 사전 훈련된 가중치를 로드할 때 가중치 묶기를 적용하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7J2mcpNPYgAf",
   "metadata": {
    "id": "7J2mcpNPYgAf"
   },
   "source": [
    "- 마지막으로 모델에 필요한 메모리 크기를 계산해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5131a752-fab8-4d70-a600-e29870b33528",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5131a752-fab8-4d70-a600-e29870b33528",
    "outputId": "bba8b4c6-38cc-4adb-f355-8e065e92797d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델에 필요한 메모리 공간: 621.83 MB\n"
     ]
    }
   ],
   "source": [
    "# 총 크기를 바이트 단위로 계산합니다(float32라 가정하면 파라미터당 4바이트입니다).\n",
    "total_size_bytes = total_params * 4\n",
    "\n",
    "# 메가바이트로 변환합니다.\n",
    "total_size_mb = total_size_bytes / (1024 * 1024)\n",
    "\n",
    "print(f\"모델에 필요한 메모리 공간: {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5d9bc0-95ab-45d4-9378-417628d86e35",
   "metadata": {
    "id": "da5d9bc0-95ab-45d4-9378-417628d86e35"
   },
   "source": [
    "## 4.7 텍스트 생성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48da5deb-6ee0-4b9b-8dd2-abed7ed65172",
   "metadata": {
    "id": "48da5deb-6ee0-4b9b-8dd2-abed7ed65172"
   },
   "source": [
    "- 앞에서 구현한 GPT와 같은 LLM은 한 번에 하나의 단어를 생성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caade12a-fe97-480f-939c-87d24044edff",
   "metadata": {
    "id": "caade12a-fe97-480f-939c-87d24044edff"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch04_compressed/16.webp\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7061524-a3bd-4803-ade6-2e3b7b79ac13",
   "metadata": {
    "id": "a7061524-a3bd-4803-ade6-2e3b7b79ac13"
   },
   "source": [
    "- 다음에 나오는 `generate_text_simple` 함수는 간단하고 빠르게 텍스트를 생성하는 그리디 디코딩(greedy decoding)을 구현합니다.\n",
    "- 그리디 디코딩에서는 각 단계마다 모델이 가장 높은 확률을 가진 단어(또는 토큰)을 다음 출력으로 선택합니다(가장 높은 로짓이 가장 높은 확률에 대응됩니다. 따라서 기술적으로는 명시적으로 소프트매맥스 함수를 적용할 필요가 없습니다).\n",
    "- 다음 장에서 조금 더 고급 기법을 사용한 `generate_text` 함수를 구현하겠습니다.\n",
    "- 다음 그림은 GPT 모델이 주어진 문맥을 기반으로 다음 토큰을 생성하는 방법을 보여줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee0f32c-c18c-445e-b294-a879de2aa187",
   "metadata": {
    "id": "7ee0f32c-c18c-445e-b294-a879de2aa187"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch04_compressed/17.webp\" width=\"900px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b428a9-8764-4b36-80cd-7d4e00595ba6",
   "metadata": {
    "id": "c9b428a9-8764-4b36-80cd-7d4e00595ba6"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model: 학습된 GPT 모델\n",
    "        idx: 현재까지 입력된 텍스트의 토큰 인덱스 텐서 (배치 크기, 현재 길이)\n",
    "        max_new_tokens: 새로 생성할 토큰의 개수\n",
    "        context_size: 모델이 한 번에 처리할 수 있는 최대 문맥 길이 (예: 1024)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 생성할 토큰 개수만큼 반복합니다. (한 번에 하나씩 생성)\n",
    "    for _ in range(max_new_tokens):\n",
    "\n",
    "        # 1. 문맥 자르기 (Sliding Window)\n",
    "        # 입력된 텍스트(idx)가 모델의 최대 허용 길이(context_size)를 넘으면,\n",
    "        # 가장 오래된 앞부분은 자르고 최근 내용만 남겨서 모델에 입력합니다.\n",
    "        # 예: context_size가 4인데 입력이 [1, 2, 3, 4, 5]라면 -> [2, 3, 4, 5]만 사용\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "\n",
    "        # 2. 모델 예측 (Forward Pass)\n",
    "        # 그레이디언트 계산을 끕니다(no_grad). \n",
    "        # 학습이 아니라 추론(생성) 단계이므로 메모리를 아끼고 속도를 높입니다.\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "\n",
    "        # 3. 다음 단어 예측값 추출\n",
    "        # 모델은 입력된 모든 위치에 대해 예측값을 내놓지만, \n",
    "        # 우리는 문장의 '맨 마지막' 단어 다음에 올 단어만 궁금합니다.\n",
    "        # logits 형태: [배치, 시퀀스 길이, 단어장 크기] -> [배치, 단어장 크기]\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # 4. 확률 변환 (Softmax)\n",
    "        # 로짓(점수)을 0~1 사이의 확률값으로 변환합니다.\n",
    "        # dim=-1: 단어장 차원을 기준으로 확률을 계산합니다.\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "\n",
    "        # 5. 그리디 선택 (Greedy Selection)\n",
    "        # 확률이 가장 높은(argmax) 단어의 인덱스 하나를 무조건 선택합니다.\n",
    "        # (이 방식은 항상 같은 결과를 내며, 창의성은 떨어질 수 있습니다.)\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
    "\n",
    "        # 6. 문장 이어 붙이기 (Concatenation)\n",
    "        # 방금 찾은 다음 단어(idx_next)를 기존 문장(idx) 뒤에 붙입니다.\n",
    "        # 이 업데이트된 idx가 다음 반복문에서 다시 모델의 입력으로 들어갑니다. (Autoregressive)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "    # 최종적으로 완성된 전체 문장(인덱스 배열)을 반환합니다.\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6515f2c1-3cc7-421c-8d58-cc2f563b7030",
   "metadata": {
    "id": "6515f2c1-3cc7-421c-8d58-cc2f563b7030"
   },
   "source": [
    "- `generate_text_simple`는 한 번에 하나의 토큰을 만드는 반복적인 과정을 구현합니다.\n",
    "\n",
    "<img src=\"images/llm_from_scratch/ch04_compressed/18.webp\" width=\"700px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f682eac4-f9bd-438b-9dec-6b1cc7bc05ce",
   "metadata": {
    "id": "f682eac4-f9bd-438b-9dec-6b1cc7bc05ce"
   },
   "source": [
    "- 입력 샘플을 준비해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d7e3e94-df0f-4c0f-a6a1-423f500ac1d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3d7e3e94-df0f-4c0f-a6a1-423f500ac1d3",
    "outputId": "5c50d131-de30-4984-d311-dfdbac474a06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩된 ID: [15496, 11, 314, 716]\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello, I am\"\n",
    "\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"인코딩된 ID:\", encoded)\n",
    "\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72a9b60-de66-44cf-b2f9-1e638934ada4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a72a9b60-de66-44cf-b2f9-1e638934ada4",
    "outputId": "d0d1a5ce-51e5-44b9-8d20-5cf9ff505214"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출력: tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 42348,  7267]])\n",
      "출력 길이: 10\n"
     ]
    }
   ],
   "source": [
    "# 1. 평가 모드 전환 (Evaluation Mode)\n",
    "# 모델을 '학습 모드(Train)'에서 '평가 모드(Eval)'로 변경합니다.\n",
    "# 중요: 이 설정을 해야 드롭아웃(Dropout)이 비활성화되어, \n",
    "#       매번 실행할 때마다 결과가 흔들리지 않고 일관되게 나옵니다.\n",
    "model.eval() \n",
    "\n",
    "# 2. 텍스트 생성 실행\n",
    "# 앞서 정의한 함수를 호출하여 다음 단어들을 예측합니다.\n",
    "out = generate_text_simple(\n",
    "    model=model,\n",
    "    # encoded_tensor: 토크나이저로 숫자로 변환된 입력 문장(프롬프트)\n",
    "    idx=encoded_tensor, \n",
    "    \n",
    "    # 새로운 토큰 6개만 더 생성하겠다는 의미입니다.\n",
    "    # (입력 길이가 10이라면, 결과 길이는 16이 됩니다.)\n",
    "    max_new_tokens=6, \n",
    "    \n",
    "    # 모델이 기억할 수 있는 최대 길이(예: 1024)를 전달합니다.\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "# 3. 결과 확인\n",
    "# 출력되는 'out'은 아직 사람이 읽을 수 있는 글자가 아니라, '숫자(Token ID)들의 텐서'입니다.\n",
    "print(\"출력(Tensor):\", out)\n",
    "\n",
    "# 생성된 전체 길이(입력 + 6)를 확인합니다.\n",
    "print(\"출력 길이:\", len(out[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d131c00-1787-44ba-bec3-7c145497b2c3",
   "metadata": {
    "id": "1d131c00-1787-44ba-bec3-7c145497b2c3"
   },
   "source": [
    "- 배치 차원을 삭제하고 텍스트로 다시 변환합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "053d99f6-5710-4446-8d52-117fb34ea9f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "053d99f6-5710-4446-8d52-117fb34ea9f6",
    "outputId": "96625fcb-6d82-44d7-e888-9d93a7bd80b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am Featureiman Byeswickattribute argue\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a894003-51f6-4ccc-996f-3b9c7d5a1d70",
   "metadata": {
    "id": "9a894003-51f6-4ccc-996f-3b9c7d5a1d70"
   },
   "source": [
    "- 모델이 훈련되지 않았기 때문에 위와 같이 랜덤한 텍스트가 출력됩니다.\n",
    "- 다음 장에서 이 모델을 훈련하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35278b6-9e5c-480f-83e5-011a1173648f",
   "metadata": {
    "id": "a35278b6-9e5c-480f-83e5-011a1173648f"
   },
   "source": [
    "## 요약\n",
    "\n",
    "- 연습문제 솔루션은 [./exercise-solutions.ipynb](./exercise-solutions.ipynb)에 있습니다."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
