{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa4dab80",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/rickiepark/llm-from-scratch/blob/main/ch04/01_main-chapter-code/ch04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f4321d-d32a-4a90-bfc7-e923f316b2f8",
   "metadata": {
    "id": "08f4321d-d32a-4a90-bfc7-e923f316b2f8"
   },
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<font size=\"2\">\n",
    "세바스찬 라시카(Sebastian Raschka)가 쓴 <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a>의 번역서 <br><<b><a href=\"<a href=\"http://tensorflow.blog/llm-from-scratch\">밑바닥부터 만들면서 배우는 LLM</a></b>>의 예제 코드입니다.<br>\n",
    "<br>코드 저장소: <a href=\"https://github.com/rickiepark/llm-from-scratch\">https://github.com/rickiepark/llm-from-scratch</a>\n",
    "</font>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<a href=\"http://tensorflow.blog/llm-from-scratch\"><img src=\"https://tensorflowkorea.wordpress.com/wp-content/uploads/2025/09/ebb091ebb094eb8ba5llm_ebb3b8ecb185_ec959eeba9b4.jpg\" width=\"100px\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9295b2-182b-490b-8325-83a67c4a001d",
   "metadata": {
    "id": "ce9295b2-182b-490b-8325-83a67c4a001d"
   },
   "source": [
    "# 4장: 밑바닥부터 GPT 모델 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9eac223-a125-40f7-bacc-bd0d890450c7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f9eac223-a125-40f7-bacc-bd0d890450c7",
    "outputId": "fa31d4bb-ced7-4ce4-f829-5511df4756aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "맷플롯립 버전: 3.10.8\n",
      "파이토치 버전: 2.8.0\n",
      "tiktoken 버전: 0.12.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "print(\"맷플롯립 버전:\", version(\"matplotlib\"))\n",
    "print(\"파이토치 버전:\", version(\"torch\"))\n",
    "print(\"tiktoken 버전:\", version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7da97ed-e02f-4d7f-b68e-a0eba3716e02",
   "metadata": {
    "id": "e7da97ed-e02f-4d7f-b68e-a0eba3716e02"
   },
   "source": [
    "- 이 장에서 GPT와 유사한 LLM 구조를 구현합니다. 다음 장에서는 이 LLM 훈련하는데 초점을 맞추겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4f11e0-4434-4979-9dee-e1207df0eb01",
   "metadata": {
    "id": "7d4f11e0-4434-4979-9dee-e1207df0eb01"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch04_compressed/01.webp\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fe99ab-0bcf-4778-a6b5-6db81fb826ef",
   "metadata": {
    "id": "53fe99ab-0bcf-4778-a6b5-6db81fb826ef"
   },
   "source": [
    "## 4.1 구조 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad72d1ff-d82d-4e33-a88e-3c1a8831797b",
   "metadata": {
    "id": "ad72d1ff-d82d-4e33-a88e-3c1a8831797b"
   },
   "source": [
    "- 1장은 GPT와 Llama 같은 모델을 소개했습니다. 이런 모델은 원본 트랜스포머 구조의 디코더 부분을 기반으로 순차적으로 단어를 생성합니다.\n",
    "- 따라서 이런 LLM을 종종 디코더 기반 LLM이라 부릅니다.\n",
    "- 전통적인 딥러닝 모델과 비교하면 LLM은 규모가 큽니다. 이는 코드의 양이 아니라 방대한 파라미터 개수 때문입니다.\n",
    "- 앞으로 보겠지만 LLM 구조의 많은 구성 요소가 반복적입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5213e9-bd1c-437e-aee8-f5e8fb717251",
   "metadata": {
    "id": "5c5213e9-bd1c-437e-aee8-f5e8fb717251"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch04_compressed/02.webp\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d43f5e2-fb51-434a-b9be-abeef6b98d99",
   "metadata": {
    "id": "0d43f5e2-fb51-434a-b9be-abeef6b98d99"
   },
   "source": [
    "- 이전 장에서 설명의 편의를 위해 토큰 입력과 출력의 임베딩 차원을 작게 했습니다.\n",
    "- 이 장에서는 작은 GPT-2 모델와 같은 임베딩 크기를 사용합니다.\n",
    "- 구체적으로 Radford et al.'s [Language Models are Unsupervised Multitask Learners](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)에 나온 가장 작은 GPT-2 모델 구조(1억 2,400만 파라미터)를 구현하겠습니다(처음에는 1억 1,700만 파라미터라고 보고되었지만 나중에 모델 저장소에 수정된 값으로 공개되었습니다).\n",
    "- 여기서 구현한 모델은 3억 4,500만 파라미터, 7억 6,200만 파라미터, 15억 4,200만 파라미터를 가진 모델과 호환됩니다. 5장에서 이 구현에 사전 훈련된 가중치를 로드하는 방법을 알아 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21baa14d-24b8-4820-8191-a2808f7fbabc",
   "metadata": {
    "id": "21baa14d-24b8-4820-8191-a2808f7fbabc"
   },
   "source": [
    "- 1억 2,400만 파라미터 GPT-2 모델의 설정은 다음과 같습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ed66875-1f24-445d-add6-006aae3c5707",
   "metadata": {
    "id": "5ed66875-1f24-445d-add6-006aae3c5707"
   },
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # 어휘사전 크기\n",
    "    \"context_length\": 1024, # 문맥 길이\n",
    "    \"emb_dim\": 768,         # 임베딩 차원\n",
    "    \"n_heads\": 12,          # 어텐션 헤드 개수\n",
    "    \"n_layers\": 12,         # 층 개수\n",
    "    \"drop_rate\": 0.1,       # 드롭아웃 비율\n",
    "    \"qkv_bias\": False       # 쿼리, 키, 값을 만들 때 편향 포함 여부\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12fcd28-d210-4c57-8be6-06cfcd5d73a4",
   "metadata": {
    "id": "c12fcd28-d210-4c57-8be6-06cfcd5d73a4"
   },
   "source": [
    "- `\"vocab_size\"`는 BPE 토크나이저(2장 참조)에서 사용할 50,257 토큰으로 구성된 어휘 사전 크기를 나타냅니다.\n",
    "- `\"context_length\"`는 위치 임베딩(2장 참조)으로 모델이 다룰 수 있는 입력 토큰의 최대 개수입니다.\n",
    "- `\"emb_dim\"`은 임베딩 크기를 나타내며, 각 토큰을 768 차원의 벡터로 변환합니다.\n",
    "- `\"n_heads\"`는 멀티 헤드 어텐션 메커니즘(3장 참조)에 있는 어텐션 헤드의 개수입니다.\n",
    "- `\"n_layers\"`에는 모델에 있는 (이 장에서 소개할) 트랜스포머 블록의 개수를 지정합니다.\n",
    "- `\"drop_rate\"`는 과대적합을 막기 위한 드롭아웃 메커니즘(3장 참조)의 강도를 지정합니다(0.1은 은닉 유닛의 10%를 랜덤하게 제외한다는 의미입니다).\n",
    "- `\"qkv_bias\"`는 멀티 헤드 어텐션의 Linear 층에서 쿼리, 키, 값을 계산할 때 편향 유닛을 도입할지 여부를 결정합니다. 현대적인 LLM의 구성 방식을 따라서 처음에는 이 값을 비활성화하지만 오픈AI의 사전 훈련된 GPT-2 가중치를 모델로 로드할 때 이를 다시 살펴 보겠습니다(5장 참조)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adce779-857b-4418-9501-12a7f3818d88",
   "metadata": {
    "id": "4adce779-857b-4418-9501-12a7f3818d88"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch04_compressed/03.webp\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "619c2eed-f8ea-4ff5-92c3-feda0f29b227",
   "metadata": {
    "id": "619c2eed-f8ea-4ff5-92c3-feda0f29b227"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DummyGPTModel(nn.Module):\n",
    "    \"\"\"\n",
    "    GPT 모델의 전체 구조를 정의하는 클래스입니다.\n",
    "    실제 연산(Attention 등)은 제외하고, 데이터의 흐름과 입출력 차원을 맞추는 구조만 구현되어 있습니다.\n",
    "    \"\"\"\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 1. 토큰 임베딩 (Token Embedding)\n",
    "        # 입력된 단어 ID(정수)를 벡터(실수)로 변환합니다.\n",
    "        # 크기: [vocab_size, emb_dim] (예: 50257개 단어, 768차원)\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        \n",
    "        # 2. 위치 임베딩 (Position Embedding)\n",
    "        # Transformer는 순서 정보가 없으므로, 단어의 위치 정보를 벡터로 학습하여 더해줍니다.\n",
    "        # 크기: [context_length, emb_dim] (예: 최대 1024개 위치, 768차원)\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        \n",
    "        # 3. 드롭아웃 (Dropout)\n",
    "        # 과적합(Overfitting)을 방지하기 위해 임베딩 값의 일부를 무작위로 0으로 만듭니다.\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        # 4. 트랜스포머 블록 (Transformer Blocks)\n",
    "        # 실제 GPT의 핵심 연산(Self-Attention + Feed Forward)이 일어나는 층을 여러 개 쌓습니다.\n",
    "        # 여기서는 더미(Dummy) 블록을 사용하여 구조만 잡았습니다.\n",
    "        # * (Asterisk)는 리스트의 요소를 풀어서(unpacking) 인자로 전달합니다.\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "\n",
    "        # 5. 최종 정규화 (Final LayerNorm)\n",
    "        # 블록들을 통과한 후, 데이터 분포를 안정화하기 위한 정규화 층입니다.\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
    "        \n",
    "        # 6. 출력 헤드 (Output Head)\n",
    "        # 최종 벡터를 다시 단어 집합 크기(vocab_size)로 변환하여,\n",
    "        # 다음에 올 단어의 확률(Logits)을 계산합니다.\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        # in_idx: 입력 데이터 (배치 크기, 시퀀스 길이) -> 예: [Batch, Seq_Len]\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        \n",
    "        # A. 토큰 임베딩 변환\n",
    "        # 입력: [Batch, Seq_Len] -> 출력: [Batch, Seq_Len, Emb_Dim]\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        \n",
    "        # B. 위치 임베딩 생성\n",
    "        # 0부터 seq_len-1까지의 숫자를 생성하여 위치 벡터로 변환합니다.\n",
    "        # device=in_idx.device는 입력 데이터와 같은 장치(CPU/GPU)를 쓰기 위함입니다.\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        \n",
    "        # C. 임베딩 합산 (Input Embedding)\n",
    "        # 토큰 정보와 위치 정보를 더해줍니다. (브로드캐스팅에 의해 배치 내 모든 샘플에 동일하게 더해짐)\n",
    "        x = tok_embeds + pos_embeds\n",
    "        \n",
    "        # D. 드롭아웃 적용\n",
    "        x = self.drop_emb(x)\n",
    "        \n",
    "        # E. 트랜스포머 블록 통과\n",
    "        # 여러 층의 블록을 순차적으로 통과하며 특징을 추출합니다.\n",
    "        x = self.trf_blocks(x)\n",
    "        \n",
    "        # F. 최종 정규화\n",
    "        x = self.final_norm(x)\n",
    "        \n",
    "        # G. 다음 단어 예측 (Logits 산출)\n",
    "        # 출력: [Batch, Seq_Len, Vocab_Size]\n",
    "        logits = self.out_head(x)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    실제로는 Multi-Head Attention과 FeedForward Network가 들어가는 곳입니다.\n",
    "    구조 파악을 위해 입력을 그대로 반환하는 더미 클래스로 대체되었습니다.\n",
    "    \"\"\"\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        # 실제 구현에서는 여기에 Attention, MLP, LayerNorm 등이 정의됩니다.\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 아무런 연산도 수행하지 않고 입력을 그대로 다음 층으로 넘깁니다.\n",
    "        return x\n",
    "\n",
    "\n",
    "class DummyLayerNorm(nn.Module):\n",
    "    \"\"\"\n",
    "    Layer Normalization을 흉내 내는 더미 클래스입니다.\n",
    "    실제로는 평균과 분산을 이용해 데이터를 정규화합니다.\n",
    "    \"\"\"\n",
    "    def __init__(self, normalized_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "        # 실제 LayerNorm과 인터페이스(파라미터 입력 방식)를 맞추기 위한 초기화입니다.\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 아무런 연산도 수행하지 않고 입력을 그대로 반환합니다.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9665e8ab-20ca-4100-b9b9-50d9bdee33be",
   "metadata": {
    "id": "9665e8ab-20ca-4100-b9b9-50d9bdee33be"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch04_compressed/04.webp\" width=\"650px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "794b6b6c-d36f-411e-a7db-8ac566a87fee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "794b6b6c-d36f-411e-a7db-8ac566a87fee",
    "outputId": "d72d0378-137a-45ba-c0bd-835e753b32ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import torch  # PyTorch 라이브러리 (텐서 연산을 위해 필요)\n",
    "import tiktoken  # OpenAI의 BPE 토크나이저 라이브러리\n",
    "\n",
    "# 1. 토크나이저 초기화\n",
    "# GPT-2 모델이 사용하는 인코딩 방식('gpt2')을 로드합니다.\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "# 데이터를 모을 빈 리스트 생성\n",
    "batch = []\n",
    "\n",
    "# 2. 예제 데이터 준비\n",
    "# 처리할 문장 두 개를 정의합니다.\n",
    "# 주의: torch.stack을 사용하려면 두 문장의 토큰 길이가 같아야 합니다.\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "\n",
    "# 3. 인코딩 및 텐서 변환\n",
    "# 과정: 텍스트 -> 토큰 ID 리스트(encode) -> 파이토치 텐서(tensor) -> 리스트에 추가(append)\n",
    "# txt1을 토큰화하여 텐서로 변환 후 batch 리스트에 담습니다.\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "\n",
    "# txt2도 동일하게 처리하여 batch 리스트에 담습니다.\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "\n",
    "# 4. 배치 생성 (Stacking)\n",
    "# 현재 batch는 [tensor([..]), tensor([..])] 형태의 리스트입니다.\n",
    "# 이를 하나의 큰 텐서(행렬)로 합칩니다. dim=0은 세로 방향(행)으로 쌓겠다는 의미입니다.\n",
    "# 결과 Shape 예상: [2, 4] (2개의 문장, 각 문장은 4개의 토큰)\n",
    "batch = torch.stack(batch, dim=0)\n",
    "\n",
    "# 결과 출력\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "009238cd-0160-4834-979c-309710986bb0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "009238cd-0160-4834-979c-309710986bb0",
    "outputId": "81c71a9d-d518-4df6-fbfd-0411eb788b91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출력 크기: torch.Size([2, 4, 50257])\n",
      "tensor([[[-1.2034,  0.3201, -0.7130,  ..., -1.5548, -0.2390, -0.4667],\n",
      "         [-0.1192,  0.4539, -0.4432,  ...,  0.2392,  1.3469,  1.2430],\n",
      "         [ 0.5307,  1.6720, -0.4695,  ...,  1.1966,  0.0111,  0.5835],\n",
      "         [ 0.0139,  1.6754, -0.3388,  ...,  1.1586, -0.0435, -1.0400]],\n",
      "\n",
      "        [[-1.0908,  0.1798, -0.9484,  ..., -1.6047,  0.2439, -0.4530],\n",
      "         [-0.7860,  0.5581, -0.0610,  ...,  0.4835, -0.0077,  1.6621],\n",
      "         [ 0.3567,  1.2698, -0.6398,  ..., -0.0162, -0.1296,  0.3717],\n",
      "         [-0.2407, -0.7349, -0.5102,  ...,  2.0057, -0.3694,  0.1814]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 1. 랜덤 시드 고정\n",
    "# 실행할 때마다 결과가 달라지지 않도록 난수 생성기의 초기값을 '123'으로 고정합니다.\n",
    "# (디버깅이나 학습용 예제에서 결과를 재현하기 위해 필수적입니다.)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# 2. 모델 인스턴스 생성\n",
    "# GPT-2(124M 버전)의 설정값(GPT_CONFIG_124M)을 사용하여 모델을 만듭니다.\n",
    "# 'Dummy'라는 이름에서 알 수 있듯이, 아직 학습되지 않은(랜덤 가중치를 가진) 껍데기 모델일 가능성이 높습니다.\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "# 3. 순전파 (Forward Pass) 실행\n",
    "# 앞서 만든 데이터(batch)를 모델에 통과시켜 예측값을 계산합니다.\n",
    "# 반환된 'logits'는 확률로 변환되기 전의 원시 점수(Score)입니다.\n",
    "logits = model(batch)\n",
    "\n",
    "# 4. 결과 확인\n",
    "# 출력 텐서의 형태(Shape)를 확인합니다.\n",
    "# 예상 형태: [배치 크기, 문장 길이, 단어 사전 크기] -> 예: [2, 4, 50257]\n",
    "print(\"출력 크기:\", logits.shape)\n",
    "\n",
    "# 실제 계산된 텐서 값들을 출력합니다.\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8332a00-98da-4eb4-b882-922776a89917",
   "metadata": {
    "id": "f8332a00-98da-4eb4-b882-922776a89917"
   },
   "source": [
    "## 4.2 층 정규화로 활성화 정규화하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066cfb81-d59b-4d95-afe3-e43cf095f292",
   "metadata": {
    "id": "066cfb81-d59b-4d95-afe3-e43cf095f292"
   },
   "source": [
    "- LayerNorm([Ba et al. 2016](https://arxiv.org/abs/1607.06450))이라고도 불리는 층 정규화는 신경망 층의 활성화를 평균이 0이고 분산이 1이 되도록 조정합니다.\n",
    "- 이를 통해 훈련을 안정화하고 가중치 수렴 속도를 높일 수 있습니다.\n",
    "- 나중에 구현하겠지만 층 정규화는 트랜스포머 블록의 멀티 헤드 어텐션 모듈 전후에 적용됩니다. 또한 최종 출력 층 전에도 적용됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314ac47a-69cc-4597-beeb-65bed3b5910f",
   "metadata": {
    "id": "314ac47a-69cc-4597-beeb-65bed3b5910f"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch04_compressed/05.webp\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab49940-6b35-4397-a80e-df8d092770a7",
   "metadata": {
    "id": "5ab49940-6b35-4397-a80e-df8d092770a7"
   },
   "source": [
    "- 작은 입력 샘플을 간단한 신경망 층에 통과시켜 층 정규화의 작동 방식을 알아 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "79e1b463-dc3f-44ac-9cdb-9d5b6f64eb9d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "79e1b463-dc3f-44ac-9cdb-9d5b6f64eb9d",
    "outputId": "9b869c41-3167-443d-a9d0-03965a10d01a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 1. 랜덤 시드 고정\n",
    "# 매번 실행할 때마다 같은 랜덤 값이 나오도록 설정하여 결과를 재현할 수 있게 합니다.\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# 2. 입력 데이터(Batch) 생성\n",
    "# 형태(Shape): [2, 5] -> (배치 크기=2, 입력 특징의 개수=5)\n",
    "# 예: 5가지 속성을 가진 데이터 샘플이 2개 있다는 의미입니다.\n",
    "batch_example = torch.randn(2, 5) \n",
    "\n",
    "# 3. 신경망 층(Layer) 정의\n",
    "# nn.Sequential은 여러 모듈을 순서대로 묶어주는 컨테이너입니다.\n",
    "layer = nn.Sequential(\n",
    "    # (1) 선형 변환 (Linear Layer): \n",
    "    # 입력 차원 5개를 받아 -> 6개의 차원으로 확장/변환합니다.\n",
    "    # 내부 연산: Output = Input x Weight + Bias\n",
    "    nn.Linear(5, 6), \n",
    "    \n",
    "    # (2) 활성화 함수 (ReLU):\n",
    "    # 선형 변환된 값에서 음수는 0으로 만들고, 양수는 그대로 둡니다.\n",
    "    # 비선형성을 추가하여 모델이 복잡한 패턴을 학습할 수 있게 돕습니다.\n",
    "    nn.ReLU()\n",
    ")\n",
    "\n",
    "# 4. 순전파 (Forward Pass)\n",
    "# 데이터를 층에 통과시킵니다.\n",
    "# 입력 [2, 5] -> Linear 거침 -> [2, 6] -> ReLU 거침 -> 최종 [2, 6]\n",
    "out = layer(batch_example)\n",
    "\n",
    "# 5. 결과 출력\n",
    "# 결과 형태는 [2, 6]이 됩니다. (2개의 샘플, 각 샘플당 6개의 특징값)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fccc29e-71fc-4c16-898c-6137c6ea5d2e",
   "metadata": {
    "id": "8fccc29e-71fc-4c16-898c-6137c6ea5d2e"
   },
   "source": [
    "- 두 개의 입력에 대해 각각 평균과 분산을 계산해 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9888f79e-8e69-44aa-8a19-cd34292adbf5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9888f79e-8e69-44aa-8a19-cd34292adbf5",
    "outputId": "4ee025db-a9b4-4892-8bfd-7335760f5b14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균:\n",
      " tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>)\n",
      "분산:\n",
      " tensor([[0.0231],\n",
      "        [0.0398]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 1. 평균(Mean) 계산\n",
    "# dim=-1: 가장 마지막 차원(여기서는 6개의 특성 값)을 기준으로 평균을 냅니다.\n",
    "#         즉, \"각 샘플(행)마다\" 가지고 있는 6개 숫자의 평균을 구합니다.\n",
    "# keepdim=True: 계산 후 차원을 없애지 않고 유지합니다.\n",
    "#               입력 [2, 6] -> 결과 [2, 1] (이 옵션이 없으면 [2]가 됨)\n",
    "mean = out.mean(dim=-1, keepdim=True)\n",
    "\n",
    "# 2. 분산(Variance) 계산\n",
    "# 데이터가 평균으로부터 얼마나 퍼져있는지(변동성)를 계산합니다.\n",
    "# 옵션은 평균 계산과 동일하게 마지막 차원을 기준으로 차원을 유지하며 계산합니다.\n",
    "var = out.var(dim=-1, keepdim=True)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"평균:\\n\", mean)\n",
    "print(\"분산:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052eda3e-b395-48c4-acd4-eb8083bab958",
   "metadata": {
    "id": "052eda3e-b395-48c4-acd4-eb8083bab958"
   },
   "source": [
    "- 정규화는 두 입력(행)에 대해 독립적으로 적용됩니다. dim=-1을 사용하면 행 차원이 아니라 마지막 차원(이 경우 특성 차원)을 따라 계산이 수행됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570db83a-205c-4f6f-b219-1f6195dde1a7",
   "metadata": {
    "id": "570db83a-205c-4f6f-b219-1f6195dde1a7"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch04_compressed/06.webp\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8ecbc7-eb14-4fa1-b5d0-7e1ff9694f99",
   "metadata": {
    "id": "9f8ecbc7-eb14-4fa1-b5d0-7e1ff9694f99"
   },
   "source": [
    "- 평균을 빼고, 분산의 제곱근(표준편차)으로 나누면 입력을 열(특성) 차원을 따라 평균이 0이고 분산이 1이 되도록 만듭니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9a1d1bb9-3341-4c9a-bc2a-d2489bf89cda",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9a1d1bb9-3341-4c9a-bc2a-d2489bf89cda",
    "outputId": "e9dded6c-f611-4ea7-9638-12b758c2fae3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화된 층 출력:\n",
      " tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
      "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "평균 (0에 가까워야 함):\n",
      " tensor([[    -0.0000],\n",
      "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
      "분산 (1에 가까워야 함):\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 1. 정규화 (Normalization) 수행\n",
    "# 공식: (입력값 - 평균) / 표준편차\n",
    "# torch.sqrt(var)는 분산의 제곱근이므로 '표준편차'가 됩니다.\n",
    "# 이 과정을 거치면 데이터의 중심이 0으로 이동하고, 퍼짐 정도가 1로 맞춰집니다.\n",
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "\n",
    "print(\"정규화된 층 출력:\\n\", out_norm)\n",
    "\n",
    "# 2. 결과 검증 (Verification)\n",
    "# 정규화가 제대로 되었다면,\n",
    "# 다시 구한 평균은 0에 매우 가깝고, 분산은 1에 매우 가까워야 합니다.\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "\n",
    "# 3. 검증 결과 출력\n",
    "# e-08 등의 표현이 나온다면 0에 아주 가까운 숫자라는 뜻입니다. (부동소수점 오차 감안)\n",
    "print(\"평균 (0에 가까워야 함):\\n\", mean)\n",
    "print(\"분산 (1에 가까워야 함):\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac62b90c-7156-4979-9a79-ce1fb92969c1",
   "metadata": {
    "id": "ac62b90c-7156-4979-9a79-ce1fb92969c1"
   },
   "source": [
    "- 각 입력의 평균은 0이고 분산은 1입니다. 결과를 보기 쉽도록 파이토치의 과학적 표기법을 끌 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e06c34b-c68a-4b36-afbe-b30eda4eca39",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3e06c34b-c68a-4b36-afbe-b30eda4eca39",
    "outputId": "17558a93-8dbf-4e25-8dfd-0b07418eb79c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균:\n",
      " tensor([[    -0.0000],\n",
      "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
      "분산:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "print(\"평균:\\n\", mean)\n",
    "print(\"분산:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944fb958-d4ed-43cc-858d-00052bb6b31a",
   "metadata": {
    "id": "944fb958-d4ed-43cc-858d-00052bb6b31a"
   },
   "source": [
    "- 위에서 각 입력의 특성을 정규화했습니다.\n",
    "- 이제 동일한 아이디어를 사용해 `LayerNorm` 클래스를 구현해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3333a305-aa3d-460a-bcce-b80662d464d9",
   "metadata": {
    "id": "3333a305-aa3d-460a-bcce-b80662d464d9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        # 1. 엡실론 (Epsilon) 정의\n",
    "        # 분산이 0이 되어 나눗셈 에러(Division by Zero)가 발생하는 것을 막기 위한 아주 작은 수입니다.\n",
    "        self.eps = 1e-5\n",
    "        \n",
    "        # 2. 학습 가능한 파라미터 (Scale & Shift)\n",
    "        # 단순히 정규화만 하면 모델의 표현력이 제한될 수 있습니다.\n",
    "        # 모델이 필요에 따라 데이터의 분포를 다시 조정할 수 있도록 '가중치'를 줍니다.\n",
    "        \n",
    "        # Scale (Gamma): 1로 초기화 (곱해도 값 변화 없음)\n",
    "        # nn.Parameter로 감싸야 역전파(Backprop) 때 학습(업데이트)이 됩니다.\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        \n",
    "        # Shift (Beta): 0으로 초기화 (더해도 값 변화 없음)\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 3. 통계량 계산\n",
    "        # 입력 데이터(x)의 마지막 차원(특성)을 기준으로 평균을 구합니다.\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        \n",
    "        # 분산을 구합니다.\n",
    "        # unbiased=False: 표본 분산(n-1로 나눔)이 아닌 모분산(n으로 나눔) 공식을 사용합니다.\n",
    "        # (딥러닝에서는 보통 n으로 나누는 방식을 선호합니다)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False) \n",
    "        \n",
    "        # 4. 정규화 (Normalization)\n",
    "        # (입력 - 평균) / sqrt(분산 + 엡실론)\n",
    "        # 데이터의 평균을 0, 분산을 1로 맞춥니다.\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        \n",
    "        # 5. 아핀 변환 (Affine Transformation)\n",
    "        # 정규화된 값에 학습된 스케일을 곱하고 시프트를 더해 최종 출력을 만듭니다.\n",
    "        # 이를 통해 모델은 정규화된 상태를 유지할지, 원래 데이터 특성을 살릴지 스스로 학습합니다.\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56c3908-7544-4808-b8cb-5d0a55bcca72",
   "metadata": {
    "id": "e56c3908-7544-4808-b8cb-5d0a55bcca72"
   },
   "source": [
    "**스케일 조정과 이동**\n",
    "\n",
    "- 평균을 빼고, 분산으로 나누어 정규화하는 것 이외에 두 개의 훈련 가능한 파라미터 `scale`과 `shift`를 추가했습니다.\n",
    "- 초기 `scale`(1)과 `shift`(0)은 아무런 영향을 미치지 못합니다. 하지만 `scale`과 `shift`가 훈련 가능한 파라미터이기 때문에 훈련 과정에서 두 파라미터를 조정하는 것이 훈련 작업에서 모델의 성능을 향상시킨다고 판단하는 경우 LLM이 자동으로 조정합니다.\n",
    "- 이를 통해 모델은 처리하는 데이터에 가잘 잘 맞는 스케일 조정과 이동을 학습할 수 있습니다.\n",
    "- 분산의 제곱근을 계산할 때 작은 값(`eps`)를 더합니다. 이는 분산이 0일 경우 0 나눗셈 오류를 방지하기 위해서입니다.\n",
    "\n",
    "**편향된 분산**\n",
    "- 위 분산 계산에서 `unbiased=False`는 $\\frac{\\sum_i (x_i - \\bar{x})^2}{n}$ 식으로 분산을 계산한다는 의미입니다. `n`은 샘플 크기입니다(여기서는 특성 또는 열 개수). 이 공식은 (분모가 `n-1`인) 베셀 보정(Bessel's correction)을 사용하지 않습니다. 따라서 편향된 분산을 추정합니다.\n",
    "- LLM에서 임베딩 차원 `n`은 매우 크므로 `n`과 `n-1`을 사용하는 차이는 무시할 수 있습니다.\n",
    "- 하지만 GPT-2가 정규화 층에 편향된 분산을 사용했으므로 나중에 사전 훈련된 가중치를 로드할 때 호환성을 위해 동일한 방식을 적용했습니다.\n",
    "- 이제 `LayerNorm`을 실제로 테스트해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "23b1000a-e613-4b43-bd90-e54deed8d292",
   "metadata": {
    "id": "23b1000a-e613-4b43-bd90-e54deed8d292"
   },
   "outputs": [],
   "source": [
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln = ln(batch_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "94c12de2-1cab-46e0-a099-e2e470353bff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "94c12de2-1cab-46e0-a099-e2e470353bff",
    "outputId": "b49dc597-2e56-4caf-b18e-527caabe3232"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균:\n",
      " tensor([[    -0.0000],\n",
      "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
      "분산:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
    "\n",
    "print(\"평균:\\n\", mean)\n",
    "print(\"분산:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e136cfc4-7c89-492e-b120-758c272bca8c",
   "metadata": {
    "id": "e136cfc4-7c89-492e-b120-758c272bca8c"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch04_compressed/07.webp\" width=\"700px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11190e7d-8c29-4115-824a-e03702f9dd54",
   "metadata": {
    "id": "11190e7d-8c29-4115-824a-e03702f9dd54"
   },
   "source": [
    "## 4.3 GELU 활성화 함수를 사용하는 피드 포워드 네트워크 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0585dfb-f21e-40e5-973f-2f63ad5cb169",
   "metadata": {
    "id": "b0585dfb-f21e-40e5-973f-2f63ad5cb169"
   },
   "source": [
    "- 이 절에서 LLM의 트랜스포머 블록에서 사용되는 작은 신경망 모듈을 구현합니다.\n",
    "- 딥러닝에서는 ReLU(Rectified Linear Unit) 활성화 함수가 간단하며 다양한 신경망 구조에서 효과적이기 때문에 널리 사용됩니다.\n",
    "- LLM에서는 전통적인 ReLU 외에도 다양한 종류의 활성화 함수가 사용됩니다. 대표적인 두 개의 함수는 GELU(Gaussian Error Linear Unit)와 SwiGLU(Swish-Gated Linear Unit)입니다.\n",
    "- GELU와 SwiGLU는 각각 가우스 오차 함수와 시그모이드 GLU(gated linear unit)을 사용한 더 복잡하고 부드러운 활성화 함수입니다. 간단한 ReLU와 달리 딥러닝 모델의 성능을 향상시킵니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d482ce7-e493-4bfc-a820-3ea99f564ebc",
   "metadata": {
    "id": "7d482ce7-e493-4bfc-a820-3ea99f564ebc"
   },
   "source": [
    "- GELU 활성화 함수([Hendrycks and Gimpel 2016](https://arxiv.org/abs/1606.08415))는 여러 방법으로 구현할 수 있습니다. 정확한 정의는 GELU(x) = x⋅𝛷(x)입니다. 여기서 𝛷(x)는 표준 가우스 누적 분포 함수(가우스 오차 함수)입니다.\n",
    "- 실제로는 계산하기 쉬운 근사식으로 구현합니다: $\\text{GELU}(x) \\approx 0.5 \\cdot x \\cdot \\left(1 + \\tanh\\left[\\sqrt{\\frac{2}{\\pi}} \\cdot \\left(x + 0.044715 \\cdot x^3\\right)\\right]\\right)\n",
    "$ (원본 GPT-2 모델도 커브 피팅(curve fitting)으로 찾은 이 근사식을 사용했습니다)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f84694b7-95f3-4323-b6d6-0a73df278e82",
   "metadata": {
    "id": "f84694b7-95f3-4323-b6d6-0a73df278e82"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # GELU는 학습해야 할 가중치(Parameter)가 없는 수학적 함수입니다.\n",
    "        # 따라서 초기화 함수(__init__)에서는 별다른 설정이 필요 없습니다.\n",
    "\n",
    "    def forward(self, x):\n",
    "        # GELU의 'tanh 근사 공식' 구현\n",
    "        # 원래 공식은 정규분포의 누적분포함수(CDF)를 사용하지만 계산 비용이 비쌉니다.\n",
    "        # 따라서 아래와 같이 tanh를 사용한 근사식을 주로 사용합니다.\n",
    "        # 식: 0.5 * x * (1 + tanh( sqrt(2/pi) * (x + 0.044715 * x^3) ))\n",
    "        \n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            # sqrt(2/pi)는 약 0.7978 정도 되는 상수입니다.\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * # 0.044715는 근사 오차를 최소화하기 위해 수학적으로 유도된 계수입니다.\n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fc5487d2-2576-4118-80a7-56c4caac2e71",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "fc5487d2-2576-4118-80a7-56c4caac2e71",
    "outputId": "31c14496-f8b6-42b4-9e61-9a7312cb04b8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "\n",
    "# 샘플 데이터\n",
    "x = torch.linspace(-3, 3, 100)\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
    "    plt.subplot(1, 2, i)\n",
    "    plt.plot(x, y)\n",
    "    plt.title(f\"{label} activation function\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(f\"{label}(x)\")\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd01662-14cb-43fd-bffd-2d702813de2d",
   "metadata": {
    "id": "1cd01662-14cb-43fd-bffd-2d702813de2d"
   },
   "source": [
    "- 여기서 보듯이 ReLU는 양수는 그대로 출력하고 음수는 모두 0을 출력하는 구간별 선형 함수(piecewise linear function)입니다.\n",
    "- GELU는 부드러운 비선형 함수로, ReLU와 비슷하지만 모든 음수 값의 그레이디언트를 0으로 만들지 않습니다(대략 x = -0.75에서는 그레이디언트가 0이 됩니다).\n",
    "- 그다음 LLM의 트랜스포머 블록에 사용할 작은 신경망 모듈인 `FeedForward`를 구현해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9275c879-b148-4579-a107-86827ca14d4d",
   "metadata": {
    "id": "9275c879-b148-4579-a107-86827ca14d4d"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        \n",
    "        # nn.Sequential: 여러 층(Layer)을 순서대로 묶어서 실행하는 컨테이너입니다.\n",
    "        self.layers = nn.Sequential(\n",
    "            \n",
    "            # 1. 확장 단계 (Expansion)\n",
    "            # 입력 차원(emb_dim)을 4배로 뻥튀기합니다.\n",
    "            # 예: 768 -> 3072 (GPT-2 small 기준)\n",
    "            # 이유: 차원을 넓혀서 더 풍부하고 복잡한 특징을 학습하기 위함입니다.\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            \n",
    "            # 2. 활성화 함수 (GELU)\n",
    "            # 앞서 구현한 GELU 함수를 사용하여 비선형성을 추가합니다.\n",
    "            # 0보다 작은 값을 부드럽게 처리하여 학습 안정성을 높입니다.\n",
    "            GELU(),\n",
    "            \n",
    "            # 3. 압축/복원 단계 (Projection)\n",
    "            # 4배로 늘어났던 차원을 다시 원래 크기(emb_dim)로 줄입니다.\n",
    "            # 예: 3072 -> 768\n",
    "            # 이유: 다음 레이어나 블록으로 데이터를 넘겨주기 위해 입출력 크기를 맞춰야 합니다.\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 정의된 순서대로(Linear -> GELU -> Linear) 데이터를 통과시킵니다.\n",
    "        # 입력 x와 출력의 형태(Shape)는 동일하게 유지됩니다. (배치, 시퀀스, 임베딩 차원)\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7c4976e2-0261-418e-b042-c5be98c2ccaf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7c4976e2-0261-418e-b042-c5be98c2ccaf",
    "outputId": "d609a4c9-2a11-4609-f748-2baead3b6bb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "print(GPT_CONFIG_124M[\"emb_dim\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcaacfa-3cfc-4c9e-b668-b71a2753145a",
   "metadata": {
    "id": "fdcaacfa-3cfc-4c9e-b668-b71a2753145a"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch04_compressed/09.webp\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "928e7f7c-d0b1-499f-8d07-4cadb428a6f9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "928e7f7c-d0b1-499f-8d07-4cadb428a6f9",
    "outputId": "a204a71c-277c-477b-c25a-2d6478971272"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "\n",
    "# 입력 크기: [batch_size, num_token, emb_size]\n",
    "x = torch.rand(2, 3, 768)\n",
    "out = ffn(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d779e0",
   "metadata": {},
   "source": [
    "입력에서 필요한 정보를 추출할 때 좀 더 잘 추출하기 위해 뻥튀기를 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8756c5-6b04-443b-93d0-e555a316c377",
   "metadata": {
    "id": "8f8756c5-6b04-443b-93d0-e555a316c377"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch04_compressed/10.webp\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5da2a50-04f4-4388-af23-ad32e405a972",
   "metadata": {
    "id": "e5da2a50-04f4-4388-af23-ad32e405a972"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch04_compressed/11.webp\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffcb905-53c7-4886-87d2-4464c5fecf89",
   "metadata": {
    "id": "4ffcb905-53c7-4886-87d2-4464c5fecf89"
   },
   "source": [
    "## 4.4 숏컷 연결 추가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffae416c-821e-4bfa-a741-8af4ba5db00e",
   "metadata": {
    "id": "ffae416c-821e-4bfa-a741-8af4ba5db00e"
   },
   "source": [
    "- 스킵 연결(skip connection)이나 잔차 연결(residual connection)이라고도 부르는 숏컷 연결(shortcut connection) 이면의 개념을 알아 보죠.\n",
    "- 원래 숏컷 연결은 컴퓨터 비전 분야의 심층 신경망(구체적으로 잔차 신경망(residual network))에서 그레이디언트 소실 문제를 완화하기 위해 제안되었습니다.\n",
    "- 숏컷 연결이 그레이디언트가 한 개 이상의 층을 건너 뛰어 네트워크에 흐를 수 있도록 짧은 다른 경로를 만든다는 것을 보여줍니다.\n",
    "- 이런 경로는 한 층의 출력을 이후 층의 출력에 더하여 만들어집니다.\n",
    "- 작은 샘플 네트워크로 이 아이디어를 설명해 보죠:\n",
    "\n",
    "<img src=\"images/llm_from_scratch/ch04_compressed/12.webp\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cfd241-a32e-4601-8790-784b82f2f23e",
   "metadata": {
    "id": "14cfd241-a32e-4601-8790-784b82f2f23e"
   },
   "source": [
    "- 코드로 구현하면 다음과 같습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "05473938-799c-49fd-86d4-8ed65f94fee6",
   "metadata": {
    "id": "05473938-799c-49fd-86d4-8ed65f94fee6"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        \n",
    "        # 1. 층(Layer) 생성\n",
    "        # nn.ModuleList를 사용하여 5개의 층을 리스트 형태로 관리합니다.\n",
    "        # 각 층은 [선형 변환 -> GELU 활성화 함수]로 구성됩니다.\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU())\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 2. 순전파 (Forward Pass)\n",
    "        for layer in self.layers:\n",
    "            # 현재 층을 통과시켜 출력을 계산합니다. (F(x))\n",
    "            layer_output = layer(x)\n",
    "            \n",
    "            # 3. 스킵 연결 (Skip Connection / Residual Connection) 적용 로직\n",
    "            # 조건 1: use_shortcut이 True여야 함 (사용자가 원할 때)\n",
    "            # 조건 2: 입력(x)과 출력(layer_output)의 차원(Shape)이 같아야 더할 수 있음\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                # [핵심] 입력값 x를 출력값에 그대로 더해줍니다. (x + F(x))\n",
    "                # 이렇게 하면 역전파 때 그레이디언트가 이 '지름길'을 타고\n",
    "                # 입력 쪽으로 막힘없이 흐를 수 있습니다.\n",
    "                x = x + layer_output\n",
    "            else:\n",
    "                # 스킵 연결을 안 쓰거나 차원이 다르면, 그냥 층의 출력만 다음으로 넘깁니다.\n",
    "                x = layer_output\n",
    "        return x\n",
    "\n",
    "\n",
    "def print_gradients(model, x):\n",
    "    # 1. 정방향 계산\n",
    "    output = model(x)\n",
    "    target = torch.tensor([[0.]]) # 임의의 정답지 (Loss 계산용)\n",
    "\n",
    "    # 2. 손실(Loss) 계산\n",
    "    # 모델의 출력과 목표값(0) 사이의 오차를 계산합니다. (MSE)\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)\n",
    "\n",
    "    # 3. 역전파 (Backpropagation)\n",
    "    # 오차를 줄이기 위해 각 가중치를 얼마나 수정해야 할지(기울기) 계산합니다.\n",
    "    # 이때 미분값이 뒤에서부터 앞으로 흘러옵니다.\n",
    "    loss.backward()\n",
    "\n",
    "    # 4. 그레이디언트(기울기) 확인\n",
    "    # 각 층의 가중치(weight)들이 가진 기울기의 크기를 출력합니다.\n",
    "    # 층이 깊어질수록 이 값이 0에 가까워지는지(소실 문제) 확인하는 것이 목적입니다.\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            # param.grad: 계산된 기울기\n",
    "            # abs().mean(): 기울기들의 절댓값 평균 (방향 무시하고 크기만 봄)\n",
    "            print(f\"{name}의 평균 그레이디언트는 {param.grad.abs().mean().item()}입니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39bf277-b3db-4bb1-84ce-7a20caff1011",
   "metadata": {
    "id": "b39bf277-b3db-4bb1-84ce-7a20caff1011"
   },
   "source": [
    "- 숏컷 연결이 **없을** 때 그레디언트 값을 출력해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c75f43cc-6923-4018-b980-26023086572c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c75f43cc-6923-4018-b980-26023086572c",
    "outputId": "d98c2d1b-6c4c-48f2-8bb6-a6d19ffe69c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight의 평균 그레이디언트는 0.00020173587836325169입니다.\n",
      "layers.1.0.weight의 평균 그레이디언트는 0.0001201116101583466입니다.\n",
      "layers.2.0.weight의 평균 그레이디언트는 0.0007152041071094573입니다.\n",
      "layers.3.0.weight의 평균 그레이디언트는 0.0013988735154271126입니다.\n",
      "layers.4.0.weight의 평균 그레이디언트는 0.005049645435065031입니다.\n"
     ]
    }
   ],
   "source": [
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(\n",
    "    layer_sizes, use_shortcut=False\n",
    ")\n",
    "print_gradients(model_without_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837fd5d4-7345-4663-97f5-38f19dfde621",
   "metadata": {
    "id": "837fd5d4-7345-4663-97f5-38f19dfde621"
   },
   "source": [
    "- 그다음 숏컷 연결이 **있을** 때 그레이디언트 값을 출력합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "11b7c0c2-f9dd-4dd5-b096-a05c48c5f6d6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "11b7c0c2-f9dd-4dd5-b096-a05c48c5f6d6",
    "outputId": "18441ec2-fc0f-463b-94a0-0b26ba0e3d63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight의 평균 그레이디언트는 0.22169791162014008입니다.\n",
      "layers.1.0.weight의 평균 그레이디언트는 0.20694106817245483입니다.\n",
      "layers.2.0.weight의 평균 그레이디언트는 0.32896995544433594입니다.\n",
      "layers.3.0.weight의 평균 그레이디언트는 0.2665732204914093입니다.\n",
      "layers.4.0.weight의 평균 그레이디언트는 1.3258540630340576입니다.\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(\n",
    "    layer_sizes, use_shortcut=True\n",
    ")\n",
    "print_gradients(model_with_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ff783a-46f0-49c5-a7a9-26a525764b6e",
   "metadata": {
    "id": "79ff783a-46f0-49c5-a7a9-26a525764b6e"
   },
   "source": [
    "- 위 출력에서 볼 수 있듯이 숏컷 연결이 앞쪽 층(`layer.0` 층)의 그레이디언트 소실 문제를 막습습니다.\n",
    "- 숏컷 연결의 개념을 사용해 트랜스포머 블록을 구현하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae578ca-e564-42cf-8635-a2267047cdff",
   "metadata": {
    "id": "cae578ca-e564-42cf-8635-a2267047cdff"
   },
   "source": [
    "## 4.5 어텐션과 선형 층을 트랜스포머 블록에 연결하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3daac6f-6545-4258-8f2d-f45a7394f429",
   "metadata": {
    "id": "a3daac6f-6545-4258-8f2d-f45a7394f429"
   },
   "source": [
    "- 이 절에서 이전에 배운 개념을 소위 트랜스포머 블록에 결합합니다.\n",
    "- 트랜스포머 블록은 이전 층에서 다룬 코잘 멀티 헤드 어텐션 모듈과 앞서 다룬 피드 포워드 신경망을 결합합니다.\n",
    "- 또한 트랜스포머 블록은 드롭아웃과 숏컷 연결을 사용합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0e1e8176-e5e3-4152-b1aa-0bbd7891dfd9",
   "metadata": {
    "id": "0e1e8176-e5e3-4152-b1aa-0bbd7891dfd9"
   },
   "outputs": [],
   "source": [
    "from previous_chapters import MultiHeadAttention\n",
    "import torch.nn as nn\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 1. 멀티 헤드 어텐션 (Multi-Head Attention)\n",
    "        # 문맥을 파악하는 핵심 부품입니다.\n",
    "        # \"단어들 사이의 관계\"를 계산하여 문맥 정보를 수집합니다.\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"]\n",
    "        )\n",
    "        \n",
    "        # 2. 피드 포워드 신경망 (FeedForward)\n",
    "        # 수집된 문맥 정보를 바탕으로 각 토큰(단어)의 정보를 개별적으로 가공/확장합니다.\n",
    "        self.ff = FeedForward(cfg)\n",
    "        \n",
    "        # 3. 레이어 정규화 (LayerNorm)\n",
    "        # 학습을 안정적으로 만들기 위해 데이터 분포를 정리합니다.\n",
    "        # 어텐션 앞(norm1)과 피드포워드 앞(norm2)에 각각 하나씩 배치됩니다.\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        \n",
    "        # 4. 드롭아웃 (Dropout)\n",
    "        # 과적합(Overfitting)을 방지하기 위해 숏컷 연결 직전에 사용합니다.\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # === [파트 1] 어텐션 블록 (Attention Block) ===\n",
    "        \n",
    "        # A. 숏컷(Shortcut) 저장\n",
    "        # \"변형되기 전의 원본 데이터\"를 따로 빼둡니다. (잔차 연결용)\n",
    "        shortcut = x\n",
    "        \n",
    "        # B. 정규화 (Pre-LayerNorm)\n",
    "        # 어텐션에 들어가기 '전에' 정규화를 먼저 합니다. (GPT-2 방식)\n",
    "        x = self.norm1(x)\n",
    "        \n",
    "        # C. 어텐션 수행\n",
    "        # 자기 자신을 포함한 주변 단어들의 정보를 모읍니다.\n",
    "        # 크기 유지: [batch_size, num_tokens, emb_size]\n",
    "        x = self.att(x)\n",
    "        \n",
    "        # D. 드롭아웃 적용\n",
    "        x = self.drop_shortcut(x)\n",
    "        \n",
    "        # E. 잔차 연결 (Residual Connection)\n",
    "        # \"학습된 변화량(x)\"에 \"원본(shortcut)\"을 더합니다.\n",
    "        # 이는 정보가 손실되지 않고 깊은 층까지 흐르게 도와줍니다.\n",
    "        x = x + shortcut \n",
    "\n",
    "        # === [파트 2] 피드 포워드 블록 (Feed Forward Block) ===\n",
    "        \n",
    "        # A. 숏컷 저장 (현재 상태를 다시 원본으로 취급)\n",
    "        shortcut = x\n",
    "        \n",
    "        # B. 정규화\n",
    "        x = self.norm2(x)\n",
    "        \n",
    "        # C. 피드 포워드 수행\n",
    "        # 정보를 확장했다가 압축하며 특징을 학습합니다.\n",
    "        x = self.ff(x)\n",
    "        \n",
    "        # D. 드롭아웃\n",
    "        x = self.drop_shortcut(x)\n",
    "        \n",
    "        # E. 잔차 연결\n",
    "        x = x + shortcut \n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b64d16-94a6-4d13-8c85-9494c50478a9",
   "metadata": {
    "id": "36b64d16-94a6-4d13-8c85-9494c50478a9"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch04_compressed/13.webp\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d2d375-87bd-4153-9040-63a1e6a2b7cb",
   "metadata": {
    "id": "54d2d375-87bd-4153-9040-63a1e6a2b7cb"
   },
   "source": [
    "- 두 개의 입력 샘플이 있다고 가정해 보죠. 각 샘플은 여섯 개의 토큰으로 구성되고 각 토큰은 768차원의 임베딩 벡터입니다. 트랜스포머 블록이 셀프 어텐션과 피드 포워드 신경망을 적용하여 동일 크기의 출력을 반환합니다.\n",
    "- 이 출력을 이전 장에서 이야기한 문맥 벡터의 증강된 버전으로 생각할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3fb45a63-b1f3-4b08-b525-dafbc8228405",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3fb45a63-b1f3-4b08-b525-dafbc8228405",
    "outputId": "8da8edb1-a5ba-4286-a862-92e46b5200e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 크기: torch.Size([2, 4, 768])\n",
      "출력 크기: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "x = torch.rand(2, 4, 768)  # 크기: [batch_size, num_tokens, emb_dim]\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "\n",
    "print(\"입력 크기:\", x.shape)\n",
    "print(\"출력 크기:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9e4ee4-cf23-4583-b1fd-317abb4fcd13",
   "metadata": {
    "id": "8f9e4ee4-cf23-4583-b1fd-317abb4fcd13"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch04_compressed/14.webp\" width=\"700px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46618527-15ac-4c32-ad85-6cfea83e006e",
   "metadata": {
    "id": "46618527-15ac-4c32-ad85-6cfea83e006e"
   },
   "source": [
    "## 4.6 GPT 모델 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec7d03d-9ff3-4ca3-ad67-01b67c2f5457",
   "metadata": {
    "id": "dec7d03d-9ff3-4ca3-ad67-01b67c2f5457"
   },
   "source": [
    "- 트랜스포머 블록을 이 장의 서두에서 만들었던 GPT 구조에 연결해 보죠.\n",
    "- 트랜스포머 블록은 여러 번 반복됩니다. 1억 2,400만 파라미터의 GPT-2 모델의 경우 12번 반복합니다:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7b362d-f8c5-48d2-8ebd-722480ac5073",
   "metadata": {
    "id": "9b7b362d-f8c5-48d2-8ebd-722480ac5073"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch04_compressed/15.webp\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324e4b5d-ed89-4fdf-9a52-67deee0593bc",
   "metadata": {
    "id": "324e4b5d-ed89-4fdf-9a52-67deee0593bc"
   },
   "source": [
    "- 이를 코드로 구현하면 다음과 같습니다. 여기서 `cfg[\"n_layers\"] = 12`입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c61de39c-d03c-4a32-8b57-f49ac3834857",
   "metadata": {
    "id": "c61de39c-d03c-4a32-8b57-f49ac3834857"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 1. 토큰 임베딩 (Token Embedding)\n",
    "        # 입력된 단어 ID를 벡터(숫자들의 리스트)로 변환합니다.\n",
    "        # 예: \"Apple\"(ID: 52) -> [0.1, -0.5, ...]\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        \n",
    "        # 2. 위치 임베딩 (Positional Embedding)\n",
    "        # GPT는 순차적으로 글을 읽는 것이 아니라 한 번에 보므로, 단어의 순서 정보를 따로 알려줘야 합니다.\n",
    "        # \"첫 번째 단어\", \"두 번째 단어\"에 해당하는 고유한 벡터를 학습합니다.\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        \n",
    "        # 3. 임베딩 드롭아웃\n",
    "        # 임베딩 단계에서 과적합을 방지하기 위해 사용합니다.\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        # 4. 트랜스포머 블록 쌓기 (The \"Brain\")\n",
    "        # 앞서 만든 TransformerBlock을 설정한 층수(n_layers)만큼 반복해서 쌓습니다.\n",
    "        # * (asterisk)는 리스트의 요소들을 풀어서 nn.Sequential에 개별 인자로 넣어줍니다.\n",
    "        # (마치 블록을 12층, 24층 높이로 쌓아 올리는 것과 같습니다.)\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "\n",
    "        # 5. 최종 정규화 (Final Normalization)\n",
    "        # 모든 블록을 통과한 후, 출력값을 안정적으로 만들기 위해 마지막으로 한 번 더 정규화합니다.\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        \n",
    "        # 6. 출력 헤드 (Output Head)\n",
    "        # 모델이 이해한 벡터(emb_dim)를 다시 전체 단어장 크기(vocab_size)로 변환합니다.\n",
    "        # 이 결과값이 각 단어가 \"다음 단어일 확률 점수(Logits)\"가 됩니다.\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        # in_idx: 입력 텍스트의 토큰 ID들 [batch_size, seq_len]\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        \n",
    "        # A. 임베딩 계산\n",
    "        # 토큰 자체의 의미 벡터 생성\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        \n",
    "        # 위치 정보 벡터 생성 (0, 1, 2, ... seq_len-1)\n",
    "        # device=in_idx.device를 써야 GPU/CPU 에러가 나지 않습니다.\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        \n",
    "        # B. 정보 결합\n",
    "        # [단어의 의미] + [단어의 위치]를 더해서 모델에게 전달합니다.\n",
    "        # 파이토치의 브로드캐스팅 기능으로 pos_embeds가 배치의 모든 문장에 똑같이 더해집니다.\n",
    "        x = tok_embeds + pos_embeds  # 크기: [batch_size, num_tokens, emb_size]\n",
    "        \n",
    "        # C. 드롭아웃 적용\n",
    "        x = self.drop_emb(x)\n",
    "        \n",
    "        # D. 트랜스포머 블록 통과 (Deep Processing)\n",
    "        # 데이터가 깊은 신경망 층을 통과하며 고차원적인 특징을 학습합니다.\n",
    "        x = self.trf_blocks(x)\n",
    "        \n",
    "        # E. 최종 정규화\n",
    "        x = self.final_norm(x)\n",
    "        \n",
    "        # F. 다음 단어 예측 (Logits 생성)\n",
    "        # [batch_size, seq_len, vocab_size] 크기의 텐서가 나옵니다.\n",
    "        logits = self.out_head(x)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2750270f-c45d-4410-8767-a6adbd05d5c3",
   "metadata": {
    "id": "2750270f-c45d-4410-8767-a6adbd05d5c3"
   },
   "source": [
    "- 1억 2,400만 파라미터 모델의 설정을 사용해 랜덤한 초기 가중치로 GPT 모델을 만들었습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ef94fd9c-4e9d-470d-8f8e-dd23d1bb1f64",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ef94fd9c-4e9d-470d-8f8e-dd23d1bb1f64",
    "outputId": "a85a7c67-46a8-49cd-b4c5-d709c4dfedea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 배치:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "\n",
      "출력 크기: torch.Size([2, 4, 50257])\n",
      "tensor([[[ 0.3613,  0.4222, -0.0711,  ...,  0.3483,  0.4661, -0.2838],\n",
      "         [-0.1792, -0.5660, -0.9485,  ...,  0.0477,  0.5181, -0.3168],\n",
      "         [ 0.7120,  0.0332,  0.1085,  ...,  0.1018, -0.4327, -0.2553],\n",
      "         [-1.0076,  0.3418, -0.1190,  ...,  0.7195,  0.4023,  0.0532]],\n",
      "\n",
      "        [[-0.2564,  0.0900,  0.0335,  ...,  0.2659,  0.4454, -0.6806],\n",
      "         [ 0.1230,  0.3653, -0.2074,  ...,  0.7705,  0.2710,  0.2246],\n",
      "         [ 1.0558,  1.0318, -0.2800,  ...,  0.6936,  0.3205, -0.3178],\n",
      "         [-0.1565,  0.3926,  0.3288,  ...,  1.2630, -0.1858,  0.0388]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "out = model(batch)\n",
    "print(\"입력 배치:\\n\", batch)\n",
    "print(\"\\n출력 크기:\", out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d616e7a-568b-4921-af29-bd3f4683cd2e",
   "metadata": {
    "id": "6d616e7a-568b-4921-af29-bd3f4683cd2e"
   },
   "source": [
    "- 이 모델을 다음 장에서 훈련해보겠습니다.\n",
    "- 크기를 간단히 계산해 보죠. 1억 2,400만 파라미터를 가지고 있는지 다음처럼 확인할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "84fb8be4-9d3b-402b-b3da-86b663aac33a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "84fb8be4-9d3b-402b-b3da-86b663aac33a",
    "outputId": "22a8b7b0-d55f-4b30-ded9-b53b450ebf22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 파라미터 개수: 163,009,536\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"총 파라미터 개수: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67d13dd-dd01-4ba6-a2ad-31ca8a9fd660",
   "metadata": {
    "id": "b67d13dd-dd01-4ba6-a2ad-31ca8a9fd660"
   },
   "source": [
    "- 위에서 보듯이 이 모델의 파라미터 개수는 1억 2,400만개가 아니라 1억 6,300만개입니다. 왜일까요?\n",
    "- 원본 GPT-2 논문에서 연구자들은 가중치 묶기(weight tying)를 적용했습니다. 토큰 임베딩 층(`tok_emb`)의 가중치를 출력 층에 재사용한다는 의미이며, `self.out_head.weight = self.tok_emb.weight`처럼 설정합니다.\n",
    "- 토큰 임베딩 층은 50,257차원의 원-핫 인코딩된 입력 토큰을 768차원의 임베딩 표현에 투영합니다.\n",
    "- 출력 층은 768차원의 임베딩을 단어로 변환하기 위해 50,257차원의 표현으로 다시 투영합니다(다음 절에서 자세히 설명합니다).\n",
    "- 따라서 가중치 행렬의 크기를 보면 알 수 있듯이 임베딩 층과 출력 층의 파라미터 개수가 같습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e3b43233-e9b8-4f5a-b72b-a263ec686982",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e3b43233-e9b8-4f5a-b72b-a263ec686982",
    "outputId": "65739d1f-5e94-4702-9082-86bb6cbeae68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토큰 임베딩 층의 가중치 크기: torch.Size([50257, 768])\n",
      "출력 층의 가중치 크기: torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"토큰 임베딩 층의 가중치 크기:\", model.tok_emb.weight.shape)\n",
    "print(\"출력 층의 가중치 크기:\", model.out_head.weight.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02259f6-6f79-4c89-a866-4ebeae1c3289",
   "metadata": {
    "id": "f02259f6-6f79-4c89-a866-4ebeae1c3289"
   },
   "source": [
    "- 원본 GPT-2 논문에서 연구자들은 토큰 임베딩 행렬을 출력 행렬로 재사용했습니다.\n",
    "- 결과적으로 출력 층의 파라미터 개수를 빼면 1억 2,400만 파라미터의 모델이 됩니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "95a22e02-50d3-48b3-a4e0-d9863343c164",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "95a22e02-50d3-48b3-a4e0-d9863343c164",
    "outputId": "7d3597ac-495c-4c33-cc84-13574661a730"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가중치 묶기를 고려한 훈련 가능한 파라미터 개수: 124,412,160\n"
     ]
    }
   ],
   "source": [
    "total_params_gpt2 =  total_params - sum(p.numel() for p in model.out_head.parameters())\n",
    "print(f\"가중치 묶기를 고려한 훈련 가능한 파라미터 개수: {total_params_gpt2:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b03f80-b94c-46e7-9d42-d0df399ff3db",
   "metadata": {
    "id": "40b03f80-b94c-46e7-9d42-d0df399ff3db"
   },
   "source": [
    "- 실제로는 가중치 묶기가 없는 모델이 훈련하기 쉽기 때문에 여기서는 구현하지 않습니다.\n",
    "- 하지만 5장에서 사전 훈련된 가중치를 로드할 때 가중치 묶기를 적용하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7J2mcpNPYgAf",
   "metadata": {
    "id": "7J2mcpNPYgAf"
   },
   "source": [
    "- 마지막으로 모델에 필요한 메모리 크기를 계산해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5131a752-fab8-4d70-a600-e29870b33528",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5131a752-fab8-4d70-a600-e29870b33528",
    "outputId": "bba8b4c6-38cc-4adb-f355-8e065e92797d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델에 필요한 메모리 공간: 621.83 MB\n"
     ]
    }
   ],
   "source": [
    "# 총 크기를 바이트 단위로 계산합니다(float32라 가정하면 파라미터당 4바이트입니다).\n",
    "total_size_bytes = total_params * 4\n",
    "\n",
    "# 메가바이트로 변환합니다.\n",
    "total_size_mb = total_size_bytes / (1024 * 1024)\n",
    "\n",
    "print(f\"모델에 필요한 메모리 공간: {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5d9bc0-95ab-45d4-9378-417628d86e35",
   "metadata": {
    "id": "da5d9bc0-95ab-45d4-9378-417628d86e35"
   },
   "source": [
    "## 4.7 텍스트 생성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48da5deb-6ee0-4b9b-8dd2-abed7ed65172",
   "metadata": {
    "id": "48da5deb-6ee0-4b9b-8dd2-abed7ed65172"
   },
   "source": [
    "- 앞에서 구현한 GPT와 같은 LLM은 한 번에 하나의 단어를 생성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caade12a-fe97-480f-939c-87d24044edff",
   "metadata": {
    "id": "caade12a-fe97-480f-939c-87d24044edff"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch04_compressed/16.webp\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7061524-a3bd-4803-ade6-2e3b7b79ac13",
   "metadata": {
    "id": "a7061524-a3bd-4803-ade6-2e3b7b79ac13"
   },
   "source": [
    "- 다음에 나오는 `generate_text_simple` 함수는 간단하고 빠르게 텍스트를 생성하는 그리디 디코딩(greedy decoding)을 구현합니다.\n",
    "- 그리디 디코딩에서는 각 단계마다 모델이 가장 높은 확률을 가진 단어(또는 토큰)을 다음 출력으로 선택합니다(가장 높은 로짓이 가장 높은 확률에 대응됩니다. 따라서 기술적으로는 명시적으로 소프트매맥스 함수를 적용할 필요가 없습니다).\n",
    "- 다음 장에서 조금 더 고급 기법을 사용한 `generate_text` 함수를 구현하겠습니다.\n",
    "- 다음 그림은 GPT 모델이 주어진 문맥을 기반으로 다음 토큰을 생성하는 방법을 보여줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee0f32c-c18c-445e-b294-a879de2aa187",
   "metadata": {
    "id": "7ee0f32c-c18c-445e-b294-a879de2aa187"
   },
   "source": [
    "<img src=\"images/llm_from_scratch/ch04_compressed/17.webp\" width=\"900px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c9b428a9-8764-4b36-80cd-7d4e00595ba6",
   "metadata": {
    "id": "c9b428a9-8764-4b36-80cd-7d4e00595ba6"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model: 학습된 GPT 모델\n",
    "        idx: 현재까지 입력된 텍스트의 토큰 인덱스 텐서 (배치 크기, 현재 길이)\n",
    "        max_new_tokens: 새로 생성할 토큰의 개수\n",
    "        context_size: 모델이 한 번에 처리할 수 있는 최대 문맥 길이 (예: 1024)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 생성할 토큰 개수만큼 반복합니다. (한 번에 하나씩 생성)\n",
    "    for _ in range(max_new_tokens):\n",
    "\n",
    "        # 1. 문맥 자르기 (Sliding Window)\n",
    "        # 입력된 텍스트(idx)가 모델의 최대 허용 길이(context_size)를 넘으면,\n",
    "        # 가장 오래된 앞부분은 자르고 최근 내용만 남겨서 모델에 입력합니다.\n",
    "        # 예: context_size가 4인데 입력이 [1, 2, 3, 4, 5]라면 -> [2, 3, 4, 5]만 사용\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "\n",
    "        # 2. 모델 예측 (Forward Pass)\n",
    "        # 그레이디언트 계산을 끕니다(no_grad). \n",
    "        # 학습이 아니라 추론(생성) 단계이므로 메모리를 아끼고 속도를 높입니다.\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "\n",
    "        # 3. 다음 단어 예측값 추출\n",
    "        # 모델은 입력된 모든 위치에 대해 예측값을 내놓지만, \n",
    "        # 우리는 문장의 '맨 마지막' 단어 다음에 올 단어만 궁금합니다.\n",
    "        # logits 형태: [배치, 시퀀스 길이, 단어장 크기] -> [배치, 단어장 크기]\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # 4. 확률 변환 (Softmax)\n",
    "        # 로짓(점수)을 0~1 사이의 확률값으로 변환합니다.\n",
    "        # dim=-1: 단어장 차원을 기준으로 확률을 계산합니다.\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "\n",
    "        # 5. 그리디 선택 (Greedy Selection)\n",
    "        # 확률이 가장 높은(argmax) 단어의 인덱스 하나를 무조건 선택합니다.\n",
    "        # (이 방식은 항상 같은 결과를 내며, 창의성은 떨어질 수 있습니다.)\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
    "\n",
    "        # 6. 문장 이어 붙이기 (Concatenation)\n",
    "        # 방금 찾은 다음 단어(idx_next)를 기존 문장(idx) 뒤에 붙입니다.\n",
    "        # 이 업데이트된 idx가 다음 반복문에서 다시 모델의 입력으로 들어갑니다. (Autoregressive)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "    # 최종적으로 완성된 전체 문장(인덱스 배열)을 반환합니다.\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6515f2c1-3cc7-421c-8d58-cc2f563b7030",
   "metadata": {
    "id": "6515f2c1-3cc7-421c-8d58-cc2f563b7030"
   },
   "source": [
    "- `generate_text_simple`는 한 번에 하나의 토큰을 만드는 반복적인 과정을 구현합니다.\n",
    "\n",
    "<img src=\"images/llm_from_scratch/ch04_compressed/18.webp\" width=\"700px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f682eac4-f9bd-438b-9dec-6b1cc7bc05ce",
   "metadata": {
    "id": "f682eac4-f9bd-438b-9dec-6b1cc7bc05ce"
   },
   "source": [
    "- 입력 샘플을 준비해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3d7e3e94-df0f-4c0f-a6a1-423f500ac1d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3d7e3e94-df0f-4c0f-a6a1-423f500ac1d3",
    "outputId": "5c50d131-de30-4984-d311-dfdbac474a06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩된 ID: [15496, 11, 314, 716]\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello, I am\"\n",
    "\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"인코딩된 ID:\", encoded)\n",
    "\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a72a9b60-de66-44cf-b2f9-1e638934ada4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a72a9b60-de66-44cf-b2f9-1e638934ada4",
    "outputId": "d0d1a5ce-51e5-44b9-8d20-5cf9ff505214"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출력(Tensor): tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 42348,  7267]])\n",
      "출력 길이: 10\n"
     ]
    }
   ],
   "source": [
    "# 1. 평가 모드 전환 (Evaluation Mode)\n",
    "# 모델을 '학습 모드(Train)'에서 '평가 모드(Eval)'로 변경합니다.\n",
    "# 중요: 이 설정을 해야 드롭아웃(Dropout)이 비활성화되어, \n",
    "#       매번 실행할 때마다 결과가 흔들리지 않고 일관되게 나옵니다.\n",
    "model.eval() \n",
    "\n",
    "# 2. 텍스트 생성 실행\n",
    "# 앞서 정의한 함수를 호출하여 다음 단어들을 예측합니다.\n",
    "out = generate_text_simple(\n",
    "    model=model,\n",
    "    # encoded_tensor: 토크나이저로 숫자로 변환된 입력 문장(프롬프트)\n",
    "    idx=encoded_tensor, \n",
    "    \n",
    "    # 새로운 토큰 6개만 더 생성하겠다는 의미입니다.\n",
    "    # (입력 길이가 10이라면, 결과 길이는 16이 됩니다.)\n",
    "    max_new_tokens=6, \n",
    "    \n",
    "    # 모델이 기억할 수 있는 최대 길이(예: 1024)를 전달합니다.\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "# 3. 결과 확인\n",
    "# 출력되는 'out'은 아직 사람이 읽을 수 있는 글자가 아니라, '숫자(Token ID)들의 텐서'입니다.\n",
    "print(\"출력(Tensor):\", out)\n",
    "\n",
    "# 생성된 전체 길이(입력 + 6)를 확인합니다.\n",
    "print(\"출력 길이:\", len(out[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d131c00-1787-44ba-bec3-7c145497b2c3",
   "metadata": {
    "id": "1d131c00-1787-44ba-bec3-7c145497b2c3"
   },
   "source": [
    "- 배치 차원을 삭제하고 텍스트로 다시 변환합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "053d99f6-5710-4446-8d52-117fb34ea9f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "053d99f6-5710-4446-8d52-117fb34ea9f6",
    "outputId": "96625fcb-6d82-44d7-e888-9d93a7bd80b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am Featureiman Byeswickattribute argue\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a894003-51f6-4ccc-996f-3b9c7d5a1d70",
   "metadata": {
    "id": "9a894003-51f6-4ccc-996f-3b9c7d5a1d70"
   },
   "source": [
    "- 모델이 훈련되지 않았기 때문에 위와 같이 랜덤한 텍스트가 출력됩니다.\n",
    "- 다음 장에서 이 모델을 훈련하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35278b6-9e5c-480f-83e5-011a1173648f",
   "metadata": {
    "id": "a35278b6-9e5c-480f-83e5-011a1173648f"
   },
   "source": [
    "## 요약\n",
    "\n",
    "- 연습문제 솔루션은 [./exercise-solutions.ipynb](./exercise-solutions.ipynb)에 있습니다."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "llm_hands_on (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
